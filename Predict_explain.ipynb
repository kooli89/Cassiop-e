{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/DATA/anaconda3/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D,Conv1D, MaxPooling1D\n",
    "from keras.models import model_from_config\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import load_model\n",
    "from keras.layers.convolutional import AveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "import RNA\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import gzip\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "import pdb\n",
    "from math import  sqrt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import theano\n",
    "import subprocess as sp\n",
    "import scipy.stats as stats\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import csv\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement du modèle et prédictions : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paramètres \n",
    "\n",
    "matrixsize11 = 6\n",
    "nbfilter11 = 24\n",
    "matrixsize12 = 7\n",
    "nbfilter12 = 4\n",
    "matrixsize21 = 6\n",
    "nbfilter21 = 24\n",
    "matrixsize22 = 7\n",
    "nbfilter22 = 4\n",
    "nbfilter1 = 64\n",
    "kernelsize = 7\n",
    "nbfilters2 = 64\n",
    "kernel_size2 = 7\n",
    "Dense1 = 128\n",
    "Dense2 = 512\n",
    "Dense3 = 512\n",
    "Dense4 = 128\n",
    "Dense5 = 0\n",
    "\n",
    "k = matrixsize11\n",
    "# init_weights\n",
    "I = np.eye(k)\n",
    "M = np.diag(np.ones(k-1),1) + np.diag(np.ones(k-1),-1) + np.eye(k)\n",
    "I2 = np.zeros((k,k))\n",
    "M2 = np.zeros((k,k))\n",
    "for j in range(k):\n",
    "    I2[:,j] = I[:,k-j-1]\n",
    "    M2[:,j] = M[:,k-j-1]        \n",
    "W = np.zeros((k,k,1,nbfilter11))\n",
    "W[:,:,0,0] = I\n",
    "W[:,:,0,1] = I2\n",
    "W[:,:,0,2] = M\n",
    "W[:,:,0,3] = M2\n",
    "for j in range(4,nbfilter11):\n",
    "    W[:,:,0,j] = np.random.randn(k,k)*0.2\n",
    "\n",
    "\n",
    "k2 = matrixsize12\n",
    "I = np.eye(k2)\n",
    "M = np.diag(np.ones(k2-1),1) + np.diag(np.ones(k2-1),-1) + np.eye(k2)\n",
    "I2=np.zeros((k2,k2))\n",
    "M2=np.zeros((k2,k2))\n",
    "for j in range(k2):\n",
    "    I2[:,j] = I[:,k2-j-1]\n",
    "    M2[:,j] = M[:,k2-j-1]   \n",
    "\n",
    "Z = np.zeros((k2,k2,nbfilter11,nbfilter12))\n",
    "\n",
    "for u in range(nbfilter12):\n",
    "    Z[:,:,u,0] = I\n",
    "    Z[:,:,u,1] = I2\n",
    "    Z[:,:,u,2] = M\n",
    "    Z[:,:,u,3] = M2\n",
    "    for p in range(4,nbfilter12):\n",
    "        Z[:,:,u,p]=np.random.randn(k2,k2)*0.3            \n",
    "\n",
    "c2d1_input = keras.Input(shape=(36,36,1))\n",
    "cnn2d1 = Conv2D(filters = nbfilter11, kernel_size=(k,k), padding='valid', input_shape=(36,36,1),strides=(1,1),weights=[W,np.zeros(nbfilter11)])(c2d1_input)\n",
    "cnn2d1 = AveragePooling2D(pool_size=(3,3))(cnn2d1)\n",
    "cnn2d1 = Conv2D(filters = nbfilter12, kernel_size = (k2, k2),strides=(1,1),padding='valid',weights=[Z,np.zeros(nbfilter12)])(cnn2d1)\n",
    "cnn2d1 = Dropout(0.2)(cnn2d1)\n",
    "cnn2d1 = Flatten()(cnn2d1)\n",
    "\n",
    "c2d2_input = keras.Input(shape=(36,36,1))\n",
    "cnn2d2 = Conv2D(filters = nbfilter11, kernel_size=(k,k), padding='valid', input_shape=(36,36,1),strides=(1,1),weights=[W,np.zeros(nbfilter11)])(c2d2_input)\n",
    "cnn2d2 = AveragePooling2D(pool_size=(3,3))(cnn2d2)\n",
    "cnn2d2 = Conv2D(filters = nbfilter12, kernel_size = (k2, k2),strides=(1,1),padding='valid',weights=[Z,np.zeros(nbfilter12)])(cnn2d2)\n",
    "cnn2d2 = Dropout(0.2)(cnn2d2)\n",
    "cnn2d2 = Flatten()(cnn2d2)\n",
    "\n",
    "c1d1_input = keras.Input(shape=(36,4))\n",
    "cnn1d1 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d1_input)\n",
    "cnn1d1 = MaxPooling1D(pool_size=8)(cnn1d1)\n",
    "cnn1d1 = Dropout(0.2)(cnn1d1)\n",
    "cnn1d1 = Flatten()(cnn1d1)\n",
    "\n",
    "c1d2_input = keras.Input(shape=(36,4))\n",
    "cnn1d2 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d2_input)\n",
    "cnn1d2 = MaxPooling1D(pool_size=8)(cnn1d2)\n",
    "cnn1d2 = Dropout(0.2)(cnn1d2)\n",
    "cnn1d2 = Flatten()(cnn1d2)\n",
    "\n",
    "c1d3_input = keras.Input(shape=(36,4))\n",
    "cnn1d3 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d3_input)\n",
    "cnn1d3 = MaxPooling1D(pool_size=8)(cnn1d3)\n",
    "cnn1d3 = Dropout(0.2)(cnn1d3)\n",
    "cnn1d3 = Flatten()(cnn1d3)\n",
    "\n",
    "c1d4_input = keras.Input(shape=(36,4))\n",
    "cnn1d4 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d4_input)\n",
    "cnn1d4 = MaxPooling1D(pool_size=8)(cnn1d4)\n",
    "cnn1d4 = Dropout(0.2)(cnn1d4)\n",
    "cnn1d4 = Flatten()(cnn1d4)\n",
    "\n",
    "model21 = keras.layers.concatenate([cnn1d1,cnn1d2])\n",
    "model21 = Dense(int(Dense2/2),kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model21)\n",
    "model21 = BatchNormalization()(model21)\n",
    "model21 = Activation('relu')(model21)\n",
    "model21 = Dropout(0.3)(model21)\n",
    "\n",
    "model22 = keras.layers.concatenate([cnn1d3,cnn1d4])\n",
    "model22 = Dense(int(Dense2/2),kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model22)\n",
    "model22 = BatchNormalization()(model22)\n",
    "model22 = Activation('relu')(model22)\n",
    "model22 = Dropout(0.3)(model22)\n",
    "\n",
    "model2 = keras.layers.concatenate([model21,model22])\n",
    "model2 = Dense(Dense2,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model2)\n",
    "model2 = BatchNormalization()(model2)\n",
    "model2 = Activation('relu')(model2)\n",
    "model2 = Dropout(0.3)(model2)\n",
    "\n",
    "model1 = keras.layers.concatenate([cnn2d1,cnn2d2])\n",
    "model1 = Dense(Dense1,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model1)\n",
    "model1 = Dropout(0.1)(model1)\n",
    "model1 = BatchNormalization()(model1)\n",
    "model1 = Activation('relu')(model1)\n",
    "\n",
    "model = keras.layers.concatenate([model1,model2])\n",
    "model = Dense(Dense3,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Activation('relu')(model)\n",
    "model = Dropout(0.2)(model)\n",
    "model = Dense(Dense4,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Activation('relu')(model)\n",
    "model = Dropout(0.2)(model)\n",
    "\n",
    "if Dense5>0:\n",
    "    model = Dense(Dense5,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Dropout(0.2)(model)\n",
    "\n",
    "model = Dense(2,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "interaction_output = Activation('softmax')(model)\n",
    "\n",
    "interaction = Model(inputs=[c2d1_input,c2d2_input,c1d1_input,c1d2_input,c1d3_input,c1d4_input],outputs=[interaction_output])\n",
    "\n",
    "interaction.load_weights('model_rna-rna_deep_livrable.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction des inputs et fenêtrage :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bdd : base de dimensions (l,2) à tester les deux colonnes correspondent respectivement aux deux séquences primaires d'entrée, au format string (ex : 'acgugcua' et 'auugaucgau') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test de deep_rna_rna sur les données de bdd : fenêtrage  de vitesse s=12 sur les deux séquences :\n",
    "- la fenêtre mesure 25 nucléotides (paramètre f)\n",
    "- deep rna rna prédit pour chaue couple de fenêtres si ces deux sites sont suceptibles d'interagir ensemble\n",
    "\n",
    "Le résultat est donc une matrice de taille (int((dim-f+1)/s),int((dim2-f+1)/s))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# f longueur des sites à tester sur chaque séquence\n",
    "f = 25\n",
    "# s vitesse de glissement de la fenêtre de test le long des deux séquences\n",
    "s = 12\n",
    "# facteur_seuil afin de décider quelles prédictions sont considérées comme des vraies interactions\n",
    "facteur_seuil = 0.95\n",
    "\n",
    "for r in range(len(bdd)):\n",
    "    \n",
    "    seq1 = bdd[r,0]\n",
    "    seq2 = bdd[r,1]\n",
    "    dim = len(seq1)\n",
    "    dim2 = len(seq2)\n",
    "    matrice = np.zeros((1,dim,dim2,1)) \n",
    "    matrice1 = np.zeros((1,dim,dim2,1))     \n",
    "    matrice2 = np.zeros((1,dim,4))\n",
    "    matrice3 = np.zeros((1,dim2,4))\n",
    "\n",
    "    proba1 = np.array(RNA.pfl_fold_up(seq1,1,dim,dim))[:,1]\n",
    "    proba2 = np.array(RNA.pfl_fold_up(seq2,1,dim2,dim2))[:,1]\n",
    "\n",
    "    for j in range(dim):\n",
    "        for k in range(dim2):\n",
    "            if (seq1[j]=='a' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='a'):\n",
    "                matrice[0,j,k,0] = 1\n",
    "            elif (seq1[j]=='g' and seq2[k]=='c') or (seq1[j]=='c' and seq2[k]=='g'):\n",
    "                matrice[0,j,k,0] = 1\n",
    "            elif (seq1[j]=='g' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='g'):\n",
    "                matrice[0,j,k,0] = 1\n",
    "            matrice1[0,j,k,0] = proba1[j] + proba2[k]\n",
    "    for j in range(dim):\n",
    "        if seq1[j]=='a':\n",
    "            matrice2[0,j,0] = 1\n",
    "        elif seq1[j]=='u':\n",
    "            matrice2[0,j,1] = 1\n",
    "        elif seq1[j]=='g':\n",
    "            matrice2[0,j,2] = 1\n",
    "        elif seq1[j]=='c':\n",
    "            matrice2[0,j,3] = 1\n",
    "    for j in range(dim2):\n",
    "        if seq2[j]=='a':\n",
    "            matrice3[0,j,0] = 1\n",
    "        elif seq2[j]=='u':\n",
    "            matrice3[0,j,1] = 1\n",
    "        elif seq2[j]=='g':\n",
    "            matrice3[0,j,2] = 1\n",
    "        elif seq2[j]=='c':\n",
    "            matrice3[0,j,3] = 1\n",
    "    u = int((dim-f+1)/s)\n",
    "    u2 = int((dim2-f+1)/s)\n",
    "    resultats = np.zeros((u,u2))\n",
    "\n",
    "    for i in range(u):\n",
    "        for j in range(u2):        \n",
    "            test = []\n",
    "            test.append(remplissage(matrice[:,i*s:i*s+36,j:j+36,:],f))\n",
    "            test.append(remplissage(matrice1[:,i*s:i*s+36,j:j+36,:],f))            \n",
    "            test.append(remplissage_seq(matrice2[:,i*s:i*s+36],f))\n",
    "            rev = np.zeros((1,36,4))\n",
    "            for q in range(36):\n",
    "                rev[:,36-q-1,:] = matrice2[:,q,:]\n",
    "            test.append(remplissage_seq(rev,f))\n",
    "            test.append(remplissage_seq(matrice3[:,j*s:j*s+36],f))\n",
    "            rev2 = np.zeros((1,36,4))\n",
    "            for q in range(36):\n",
    "                rev2[:,36-q-1,:] = matrice3[:,q,:]\n",
    "            test.append(remplissage_seq(rev2,f))\n",
    "\n",
    "            resultats[i,j] = interaction.predict(test)[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explication d'une prédiction par méthode de gradient class activation maps : mise en valuer de motifs pertinents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Lambda\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.framework import ops\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importation du modèle d'explication :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paramètres \n",
    "\n",
    "matrixsize11 = 6\n",
    "nbfilter11 = 24\n",
    "matrixsize12 = 7\n",
    "nbfilter12 = 4\n",
    "matrixsize21 = 6\n",
    "nbfilter21 = 24\n",
    "matrixsize22 = 7\n",
    "nbfilter22 = 4\n",
    "nbfilter1 = 64\n",
    "kernelsize = 7\n",
    "nbfilters2 = 64\n",
    "kernel_size2 = 7\n",
    "Dense1 = 128\n",
    "Dense2 = 512\n",
    "Dense3 = 512\n",
    "Dense4 = 128\n",
    "Dense5 = 0\n",
    "\n",
    "from keras.layers import merge\n",
    "from keras import Model\n",
    "k = matrixsize11\n",
    "# init_weights\n",
    "I = np.eye(k)\n",
    "M = np.diag(np.ones(k-1),1) + np.diag(np.ones(k-1),-1) + np.eye(k)\n",
    "I2 = np.zeros((k,k))\n",
    "M2 = np.zeros((k,k))\n",
    "for j in range(k):\n",
    "    I2[:,j] = I[:,k-j-1]\n",
    "    M2[:,j] = M[:,k-j-1]        \n",
    "W = np.zeros((k,k,1,nbfilter11))\n",
    "W[:,:,0,0] = I\n",
    "W[:,:,0,1] = I2\n",
    "W[:,:,0,2] = M\n",
    "W[:,:,0,3] = M2\n",
    "for j in range(4,nbfilter11):\n",
    "    W[:,:,0,j] = np.random.randn(k,k)*0.2\n",
    "\n",
    "\n",
    "k2 = matrixsize12\n",
    "I = np.eye(k2)\n",
    "M = np.diag(np.ones(k2-1),1) + np.diag(np.ones(k2-1),-1) + np.eye(k2)\n",
    "I2=np.zeros((k2,k2))\n",
    "M2=np.zeros((k2,k2))\n",
    "for j in range(k2):\n",
    "    I2[:,j] = I[:,k2-j-1]\n",
    "    M2[:,j] = M[:,k2-j-1]   \n",
    "\n",
    "Z = np.zeros((k2,k2,nbfilter11,nbfilter12))\n",
    "\n",
    "for u in range(nbfilter12):\n",
    "    Z[:,:,u,0] = I\n",
    "    Z[:,:,u,1] = I2\n",
    "    Z[:,:,u,2] = M\n",
    "    Z[:,:,u,3] = M2\n",
    "    for p in range(4,nbfilter12):\n",
    "        Z[:,:,u,p]=np.random.randn(k2,k2)*0.3            \n",
    "\n",
    "c2d1_input = keras.Input(shape=(36,36,1))\n",
    "cnn2d1 = Conv2D(filters = nbfilter11, kernel_size=(k,k), padding='valid', input_shape=(36,36,1),strides=(1,1),weights=[W,np.zeros(nbfilter11)])(c2d1_input)\n",
    "cnn2d1 = AveragePooling2D(pool_size=(3,3))(cnn2d1)\n",
    "cnn2d1 = Conv2D(filters = nbfilter12, kernel_size = (k2, k2),strides=(1,1),padding='valid',weights=[Z,np.zeros(nbfilter12)])(cnn2d1)\n",
    "cnn2d1 = Dropout(0.2)(cnn2d1)\n",
    "cnn2d1 = Flatten()(cnn2d1)\n",
    "\n",
    "c2d2_input = keras.Input(shape=(36,36,1))\n",
    "cnn2d2 = Conv2D(filters = nbfilter11, kernel_size=(k,k), padding='valid', input_shape=(36,36,1),strides=(1,1),weights=[W,np.zeros(nbfilter11)])(c2d2_input)\n",
    "cnn2d2 = AveragePooling2D(pool_size=(3,3))(cnn2d2)\n",
    "cnn2d2 = Conv2D(filters = nbfilter12, kernel_size = (k2, k2),strides=(1,1),padding='valid',weights=[Z,np.zeros(nbfilter12)])(cnn2d2)\n",
    "cnn2d2 = Dropout(0.2)(cnn2d2)\n",
    "cnn2d2 = Flatten()(cnn2d2)\n",
    "\n",
    "c1d1_input = keras.Input(shape=(36,4))\n",
    "cnn1d1 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d1_input)\n",
    "cnn1d1 = MaxPooling1D(pool_size=8)(cnn1d1)\n",
    "cnn1d1 = Dropout(0.2)(cnn1d1)\n",
    "cnn1d1 = Flatten()(cnn1d1)\n",
    "#cnn1d1 = get_cnn_network_seq(nbfilter1,kernel_size1)(c1d1_input)\n",
    "c1d2_input = keras.Input(shape=(36,4))\n",
    "cnn1d2 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d2_input)\n",
    "cnn1d2 = MaxPooling1D(pool_size=8)(cnn1d2)\n",
    "cnn1d2 = Dropout(0.2)(cnn1d2)\n",
    "cnn1d2 = Flatten()(cnn1d2)\n",
    "#cnn1d2 = get_cnn_network_seq(nbfilter1,kernel_size1)(c1d2_input)\n",
    "c1d3_input = keras.Input(shape=(36,4))\n",
    "cnn1d3 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d3_input)\n",
    "cnn1d3 = MaxPooling1D(pool_size=8)(cnn1d3)\n",
    "cnn1d3 = Dropout(0.2)(cnn1d3)\n",
    "cnn1d3 = Flatten()(cnn1d3)\n",
    "\n",
    "c1d4_input = keras.Input(shape=(36,4))\n",
    "cnn1d4 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d4_input)\n",
    "cnn1d4 = MaxPooling1D(pool_size=8)(cnn1d4)\n",
    "cnn1d4 = Dropout(0.2)(cnn1d4)\n",
    "cnn1d4 = Flatten()(cnn1d4)\n",
    "\n",
    "model21 = keras.layers.concatenate([cnn1d1,cnn1d2])\n",
    "model21 = Dense(int(Dense2/2),kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model21)\n",
    "model21 = BatchNormalization()(model21)\n",
    "model21 = Activation('relu')(model21)\n",
    "model21 = Dropout(0.3)(model21)\n",
    "\n",
    "model22 = keras.layers.concatenate([cnn1d3,cnn1d4])\n",
    "model22 = Dense(int(Dense2/2),kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model22)\n",
    "model22 = BatchNormalization()(model22)\n",
    "model22 = Activation('relu')(model22)\n",
    "model22 = Dropout(0.3)(model22)\n",
    "\n",
    "model2 = keras.layers.concatenate([model21,model22])\n",
    "model2 = Dense(Dense2,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model2)\n",
    "model2 = BatchNormalization()(model2)\n",
    "model2 = Activation('relu')(model2)\n",
    "model2 = Dropout(0.3)(model2)\n",
    "\n",
    "model1 = keras.layers.concatenate([cnn2d1,cnn2d2])\n",
    "model1 = Dense(Dense1,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model1)\n",
    "model1 = Dropout(0.1)(model1)\n",
    "model1 = BatchNormalization()(model1)\n",
    "model1 = Activation('relu')(model1)\n",
    "\n",
    "model = keras.layers.concatenate([model1,model2])\n",
    "model = Dense(Dense3,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Activation('relu')(model)\n",
    "model = Dropout(0.2)(model)\n",
    "model = Dense(Dense4,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Activation('relu')(model)\n",
    "model = Dropout(0.2)(model)\n",
    "\n",
    "if Dense5>0:\n",
    "    model = Dense(Dense5,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Dropout(0.2)(model)\n",
    "\n",
    "model = Dense(2,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "interaction_output = Activation('softmax')(model)\n",
    "interaction = Model(inputs=[c2d1_input,c2d2_input,c1d1_input,c1d2_input,c1d3_input,c1d4_input],outputs=[interaction_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonctions utiles pour l'explication "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def target_category_loss(x, category_index, nb_classes):\n",
    "    return tf.multiply(x, K.one_hot([category_index], nb_classes))\n",
    "\n",
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "\n",
    "def seq2augc(seq):\n",
    "    string = ''\n",
    "    for i in range(36):\n",
    "        if seq[i][0]==1:\n",
    "            string += 'a'\n",
    "        elif seq[i][1]==1:\n",
    "            string += 'u'\n",
    "        elif seq[i][2]==1:\n",
    "            string += 'g'\n",
    "        elif seq[i][3]==1:\n",
    "            string += 'c'\n",
    "        else:\n",
    "            a=0\n",
    "    return string\n",
    "\n",
    "def argumentsmax(argw):\n",
    "    l=[]\n",
    "    for r in argw:\n",
    "        l.append(r)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ajout d'une couche récupérant la sortie du réseau de neurones afin d'apercevoir les activations de la classe 'interaction' \n",
    "- Ajustement du modèle et chargement des poids de Deep_rna_rna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "category_index = 1\n",
    "target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "interaction_output = Lambda(target_layer, output_shape = target_category_loss_output_shape)(interaction_output)\n",
    "interaction = Model(inputs=[c2d1_input,c2d2_input,c1d1_input,c1d2_input,c1d3_input,c1d4_input],outputs=[interaction_output])\n",
    "interaction.load_weights(\"model_finaldeep.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Couches dont on étudie la sortie : couches de convolution extrayant des motifs des séquences primaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interaction.layers[4].name,interaction.layers[5].name,interaction.layers[6].name,interaction.layers[7].name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sélection des deux tronçons de séquence dont l'interaction doit être expliquée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq1 = 'aaauauagcuagucagcucguacgcaguacgucguagcgacuagcuagcuagcuaucgaucuagcauggcuacugaguca'\n",
    "seq2 = 'auuagcucagcuacggggggggacgucgaucguacgcuagcugcuagcucgcuaaucgauuagcuagcuacguacagcucguacgc'\n",
    "proba1 = [0.9, 0.5, ..., 0.8]\n",
    "proba2 = [0.7, 0.12, ..., 0.2]\n",
    "assert(len(seq1)==len(proba1))\n",
    "assert(len(seq2)==len(proba2))\n",
    "\n",
    "# pos1 : argument de la première séquence d'où débute le tronçon de 36 nucléotides à tester\n",
    "pos1 = 49\n",
    "# pos2 : argument de la deuxième séquence d'où débute le tronçon de 36 nucléotides à tester\n",
    "pos2 = 12\n",
    "\n",
    "l = 1\n",
    "matrice = np.zeros((l,36,36,1)) \n",
    "matrice1 = np.zeros((l,36,36,1))\n",
    "matrice2 = np.zeros((l,36,4))\n",
    "matrice3 = np.zeros((l,36,4))\n",
    "matrice4 = np.zeros((l,36,4))\n",
    "matrice5 = np.zeros((l,36,4))\n",
    "\n",
    "for i in range(l):\n",
    "    # sélection du tronçon 1\n",
    "    seq1 = seq1[pos1:pos1+36]\n",
    "    prob1 = proba1[pos1:pos1+36]\n",
    "    # sélection du tronçon 2\n",
    "    seq2 = seq2[pos2:pos2+36]\n",
    "    prob2 = proba2[pos2:pos2+36]\n",
    "    \n",
    "    for j in range(len(seq1)):\n",
    "        for k in range(len(seq2)):\n",
    "            if (seq1[j]=='a' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='a'):\n",
    "                matrice[i,j,k,0] = 1\n",
    "            elif (seq1[j]=='g' and seq2[k]=='c') or (seq1[j]=='c' and seq2[k]=='g'):\n",
    "                matrice[i,j,k,0] = 1\n",
    "            elif (seq1[j]=='g' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='g'):\n",
    "                matrice[i,j,k,0] = 1\n",
    "            matrice1[i,j,k,0] = prob1[j]+prob2[k]\n",
    "    for j in range(len(seq1)):\n",
    "        if seq1[j]=='a':\n",
    "            matrice2[i,j,0] = 1\n",
    "        elif seq1[j]=='u':\n",
    "            matrice2[i,j,1] = 1\n",
    "        elif seq1[j]=='g':\n",
    "            matrice2[i,j,2] = 1\n",
    "        elif seq1[j]=='c':\n",
    "            matrice2[i,j,3] = 1\n",
    "    for j in range(len(seq2)):\n",
    "        if seq2[j]=='a':\n",
    "            matrice3[i,j,0] = 1\n",
    "        elif seq2[j]=='u':\n",
    "            matrice3[i,j,1] = 1\n",
    "        elif seq2[j]=='g':\n",
    "            matrice3[i,j,2] = 1\n",
    "        elif seq2[j]=='c':\n",
    "            matrice3[i,j,3] = 1\n",
    "\n",
    "for i in range(36):\n",
    "    matrice4[:,36-i-1,:] = matrice2[:,i,:]\n",
    "for i in range(36):\n",
    "    matrice5[:,36-i-1,:] = matrice3[:,i,:]\n",
    "\n",
    "testing = []\n",
    "testing.append(matrice)\n",
    "testing.append(matrice1)\n",
    "testing.append(matrice2\n",
    "testing.append(matrice4)\n",
    "testing.append(matrice3)\n",
    "testing.append(matrice5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lancement de Gradient Class Activation Maps et affichage des motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motif1 = []\n",
    "    \n",
    "z1=0\n",
    "# couche 1 : séquence 1 à l'endroit\n",
    "layer_name = 'conv1d_1'\n",
    "# fonction de récupération de la sortie du réseau lié à la classe 'interaction'\n",
    "loss = K.sum(interaction.layers[-1].output)\n",
    "#récupération de la sortie de la couche de convolution\n",
    "conv_output = [l for l in interaction.layers if l.name == layer_name][0].output\n",
    "# calcul des gradients\n",
    "grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "gradient_function = K.function(interaction.input, [conv_output, grads])\n",
    "\n",
    "output, grads_val = gradient_function(testing)\n",
    "output, grads_val = output[0, :], grads_val[0, :, :]\n",
    "\n",
    "# calcul du lien entre la séquence observée et les poids liant les filtres à la classe 'interaction'\n",
    "\n",
    "weights = np.mean(grads_val, axis = 0)\n",
    "cam = np.ones(output.shape[0 : 1], dtype = np.float32)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    cam += w*output[:, i]\n",
    "# cam = class activation map\n",
    "\n",
    "cam = np.maximum(cam, 0)\n",
    "# heatmap : normalisation de la cam\n",
    "\n",
    "heatmap = cam / np.max(cam)\n",
    "\n",
    "# Extraction des motifs repérés dans la séquence\n",
    "\n",
    "args = argumentsmax(np.argwhere(heatmap==1)[:,0])\n",
    "if (len(args)==0):\n",
    "    z1+=1\n",
    "else:    \n",
    "    seq = seq2augc(matrice2[0])\n",
    "    for pos in argumentsmax(args):\n",
    "        motif1.append(seq[pos:pos+7])\n",
    "# Idem pour la séquence 1 à l'envers\n",
    "layer_name = 'conv1d_2'\n",
    "loss = K.sum(interaction.layers[-1].output)\n",
    "conv_output = [l for l in interaction.layers if l.name == layer_name][0].output\n",
    "grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "gradient_function = K.function(interaction.input, [conv_output, grads])\n",
    "\n",
    "output, grads_val = gradient_function(testing)\n",
    "output, grads_val = output[0, :], grads_val[0, :, :]\n",
    "\n",
    "weights = np.mean(grads_val, axis = 0)\n",
    "cam = np.ones(output.shape[0 : 1], dtype = np.float32)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    cam += w * output[:, i]\n",
    "\n",
    "cam = np.maximum(cam, 0)\n",
    "heatmap = cam / np.max(cam)\n",
    "args = argumentsmax(np.argwhere(heatmap==1)[:,0])\n",
    "if (len(args)==0):\n",
    "    z1+=1\n",
    "else:    \n",
    "    seq = seq2augc(matrice4[0])\n",
    "    for pos in argumentsmax(args):\n",
    "        motif1.append(seq[pos:pos+7])\n",
    "\n",
    "# Idem pour la séquence 2 à l'endroit\n",
    "\n",
    "motif2 = []\n",
    "\n",
    "z2=0\n",
    "layer_name = 'conv1d_3'\n",
    "loss = K.sum(interaction.layers[-1].output)\n",
    "conv_output = [l for l in interaction.layers if l.name == layer_name][0].output\n",
    "grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "gradient_function = K.function(interaction.input, [conv_output, grads])\n",
    "\n",
    "output, grads_val = gradient_function(testing)\n",
    "output, grads_val = output[0, :], grads_val[0, :, :]\n",
    "\n",
    "weights = np.mean(grads_val, axis = 0)\n",
    "cam = np.ones(output.shape[0 : 1], dtype = np.float32)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    cam += w * output[:, i]\n",
    "\n",
    "cam = np.maximum(cam, 0)\n",
    "heatmap = cam / np.max(cam)\n",
    "\n",
    "args = (np.argwhere(heatmap==1)[:,0])\n",
    "if (len(args)==0):\n",
    "    z2+=1\n",
    "else:    \n",
    "    seq = seq2augc(matrice3[0])\n",
    "    for pos in argumentsmax(args):\n",
    "        motif2.append(seq[pos:pos+7])\n",
    "\n",
    "# Idem pour la séquence 2 à l'envers\n",
    "\n",
    "layer_name = 'conv1d_4'\n",
    "loss = K.sum(interaction.layers[-1].output)\n",
    "conv_output = [l for l in interaction.layers if l.name == layer_name][0].output\n",
    "grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "gradient_function = K.function(interaction.input, [conv_output, grads])\n",
    "\n",
    "output, grads_val = gradient_function(testing)\n",
    "output, grads_val = output[0, :], grads_val[0, :, :]\n",
    "\n",
    "weights = np.mean(grads_val, axis = 0)\n",
    "cam = np.ones(output.shape[0 : 1], dtype = np.float32)\n",
    "\n",
    "for i, w in enumerate(weights):\n",
    "    cam += w * output[:, i]\n",
    "\n",
    "cam = np.maximum(cam, 0)\n",
    "heatmap = cam / np.max(cam)\n",
    "\n",
    "args = (np.argwhere(heatmap==1)[:,0])\n",
    "if (len(args)==0):\n",
    "    z2+=1\n",
    "else:    \n",
    "    seq = seq2augc(matrice5[0])\n",
    "    for pos in argumentsmax(args):\n",
    "        motif2.append(seq[pos:pos+7])\n",
    "#\n",
    "if (z1>=2 or z2>=2):\n",
    "    print('rien')\n",
    "else:\n",
    "    motifs.append([motif1,motif2])\n",
    "\n",
    "print(motifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les couples de motifs ainsi récupérés sur chaque séquence peuvent révéler des fonctions biologiques expliquant certaines interactions. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

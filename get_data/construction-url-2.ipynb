{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction de la base d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pour construire la base d'apprentissage seulement\n",
    "#from Bio import SeqIO\n",
    "#import RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformer_sequence(sequence,long):\n",
    "    nucleotides = np.zeros((4,int(max(long,25))))\n",
    "    cnt = 0\n",
    "    for lettre in sequence:\n",
    "        if lettre=='a':\n",
    "            nucleotides[0,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "        elif lettre=='c':\n",
    "            nucleotides[1,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "        elif lettre=='g':\n",
    "            nucleotides[2,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "        else:\n",
    "            nucleotides[3,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "    return nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformer_structure(structure):\n",
    "    long = len(structure)\n",
    "    a = np.zeros(25)\n",
    "    a[:long] = structure\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traduire(seq,strand):\n",
    "    nucleotides = ''\n",
    "    if strand:\n",
    "        for lettre in seq:\n",
    "            if lettre=='A':\n",
    "                nucleotides=nucleotides+'a'\n",
    "            elif lettre=='C':\n",
    "                nucleotides=nucleotides+'c'\n",
    "            elif lettre=='G':\n",
    "                nucleotides=nucleotides+'g'\n",
    "            else:\n",
    "                nucleotides=nucleotides+'u'    \n",
    "    else:\n",
    "        string = ''\n",
    "        for i in seq:\n",
    "            string = i + string\n",
    "        seq = string\n",
    "        for lettre in seq:\n",
    "            if lettre=='A':\n",
    "                nucleotides=nucleotides+'u'\n",
    "            elif lettre=='C':\n",
    "                nucleotides=nucleotides+'g'\n",
    "            elif lettre=='G':\n",
    "                nucleotides=nucleotides+'c'\n",
    "            else:\n",
    "                nucleotides=nucleotides+'a'\n",
    "    return nucleotides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération des bdd (ne pas exécuter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = SeqIO.parse(open(\"genomes/GRCh38.genome.fa\"),\"fasta\")\n",
    "dict_fasta = dict([(seq.id, seq) for seq in parser])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11473\n"
     ]
    }
   ],
   "source": [
    "# base de données rise_human_targeted\n",
    "bdd = pd.read_csv(\"rise_human_targeted.csv\", sep = \"\\t\",header=None)\n",
    "arrbdd = np.array(bdd)\n",
    "\n",
    "# Ne garder que les interactions miRNA - mRNA\n",
    "arg_mi = np.argwhere(arrbdd[:,14]=='miRNA')[:,0]\n",
    "arg_m = np.argwhere(arrbdd[:,15]=='protein_coding')[:,0]\n",
    "args = [k for k in arg_mi if k in arg_m]\n",
    "args = np.array(args)\n",
    "arrbdd = arrbdd[args]\n",
    "\n",
    "#enlever les chromosomes M\n",
    "arg_sansM = np.argwhere((arrbdd[:,0] != 'chrM') & (arrbdd[:,3] != 'chrM'))\n",
    "arrbdd = arrbdd[arg_sansM[:,0]]\n",
    "#enlever les champs vides\n",
    "arg_sansM = np.argwhere((arrbdd[:,1] != '.') & (arrbdd[:,2] != '.') & (arrbdd[:,4] != '.') & (arrbdd[:,5] != '.') & (arrbdd[:,0] != '.') & (arrbdd[:,3] != '.') & (arrbdd[:,8] != '.') & (arrbdd[:,9] != '.'))\n",
    "print(len(arg_sansM))\n",
    "varrbdd = arrbdd[arg_sansM[:,0]]\n",
    "\n",
    "\n",
    "#changement strand\n",
    "for i,el in enumerate(varrbdd[:,8]):\n",
    "    if varrbdd[i,8] == '+':\n",
    "        varrbdd[i,8] = True\n",
    "    else:\n",
    "        varrbdd[i,8] = False\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,9]):\n",
    "    if varrbdd[i,9] == '+':\n",
    "        varrbdd[i,9] = True\n",
    "    else:\n",
    "        varrbdd[i,9] = False\n",
    "\n",
    "#génération position début et fin de séquence (nucléotides)\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,1]):\n",
    "    varrbdd[i,1] = int(varrbdd[i,1])-1\n",
    "    varrbdd[i,2] = int(varrbdd[i,2])\n",
    "    milieu = int((int(varrbdd[i,4])+int(varrbdd[i,5]))/2)\n",
    "    varrbdd[i,4] = milieu-50-1\n",
    "    varrbdd[i,5] = milieu+50\n",
    "bdd = varrbdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = csv.writer(open(\"genomes/positifs.csv\", 'w',newline=''),delimiter=\"\\t\")\n",
    "    \n",
    "for i in range(len(bdd)):\n",
    "    pos = bdd[i,:4]\n",
    "    ide, begin, end = [bdd[i,0],bdd[i,1],bdd[i,2]]\n",
    "    pos[0] = traduire(dict_fasta[ide][begin:end].format(\"fasta\").split('\\n')[1],bdd[i,8])\n",
    "    ide, begin, end = [bdd[i,3],bdd[i,4],bdd[i,5]]\n",
    "    seq = dict_fasta[ide][begin:end].format(\"fasta\").split('\\n')\n",
    "    pos[1] = traduire(seq[1]+seq[2],bdd[i,9])\n",
    "    w = len(pos[0])\n",
    "    pos[2] = np.array(RNA.pfl_fold_up(pos[0],1,w,w))[1:,1]\n",
    "    pos[3] = np.array(RNA.pfl_fold_up(pos[1],1,101,101))[1:,1]\n",
    "    writer.writerow(pos)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10024\n"
     ]
    }
   ],
   "source": [
    "# base de données rise_human_targeted\n",
    "bdd = pd.read_csv(\"rise_human_targeted.csv\", sep = \"\\t\",header=None)\n",
    "arrbdd = np.array(bdd)[:16650]\n",
    "\n",
    "# Ne garder que les interactions miRNA - mRNA\n",
    "arg_mi = np.argwhere(arrbdd[:,14]=='miRNA')[:,0]\n",
    "arg_m = np.argwhere(arrbdd[:,15]=='protein_coding')[:,0]\n",
    "args = [k for k in arg_mi if k in arg_m]\n",
    "args = np.array(args)\n",
    "arrbdd = arrbdd[args]\n",
    "\n",
    "#enlever les chromosomes M\n",
    "arg_sansM = np.argwhere((arrbdd[:,0] != 'chrM') & (arrbdd[:,3] != 'chrM'))\n",
    "arrbdd = arrbdd[arg_sansM[:,0]]\n",
    "#enlever les champs vides\n",
    "arg_sansM = np.argwhere((arrbdd[:,1] != '.') & (arrbdd[:,2] != '.') & (arrbdd[:,4] != '.') & (arrbdd[:,5] != '.') & (arrbdd[:,0] != '.') & (arrbdd[:,3] != '.') & (arrbdd[:,8] != '.') & (arrbdd[:,9] != '.'))\n",
    "print(len(arg_sansM))\n",
    "varrbdd = arrbdd[arg_sansM[:,0]]\n",
    "\n",
    "\n",
    "#changement strand\n",
    "for i,el in enumerate(varrbdd[:,8]):\n",
    "    if varrbdd[i,8] == '+':\n",
    "        varrbdd[i,8] = True\n",
    "    else:\n",
    "        varrbdd[i,8] = False\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,9]):\n",
    "    if varrbdd[i,9] == '+':\n",
    "        varrbdd[i,9] = True\n",
    "    else:\n",
    "        varrbdd[i,9] = False\n",
    "\n",
    "#génération position début et fin de séquence (nucléotides)\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,1]):\n",
    "    varrbdd[i,1] = int(varrbdd[i,1])-1\n",
    "    varrbdd[i,2] = int(varrbdd[i,2])\n",
    "    milieu = int((int(varrbdd[i,4])+int(varrbdd[i,5]))/2)\n",
    "    varrbdd[i,4] = milieu-50-1\n",
    "    varrbdd[i,5] = milieu+50\n",
    "bdd = varrbdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = csv.writer(open(\"genomes/negatifs.csv\", 'w',newline=''),delimiter=\"\\t\")\n",
    "\n",
    "for i in range(len(bdd)): \n",
    "    neg = bdd[i,:4]\n",
    "    ide, begin, end = [bdd[i,0],bdd[i,1],bdd[i,2]]\n",
    "    neg[0] = traduire(dict_fasta[ide][begin:end].format(\"fasta\").split('\\n')[1],bdd[i,8])\n",
    "    ide, begin, end = bdd[i,3], bdd[i,4], bdd[i,5]\n",
    "    begin = begin+80\n",
    "    end = end+80\n",
    "    sequ = dict_fasta[ide][begin:end].format(\"fasta\").split('\\n')\n",
    "    neg[1] = traduire(sequ[1]+sequ[2],bdd[i,9])\n",
    "    w = len(neg[0])\n",
    "    neg[2] = np.array(RNA.pfl_fold_up(neg[0],1,w,w))[1:,1]\n",
    "    neg[3] = np.array(RNA.pfl_fold_up(neg[1],1,101,101))[1:,1]\n",
    "    writer.writerow(neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération et vérification des bases de données (exécuter à partir d'ici pour l'apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau de neurones basé sur iDeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/DATA/anaconda3/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Concatenate, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D,Conv1D, MaxPooling1D\n",
    "from keras.models import model_from_config\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Merge\n",
    "#from keras.optimizers import kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm, grid_search\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_curve\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals import joblib \n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import gzip\n",
    "import pdb\n",
    "from math import  sqrt\n",
    "import theano\n",
    "import subprocess as sp\n",
    "import scipy.stats as stats\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_performance(test_num, pred_y,  labels):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index in range(test_num):\n",
    "        if labels[index] ==1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp = tp +1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn = tn +1\n",
    "            else:\n",
    "                fp = fp + 1               \n",
    "            \n",
    "    acc = float(tp + tn)/test_num\n",
    "    precision = float(tp)/(tp+ fp)\n",
    "    sensitivity = float(tp)/ (tp+fn)\n",
    "    specificity = float(tn)/(tn + fp)\n",
    "    MCC = float(tp*tn-fp*fn)/(np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "    return acc, precision, sensitivity, specificity, MCC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(seq):\n",
    "    seq = seq.split('\\n')\n",
    "    seq2 = ''\n",
    "    for j in seq:\n",
    "        seq2 = seq2 + j\n",
    "    seq2 = seq2[2:len(seq2)-1]\n",
    "    seq2 = seq2.split(' ')\n",
    "    #print(seq2)\n",
    "    seq3=[]\n",
    "    for j in seq2:\n",
    "        #print(j)\n",
    "        if j=='':\n",
    "            a=0\n",
    "        else:\n",
    "            seq3.append(float(j))\n",
    "    return seq3\n",
    "\n",
    "verif = pd.read_csv(\"genomes/negatifs.csv\", sep = \"\\t\",header=None)\n",
    "verif = np.array(verif)\n",
    "for i in range(len(verif)):\n",
    "    for j in range(4):\n",
    "        if len(verif[i,j]) <= 15:\n",
    "            print(i,\"erreur\")\n",
    "            \n",
    "\n",
    "for i in range(len(verif)):\n",
    "    verif[i,2] = np.array(clean(verif[i,2]))\n",
    "    verif[i,3] = np.array(clean(verif[i,3]))    \n",
    "\n",
    "neg = verif\n",
    "\n",
    "verif = pd.read_csv(\"genomes/positifs.csv\", sep = \"\\t\",header=None)  \n",
    "verif = np.array(verif)\n",
    "for i in range(len(verif)):\n",
    "    for j in range(4):\n",
    "        if len(verif[i,j]) <= 15:\n",
    "            print(i,\"erreur\")\n",
    "            \n",
    "\n",
    "for i in range(len(verif)):\n",
    "    verif[i,2] = np.array(clean(verif[i,2]))\n",
    "    verif[i,3] = np.array(clean(verif[i,3]))\n",
    "\n",
    "pos = verif\n",
    "verif = []\n",
    "bdd = np.concatenate((pos,neg))\n",
    "pos = []\n",
    "neg = []\n",
    "labels = np.zeros((len(bdd),1))\n",
    "\n",
    "bdd = np.concatenate((bdd,labels),axis=1)\n",
    "for i in range(int(len(bdd)/2)):\n",
    "    bdd[i,4]=1    \n",
    "labels=[]\n",
    "for i in range(len(bdd)):\n",
    "    bdd[i,0] = transformer_sequence(bdd[i,0],len(bdd[i,0]))\n",
    "    bdd[i,1] = transformer_sequence(bdd[i,1],101)\n",
    "    bdd[i,2] = transformer_structure(bdd[i,2])\n",
    "\n",
    "# shuffle pour mélanger positifs et négatifs\n",
    "\n",
    "indices = np.zeros(len(bdd),dtype=int)\n",
    "for i in range(int(len(bdd)/2)):\n",
    "    indices[2*i] = int(i)\n",
    "    indices[2*i+1] = int(i + int(len(bdd)/2))\n",
    "bdd = bdd[indices]\n",
    "indices = []\n",
    "\n",
    "# shuffle total\n",
    "\n",
    "indices = np.arange(len(bdd))\n",
    "shuffle(indices)\n",
    "bdd = bdd[indices]\n",
    "\n",
    "for i in range(len(bdd)):\n",
    "    bdd[i,0] = bdd[i,0].transpose()\n",
    "    bdd[i,1] = bdd[i,1].transpose()\n",
    "\n",
    "resh0 = np.zeros((20048,25,4))\n",
    "\n",
    "for i in range(len(bdd)):\n",
    "    resh0[i,:,:] = bdd[i,0]\n",
    "    \n",
    "resh1 = np.zeros((20048,101,4))\n",
    "\n",
    "for i in range(len(bdd)):\n",
    "    resh1[i,:,:] = bdd[i,1]\n",
    "\n",
    "resh2 = np.zeros((20048,25))\n",
    "\n",
    "for i in range(len(bdd)):\n",
    "    resh2[i,:] = bdd[i,2]\n",
    "    \n",
    "resh3 = np.zeros((20048,101))\n",
    "\n",
    "for i in range(len(bdd)):\n",
    "    resh3[i,:] = bdd[i,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_train = 17000\n",
    "nb_val = 500\n",
    "nb_test = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resh0_train = resh0[:nb_train]\n",
    "resh0_val = resh0[nb_train:nb_train+nb_val]\n",
    "resh1_train = resh1[:nb_train]\n",
    "resh1_val = resh1[nb_train:nb_train+nb_val]\n",
    "resh2_train = resh2[:nb_train]\n",
    "resh2_val = resh2[nb_train:nb_train+nb_val]\n",
    "resh3_train = resh3[:nb_train]\n",
    "resh3_val = resh3[nb_train:nb_train+nb_val]\n",
    "resh0_test = resh0[-nb_test:]\n",
    "resh1_test = resh1[-nb_test:]\n",
    "resh2_test = resh2[-nb_test:]\n",
    "resh3_test = resh3[-nb_test:]\n",
    "resh0=[]\n",
    "resh1=[]\n",
    "resh2=[]\n",
    "resh3=[]\n",
    "train = bdd[:nb_train]\n",
    "valid = bdd[nb_train:nb_train+nb_val]\n",
    "y = train[:,4]\n",
    "y = keras.utils.np_utils.to_categorical(y,2)\n",
    "val_y = valid[:,4]\n",
    "val_y = keras.utils.np_utils.to_categorical(val_y,2)\n",
    "train=[]\n",
    "valid=[]\n",
    "test = bdd[-nb_test:]\n",
    "bdd = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_networks_train_predict():\n",
    "    \n",
    "    print('training', nb_train)\n",
    "    \n",
    "    micro_structure_hid = 64\n",
    "    messenger_structure_hid = 128\n",
    "    micro_seq_hid = 22\n",
    "    messenger_seq_hid = 100\n",
    "    \n",
    "    micro_seq_train = resh0_train\n",
    "    micro_seq_validation = resh0_val\n",
    "    micro_seq_net =  get_cnn_network_microRNA()\n",
    "    \n",
    "    messenger_seq_train = resh1_train\n",
    "    messenger_seq_validation = resh1_val\n",
    "    messenger_seq_net = get_cnn_network_messengerRNA()\n",
    "    \n",
    "    micro_structure_train = resh2_train\n",
    "    micro_structure_validation = resh2_val\n",
    "    micro_structure_net = get_mlp_microRNA()\n",
    "    \n",
    "    messenger_structure_train = resh3_train\n",
    "    messenger_structure_validation = resh3_val\n",
    "    messenger_structure_net = get_mlp_messengerRNA()        \n",
    "    \n",
    "    #y, encoder = preprocess_labels(training_label)\n",
    "    #val_y, encoder = preprocess_labels(validation_label, encoder = encoder)\n",
    "       \n",
    "    \n",
    "    #model = Sequential()\n",
    "    training_net=[]\n",
    "    training = []\n",
    "    validation = []\n",
    "    total_hid = 0\n",
    "    \n",
    "    training_net.append(micro_seq_net)\n",
    "    training.append(micro_seq_train)\n",
    "    validation.append(micro_seq_validation)\n",
    "    total_hid = total_hid + micro_seq_hid\n",
    "    micro_seq_train = []\n",
    "    micro_seq_validation = [] \n",
    "    \n",
    "    training_net.append(messenger_seq_net)\n",
    "    training.append(messenger_seq_train)\n",
    "    validation.append(messenger_seq_validation)\n",
    "    total_hid = total_hid + messenger_seq_hid\n",
    "    messenger_seq_train = []\n",
    "    messenger_seq_validation = []\n",
    "    \n",
    "    training_net.append(micro_structure_net)\n",
    "    training.append(micro_structure_train)\n",
    "    validation.append(micro_structure_validation)\n",
    "    total_hid = total_hid + micro_structure_hid\n",
    "    micro_structure_train = []\n",
    "    micro_structure_validation = []\n",
    "    \n",
    "    training_net.append(messenger_structure_net)\n",
    "    training.append(messenger_structure_train)\n",
    "    validation.append(messenger_structure_validation)\n",
    "    total_hid = total_hid + messenger_structure_hid\n",
    "    messenger_structure_train = []\n",
    "    messenger_structure_validation = []\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Merge(training_net, mode='concat'))\n",
    " \n",
    "    #model.add(Dense(total_hid, input_shape=(total_hid,)))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(PReLU())\n",
    "    #model.add(BatchNormalization(mode=2))\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    print(total_hid)\n",
    "    model.add(Dense(2, input_shape=(total_hid,)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    #sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    \n",
    "    #checkpointer = ModelCheckpoint(filepath=\"models/bestmodel.hdf5\", verbose=0, save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "    #validation_data=(np.transpose(validmat['validxdata'],axes=(0,2,1)), validmat['validdata']), callbacks=[checkpointer,earlystopper]\n",
    "    print('model training')\n",
    "    model.fit(training, y, batch_size=10000, epochs=1000, verbose=0, validation_data=(validation, val_y), callbacks=[earlystopper])\n",
    "    \n",
    "    training = []\n",
    "    validation = []\n",
    "    \n",
    "    # test\n",
    "    true_y = test[:,4]\n",
    "    \n",
    "    print('predicting')\n",
    "    testing = []\n",
    "    testing.append(resh0_test)\n",
    "    testing.append(resh1_test)\n",
    "    testing.append(resh2_test)\n",
    "    testing.append(resh3_test)\n",
    "        \n",
    "    predictions = model.predict_proba(testing)[:,1]\n",
    "    print(predictions)\n",
    "    for i,nulll in enumerate(predictions):\n",
    "        predictions[i] = round(predictions[i])\n",
    "    print(predictions,true_y)\n",
    "    perfs = calculate_performance(len(predictions), predictions, true_y)\n",
    "    print(\"acc : \", perfs[0])\n",
    "    print(\"precision : \", perfs[1])\n",
    "    print(\"sensitivity : \", perfs[2])\n",
    "    print(\"specificity : \", perfs[3])\n",
    "    print(\"MCC : \", perfs[4])\n",
    "\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training 17000\n",
      "configure cnn network\n",
      "configure cnn network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/DATA/anaconda3/envs/keras/lib/python3.6/site-packages/ipykernel_launcher.py:65: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "314\n",
      "model training\n",
      "predicting\n",
      "[0.44264212 0.5621759  0.5483066  ... 0.6002486  0.54963225 0.56503737]\n",
      "[0. 1. 1. ... 1. 1. 1.] [0.0 0.0 1 ... 1 1 1]\n",
      "acc :  0.5564\n",
      "precision :  0.5346628679962013\n",
      "sensitivity :  0.8972111553784861\n",
      "specificity :  0.21285140562248997\n",
      "MCC :  0.15103195995226454\n"
     ]
    }
   ],
   "source": [
    "m = merge_networks_train_predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 100 trains : \n",
    "acc :  0.5\n",
    "precision :  0.5333333333333333\n",
    "sensitivity :  0.7272727272727273\n",
    "specificity :  0.2222222222222222\n",
    "MCC :  -0.058025885318565944\n",
    "\n",
    "##### 17000 trains\n",
    "acc :  0.5964\n",
    "precision :  0.6069017254313578\n",
    "sensitivity :  0.625193199381762\n",
    "specificity :  0.5655058043117744\n",
    "MCC :  0.19100235122777048\n",
    "##### \n",
    "acc :  0.5564\n",
    "precision :  0.5346628679962013\n",
    "sensitivity :  0.8972111553784861\n",
    "specificity :  0.21285140562248997\n",
    "MCC :  0.15103195995226454\n",
    "(10000 batch et 1000 epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_network_microRNA():    \n",
    "    print('configure cnn network')\n",
    "    nbfilter = 22\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(activation=\"relu\", input_shape=(25, 4), filters=22, kernel_size=7, strides=1, padding=\"valid\"))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(nbfilter, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(PReLU())\n",
    "    #model.add(BatchNormalization(mode=2))\n",
    "    #model.add(Dense(64))\n",
    " \n",
    "    #model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_cnn_network_messengerRNA():    \n",
    "    print('configure cnn network')\n",
    "    nbfilter = 100\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(activation=\"relu\", input_shape=(101, 4), filters=100, kernel_size=7, strides=1, padding=\"valid\"))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #model.add(Dense(nbfilter, activation='relu'))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(PReLU())\n",
    "    #model.add(BatchNormalization(mode=2))\n",
    "    #model.add(Dense(64))    \n",
    "    \n",
    "    #model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn2D():\n",
    "    nb_conv = 4\n",
    "    nb_pool = 2\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (nb_conv, nb_conv), padding='valid', input_shape=(1, 101,4),strides=(1,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mlp_microRNA(num_hidden = 64):\n",
    "    model = Sequential()\n",
    "\n",
    "    #model.add(Dense(num_hidden, input_dim=train.shape[1], activation='relu'))\n",
    "    model.add(Dense(num_hidden, input_shape=(25,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(num_hidden, input_dim=num_hidden, activation='relu'))\n",
    "    #model.add(Dense(num_hidden, input_shape=(num_hidden,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    '''\n",
    "    model.add(Dense(sec_num_hidden, input_shape=(num_hidden,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    '''\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mlp_messengerRNA(num_hidden = 128):\n",
    "    model = Sequential()\n",
    "\n",
    "    #model.add(Dense(num_hidden, input_dim=train.shape[1], activation='relu'))\n",
    "    model.add(Dense(num_hidden, input_shape=(101,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_hidden, input_dim=num_hidden, activation='relu'))\n",
    "    #model.add(Dense(num_hidden, input_shape=(num_hidden,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    '''\n",
    "    model.add(Dense(sec_num_hidden, input_shape=(num_hidden,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    '''\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARCHIVES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération rapide des séquences à partir de chr_nb start end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download genome at ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_24/GRCh38.primary_assembly.genome.fa.gz\n",
    "\n",
    "parser = SeqIO.parse(open(\"genomes/GRCh38.genome.fa\"),\"fasta\")\n",
    "\n",
    "dict_fasta = dict([(seq.id, seq) for seq in parser])\n",
    "\n",
    "ide, begin, end = ['chr17',8222876,8222895]\n",
    "\n",
    "dict_fasta[ide][begin:end].format(\"fasta\").split('\\n')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A partir de là c'est l'ancienne méthode (à conserver au cas où, archive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On  sauvegarde la base de données dans un fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()\n",
    "import csv\n",
    "\n",
    "writer = csv.writer(open(\"genomes/database.csv\", 'w',newline=''),delimiter=\"\\t\")\n",
    "for i,el in enumerate(varrbdd):\n",
    "    row = transformer_database2(varrbdd[i])    \n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche les trous dans les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdd_5000_trouee = pd.read_csv(\"genomes/database.csv\", sep = \"\\t\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4983"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdd_5000_trouee = np.array(bdd_5000_trouee)\n",
    "l = []\n",
    "for i,el in enumerate(bdd_5000_trouee):\n",
    "    if type(bdd_5000_trouee[i,0])==float or type(bdd_5000_trouee[i,1])==float:\n",
    "        a=0\n",
    "    elif len(bdd_5000_trouee[i,0])==0 or len(bdd_5000_trouee[i,0])==0:\n",
    "        a=0\n",
    "    else:\n",
    "        l.append(i)\n",
    "l = np.array(l)\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdd_miRNA_mRNA = bdd_5000_trouee[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdd_miRNA_mRNA = nettoyer(bdd_miRNA_mRNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdd_miRNA_mRNA = traduire_séquences(bdd_miRNA_mRNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdd_apprentissage = construire_seq_et_structure_bdd(bdd_miRNA_mRNA[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A partir de mainenant, on essaye d'obtenir les probabilités d'accesibilité de chaque nucléotide sur une séquence quelconque ARN par exemple 'ACGUUGUCACACGAU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traduire_test(seq,strand):\n",
    "    nucleotides = ''\n",
    "    if strand:\n",
    "        string = ''\n",
    "        for i in seq:\n",
    "            string = i + string\n",
    "        seq = string\n",
    "        for lettre in seq:\n",
    "            if lettre=='a':\n",
    "                nucleotides=nucleotides+'u'\n",
    "            elif lettre=='c':\n",
    "                nucleotides=nucleotides+'g'\n",
    "            elif lettre=='g':\n",
    "                nucleotides=nucleotides+'c'\n",
    "            else:\n",
    "                nucleotides=nucleotides+'a'\n",
    "    else:\n",
    "        for lettre in seq:\n",
    "            if lettre=='a':\n",
    "                nucleotides=nucleotides+'a'\n",
    "            elif lettre=='c':\n",
    "                nucleotides=nucleotides+'c'\n",
    "            elif lettre=='g':\n",
    "                nucleotides=nucleotides+'g'\n",
    "            else:\n",
    "                nucleotides=nucleotides+'u'    \n",
    "    return nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cacuacagcaagccuggcacgaccucuaaggcgguucgcggcaacguccgcacgucggcucguuggucuagggguaugauucucgcuucgggugcgagaggucccggguucaaaucccggacgagcccuccuuuaccuuuuacugagacaagagugucuuc'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traduire_test('gaagacactcttgtctcagtaaaaggtaaaggagggctcgtccgggatttgaacccgggacctctcgcacccgaagcgagaatcatacccctagaccaacgagccgacgtgcggacgttgccgcgaaccgccttagaggtcgtgccaggcttgctgtagtg',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'gaagacactcttgtctcagtaaaaggtaaaggagggctcgtccgggatttgaacccgggacctctcgcacccgaagcgagaatcatacccctagaccaacgagccgacgtgcggacgttgccgcgaaccgccttagaggtcgtgccaggcttgctgtagtg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/DATA/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "bdd = pd.read_csv(\"rise_human_transcriptome (copie).csv\", sep = \"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bdd convertie panda -> numpy array et seuls les 70 000 premiers RRIs retenus\n",
    "arrbdd = np.array(bdd)[:70000]\n",
    "\n",
    "#enlever 'chr' et formater les numéros de chromosomes\n",
    "for i,el in enumerate(arrbdd[:,0]):\n",
    "    arrbdd[i,0] = arrbdd[i,0][3:]\n",
    "\n",
    "for i,el in enumerate(arrbdd[:,0]):\n",
    "    if arrbdd[i,0] == 'X':\n",
    "        arrbdd[i,0] = '23'\n",
    "    if arrbdd[i,0] == 'Y':\n",
    "        arrbdd[i,0] = '24'\n",
    "    if arrbdd[i,0] == '1':\n",
    "        arrbdd[i,0] = '01'\n",
    "    if arrbdd[i,0] == '2':\n",
    "        arrbdd[i,0] = '02'\n",
    "    if arrbdd[i,0] == '3':\n",
    "        arrbdd[i,0] = '03'\n",
    "    if arrbdd[i,0] == '4':\n",
    "        arrbdd[i,0] = '04'\n",
    "    if arrbdd[i,0] == '5':\n",
    "        arrbdd[i,0] = '05'\n",
    "    if arrbdd[i,0] == '6':\n",
    "        arrbdd[i,0] = '06'\n",
    "    if arrbdd[i,0] == '7':\n",
    "        arrbdd[i,0] = '07'\n",
    "    if arrbdd[i,0] == '8':\n",
    "        arrbdd[i,0] = '08'\n",
    "    if arrbdd[i,0] == '9':\n",
    "        arrbdd[i,0] = '09'\n",
    "\n",
    "for i,el in enumerate(arrbdd[:,3]):\n",
    "    arrbdd[i,3] = arrbdd[i,3][3:]\n",
    "\n",
    "for i,el in enumerate(arrbdd[:,3]):\n",
    "    if arrbdd[i,3] == 'X':\n",
    "        arrbdd[i,3] = '23'\n",
    "    elif arrbdd[i,3] == 'Y':\n",
    "        arrbdd[i,3] = '24'  \n",
    "    elif arrbdd[i,3] == '1':\n",
    "        arrbdd[i,3] = '01'\n",
    "    elif arrbdd[i,3] == '2':\n",
    "        arrbdd[i,3] = '02'\n",
    "    elif arrbdd[i,3] == '3':\n",
    "        arrbdd[i,3] = '03'\n",
    "    elif arrbdd[i,3] == '4':\n",
    "        arrbdd[i,3] = '04'\n",
    "    elif arrbdd[i,3] == '5':\n",
    "        arrbdd[i,3] = '05'\n",
    "    elif arrbdd[i,3] == '6':\n",
    "        arrbdd[i,3] = '06'\n",
    "    elif arrbdd[i,3] == '7':\n",
    "        arrbdd[i,3] = '07'\n",
    "    elif arrbdd[i,3] == '8':\n",
    "        arrbdd[i,3] = '08'\n",
    "    elif arrbdd[i,3] == '9':\n",
    "        arrbdd[i,3] = '09'\n",
    "\n",
    "\n",
    "#enlever les chromosomes M\n",
    "arg_sansM = np.argwhere((arrbdd[:,0] != 'M') & (arrbdd[:,3] != 'M'))\n",
    "varrbdd = arrbdd[arg_sansM[:,0]]\n",
    "\n",
    "#changement strand\n",
    "for i,el in enumerate(varrbdd[:,8]):\n",
    "    if varrbdd[i,8] == '+':\n",
    "        varrbdd[i,8] = 'true'\n",
    "    else:\n",
    "        varrbdd[i,8] = 'false'\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,9]):\n",
    "    if varrbdd[i,9] == '+':\n",
    "        varrbdd[i,9] = 'true'\n",
    "    else:\n",
    "        varrbdd[i,9] = 'false'\n",
    "\n",
    "\n",
    "#int str\n",
    "for i,el in enumerate(varrbdd[:,1]):\n",
    "    if type(el) == int:\n",
    "        varrbdd[i,1] = str(el)\n",
    "for i,el in enumerate(varrbdd[:,2]):\n",
    "    if type(el) == int:\n",
    "        varrbdd[i,2] = str(el)\n",
    "for i,el in enumerate(varrbdd[:,4]):\n",
    "    if type(el) == int:\n",
    "        varrbdd[i,4] = str(el)\n",
    "for i,el in enumerate(varrbdd[:,5]):\n",
    "    if type(el) == int:\n",
    "        varrbdd[i,5] = str(el)\n",
    "\n",
    "#génération position début et fin de séquence (nucléotides)\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,1]):\n",
    "    milieu = int((int(varrbdd[i,1])+int(varrbdd[i,2]))/2)\n",
    "    varrbdd[i,1] = str(milieu-50)\n",
    "    varrbdd[i,2] = str(milieu+50)\n",
    "    milieu = int((int(varrbdd[i,4])+int(varrbdd[i,5]))/2)\n",
    "    varrbdd[i,4] = str(milieu-50)\n",
    "    varrbdd[i,5] = str(milieu+50)\n",
    "\n",
    "# Génération URLs\n",
    "\n",
    "#for i,el in enumerate(varrbdd[:,6]):\n",
    " #   varrbdd[i,6] = \"https://www.ncbi.nlm.nih.gov/nuccore/NC_0000\"+varrbdd[i,0]+\"?report=genbank&from=\"+varrbdd[i,1]+\"&to=\"+varrbdd[i,2]+\"&strand=\"+varrbdd[i,8]+\".html\"\n",
    "#for i,el in enumerate(varrbdd[:,6]):\n",
    " #   varrbdd[i,6] = 'https://www.ncbi.nlm.nih.gov/nuccore/NC_0000'+varrbdd[i,0]+'?report=fasta&log$=seqview&format=text&from='+varrbdd[i,1]+'&to='+varrbdd[i,2]\n",
    "\n",
    "#for i,el in enumerate(varrbdd[:,7]):\n",
    " #   varrbdd[i,7] = \"https://www.ncbi.nlm.nih.gov/nuccore/NC_0000\"+varrbdd[i,3]+\"?report=genbank&from=\"+varrbdd[i,4]+\"&to=\"+varrbdd[i,5]+\"&strand=\"+varrbdd[i,9]+\".html\"\n",
    "#for i,el in enumerate(varrbdd[:,7]):\n",
    " #   varrbdd[i,7] = 'https://www.ncbi.nlm.nih.gov/nuccore/NC_0000'+varrbdd[i,3]+'?report=fasta&log$=seqview&format=text&from='+varrbdd[i,4]+'&to='+varrbdd[i,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recuperer_sequence(url):\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(url)\n",
    "    time.sleep(4)\n",
    "    innerHTML = browser.execute_script(\"return document.body.innerHTML\")\n",
    "    browser.quit()\n",
    "    soup = BeautifulSoup(innerHTML,\"lxml\")\n",
    "    seq = soup.find_all(\"span\",{'class':\"ff_line\"})\n",
    "    rep = seq[0].text+seq[1].text+seq[2].text+seq[3].text\n",
    "    rep = ''.join(rep.split())\n",
    "    return rep\n",
    "\n",
    "def recuperer_sequence2(url):\n",
    "    browser.get(url)\n",
    "    time.sleep(1.3)\n",
    "    innerHTML = browser.execute_script(\"return document.body.innerHTML\")\n",
    "    soup = BeautifulSoup(innerHTML,\"lxml\")\n",
    "    seq = soup.find_all(\"div\",{'class':\"seq gbff\"})\n",
    "    rep = seq[0].text   \n",
    "    return rep\n",
    "\n",
    "def transformer_database(bddrow):\n",
    "    sequence=recuperer_sequence(bddrow[6])\n",
    "    sequence=transformer_sequence(sequence,len(sequence))\n",
    "    sequencebis=recuperer_sequence(bddrow[7])\n",
    "    sequencebis=transformer_sequence(sequencebis,len(sequencebis))    \n",
    "    bddrow = np.array([bddrow[18],bddrow[19],bddrow[20],bddrow[21],sequence,bddrow[0],bddrow[1],bddrow[2],bddrow[8],bddrow[10],bddrow[11],bddrow[14],bddrow[16],sequencebis,bddrow[3],bddrow[4],bddrow[5],bddrow[9],bddrow[12],bddrow[13],bddrow[15],bddrow[17]], dtype=object)\n",
    "    return bddrow\n",
    "\n",
    "def transformer_database2(bddrow):\n",
    "    sequence=recuperer_sequence2(bddrow[6])\n",
    "    sequencebis=recuperer_sequence2(bddrow[7])\n",
    "    bddrow = np.array([sequence,sequencebis,bddrow[8],bddrow[9]], dtype=object)\n",
    "    return bddrow\n",
    "\n",
    "def construire_seq_et_structure_bdd(bdd):\n",
    "    for i,el in enumerate(bdd):\n",
    "        bdd[i,2] = np.array(RNA.pfl_fold_up(bdd[i,0],1,201,201))[1:,1]\n",
    "        bdd[i,3] = np.array(RNA.pfl_fold_up(bdd[i,1],1,201,201))[1:,1]\n",
    "        #bdd[i,0] = transformer_sequence(bdd[i,0],201)\n",
    "        #bdd[i,1] = transformer_sequence(bdd[i,1],201)\n",
    "    return bdd\n",
    "\n",
    "def nettoyer(bdd):\n",
    "    for i,el in enumerate(bdd):\n",
    "        bdd[i,0]=bdd[i,0].split('\\n')[1]+bdd[i,0].split('\\n')[2]+bdd[i,0].split('\\n')[3]\n",
    "        bdd[i,1]=bdd[i,1].split('\\n')[1]+bdd[i,1].split('\\n')[2]+bdd[i,1].split('\\n')[3]\n",
    "    return bdd\n",
    "\n",
    "def traduire_séquences(bdd):\n",
    "    for i,el in enumerate(bdd):\n",
    "        bdd[i,0]=traduire(bdd[i,0],bdd[i,2])\n",
    "        bdd[i,1]=traduire(bdd[i,1],bdd[i,3])\n",
    "    return bdd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

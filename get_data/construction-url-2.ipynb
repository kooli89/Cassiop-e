{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Construction de la base d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pour construire la base d'apprentissage seulement\n",
    "from Bio import SeqIO\n",
    "import RNA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transformer_sequence(sequence,long):\n",
    "    nucleotides = np.zeros((4,long))\n",
    "    cnt = 0\n",
    "    for lettre in sequence:\n",
    "        if lettre=='a':\n",
    "            nucleotides[0,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "        elif lettre=='c':\n",
    "            nucleotides[1,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "        elif lettre=='g':\n",
    "            nucleotides[2,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "        else:\n",
    "            nucleotides[3,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "    return nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traduire(seq,strand):\n",
    "    nucleotides = ''\n",
    "    if strand:\n",
    "        for lettre in seq:\n",
    "            if lettre=='A':\n",
    "                nucleotides=nucleotides+'a'\n",
    "            elif lettre=='C':\n",
    "                nucleotides=nucleotides+'c'\n",
    "            elif lettre=='G':\n",
    "                nucleotides=nucleotides+'g'\n",
    "            else:\n",
    "                nucleotides=nucleotides+'u'    \n",
    "    else:\n",
    "        string = ''\n",
    "        for i in seq:\n",
    "            string = i + string\n",
    "        seq = string\n",
    "        for lettre in seq:\n",
    "            if lettre=='A':\n",
    "                nucleotides=nucleotides+'u'\n",
    "            elif lettre=='C':\n",
    "                nucleotides=nucleotides+'g'\n",
    "            elif lettre=='G':\n",
    "                nucleotides=nucleotides+'c'\n",
    "            else:\n",
    "                nucleotides=nucleotides+'a'\n",
    "    return nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parser = SeqIO.parse(open(\"genomes/GRCh38.genome.fa\"),\"fasta\")\n",
    "dict_fasta = dict([(seq.id, seq) for seq in parser])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10024\n"
     ]
    }
   ],
   "source": [
    "# base de données rise_human_targeted\n",
    "bdd = pd.read_csv(\"rise_human_targeted.csv\", sep = \"\\t\",header=None)\n",
    "arrbdd = np.array(bdd)[:16650]\n",
    "\n",
    "# Ne garder que les interactions miRNA - mRNA\n",
    "arg_mi = np.argwhere(arrbdd[:,14]=='miRNA')[:,0]\n",
    "arg_m = np.argwhere(arrbdd[:,15]=='protein_coding')[:,0]\n",
    "args = [k for k in arg_mi if k in arg_m]\n",
    "args = np.array(args)\n",
    "arrbdd = arrbdd[args]\n",
    "\n",
    "#enlever les chromosomes M\n",
    "arg_sansM = np.argwhere((arrbdd[:,0] != 'chrM') & (arrbdd[:,3] != 'chrM'))\n",
    "arrbdd = arrbdd[arg_sansM[:,0]]\n",
    "#enlever les champs vides\n",
    "arg_sansM = np.argwhere((arrbdd[:,1] != '.') & (arrbdd[:,2] != '.') & (arrbdd[:,4] != '.') & (arrbdd[:,5] != '.') & (arrbdd[:,0] != '.') & (arrbdd[:,3] != '.') & (arrbdd[:,8] != '.') & (arrbdd[:,9] != '.'))\n",
    "print(len(arg_sansM))\n",
    "varrbdd = arrbdd[arg_sansM[:,0]]\n",
    "\n",
    "\n",
    "#changement strand\n",
    "for i,el in enumerate(varrbdd[:,8]):\n",
    "    if varrbdd[i,8] == '+':\n",
    "        varrbdd[i,8] = True\n",
    "    else:\n",
    "        varrbdd[i,8] = False\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,9]):\n",
    "    if varrbdd[i,9] == '+':\n",
    "        varrbdd[i,9] = True\n",
    "    else:\n",
    "        varrbdd[i,9] = False\n",
    "\n",
    "#génération position début et fin de séquence (nucléotides)\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,1]):\n",
    "    varrbdd[i,1] = int(varrbdd[i,1])-1\n",
    "    varrbdd[i,2] = int(varrbdd[i,2])\n",
    "    milieu = int((int(varrbdd[i,4])+int(varrbdd[i,5]))/2)\n",
    "    varrbdd[i,4] = milieu-50-1\n",
    "    varrbdd[i,5] = milieu+50\n",
    "bdd = varrbdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = csv.writer(open(\"genomes/positifs.csv\", 'w',newline=''),delimiter=\"\\t\")\n",
    "    \n",
    "for i in range(len(bdd)):\n",
    "    pos = bdd[i,:4]\n",
    "    ide, begin, end = [bdd[i,0],bdd[i,1],bdd[i,2]]\n",
    "    pos[0] = traduire(dict_fasta[ide][begin:end].format(\"fasta\").split('\\n')[1],bdd[i,8])\n",
    "    ide, begin, end = [bdd[i,3],bdd[i,4],bdd[i,5]]\n",
    "    seq = dict_fasta[ide][begin:end].format(\"fasta\").split('\\n')\n",
    "    pos[1] = traduire(seq[1]+seq[2],bdd[i,9])\n",
    "    w = len(pos[0])\n",
    "    pos[2] = np.array(RNA.pfl_fold_up(pos[0],1,w,w))[1:,1]\n",
    "    pos[3] = np.array(RNA.pfl_fold_up(pos[1],1,101,101))[1:,1]\n",
    "    writer.writerow(pos)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10024\n"
     ]
    }
   ],
   "source": [
    "# base de données rise_human_targeted\n",
    "bdd = pd.read_csv(\"rise_human_targeted.csv\", sep = \"\\t\",header=None)\n",
    "arrbdd = np.array(bdd)[:16650]\n",
    "\n",
    "# Ne garder que les interactions miRNA - mRNA\n",
    "arg_mi = np.argwhere(arrbdd[:,14]=='miRNA')[:,0]\n",
    "arg_m = np.argwhere(arrbdd[:,15]=='protein_coding')[:,0]\n",
    "args = [k for k in arg_mi if k in arg_m]\n",
    "args = np.array(args)\n",
    "arrbdd = arrbdd[args]\n",
    "\n",
    "#enlever les chromosomes M\n",
    "arg_sansM = np.argwhere((arrbdd[:,0] != 'chrM') & (arrbdd[:,3] != 'chrM'))\n",
    "arrbdd = arrbdd[arg_sansM[:,0]]\n",
    "#enlever les champs vides\n",
    "arg_sansM = np.argwhere((arrbdd[:,1] != '.') & (arrbdd[:,2] != '.') & (arrbdd[:,4] != '.') & (arrbdd[:,5] != '.') & (arrbdd[:,0] != '.') & (arrbdd[:,3] != '.') & (arrbdd[:,8] != '.') & (arrbdd[:,9] != '.'))\n",
    "print(len(arg_sansM))\n",
    "varrbdd = arrbdd[arg_sansM[:,0]]\n",
    "\n",
    "\n",
    "#changement strand\n",
    "for i,el in enumerate(varrbdd[:,8]):\n",
    "    if varrbdd[i,8] == '+':\n",
    "        varrbdd[i,8] = True\n",
    "    else:\n",
    "        varrbdd[i,8] = False\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,9]):\n",
    "    if varrbdd[i,9] == '+':\n",
    "        varrbdd[i,9] = True\n",
    "    else:\n",
    "        varrbdd[i,9] = False\n",
    "\n",
    "#génération position début et fin de séquence (nucléotides)\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,1]):\n",
    "    varrbdd[i,1] = int(varrbdd[i,1])-1\n",
    "    varrbdd[i,2] = int(varrbdd[i,2])\n",
    "    milieu = int((int(varrbdd[i,4])+int(varrbdd[i,5]))/2)\n",
    "    varrbdd[i,4] = milieu-50-1\n",
    "    varrbdd[i,5] = milieu+50\n",
    "bdd = varrbdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "writer = csv.writer(open(\"genomes/negatifs.csv\", 'w',newline=''),delimiter=\"\\t\")\n",
    "\n",
    "for i in range(len(bdd)): \n",
    "    neg = bdd[i,:4]\n",
    "    ide, begin, end = [bdd[i,0],bdd[i,1],bdd[i,2]]\n",
    "    neg[0] = traduire(dict_fasta[ide][begin:end].format(\"fasta\").split('\\n')[1],bdd[i,8])\n",
    "    ide, begin, end = bdd[i,3], bdd[i,4], bdd[i,5]\n",
    "    begin = begin+80\n",
    "    end = end+80\n",
    "    sequ = dict_fasta[ide][begin:end].format(\"fasta\").split('\\n')\n",
    "    neg[1] = traduire(sequ[1]+sequ[2],bdd[i,9])\n",
    "    w = len(neg[0])\n",
    "    neg[2] = np.array(RNA.pfl_fold_up(neg[0],1,w,w))[1:,1]\n",
    "    neg[3] = np.array(RNA.pfl_fold_up(neg[1],1,101,101))[1:,1]\n",
    "    writer.writerow(neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération et vérification des bases de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([0.75247835, 0.62687611, 0.4064086, 0.29321916, 0.30684459, 0.62212081, 0.65814599, 0.94280037, 0.90369972, 0.88273396, 0.97805859, 0.81492998, 0.80743019, 0.70509516, 0.81725737, 0.65741904, 0.56824192, 0.58559265, 0.60675931, 0.59992604, 0.94614898, 0.80518961, 0.95394779]),\n",
       "       list([0.53508958, 0.52802268, 0.18018329, 0.19089549, 0.25869744, 0.19186406, 0.2002014, 0.2186135, 0.71730343, 0.71202333, 0.55948361, 0.67560936, 0.64722184, 0.64337215, 0.37448709, 0.39657868, 0.61546366, 0.54977241, 0.17184944, 0.06457585, 0.0421673, 0.52450281, 0.76204176, 0.93660894, 0.90328314, 0.41512492, 0.26891803, 0.12032854, 0.22452976, 0.92798199, 0.73548635, 0.64159228, 0.24752479, 0.0743875, 0.17827516, 0.23989725, 0.47072754, 0.43771495, 0.39959753, 0.9247684, 0.58483969, 0.53661715, 0.60304792, 0.38145832, 0.59856157, 0.61861123, 0.11636075, 0.00670025, 0.00436371, 0.00674381, 0.00949024, 0.03531312, 0.98513546, 0.09686335, 0.03402785, 0.43056721, 0.94144578, 0.84407512, 0.94011952, 0.19858307, 0.08435996, 0.07163487, 0.05199596, 0.15014502, 0.94737384, 0.91666376, 0.51656909, 0.13197016, 0.03866276, 0.08177891, 0.01289258, 0.00786901, 0.89020732, 0.92354599, 0.98262173, 0.9955203, 0.99441186, 0.99081461, 0.97834847, 0.97546692, 0.08839712, 0.08073295, 0.07752944, 0.19720105, 0.28508114, 0.62409881, 0.60617348, 0.94230966, 0.96679743, 0.95352063, 0.13693581, 0.0708633, 0.08909084, 0.11487529, 0.20666685, 0.93426194, 0.84308346, 0.91048905, 0.41878099, 0.44682406, 0.46060587])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(seq):\n",
    "    seq = seq.split('\\n')\n",
    "    seq2 = ''\n",
    "    for j in seq:\n",
    "        seq2 = seq2 + j\n",
    "    seq2 = seq2[2:len(seq2)-1]\n",
    "    seq2 = seq2.split(' ')\n",
    "    #print(seq2)\n",
    "    seq3=[]\n",
    "    for j in seq2:\n",
    "        #print(j)\n",
    "        if j=='':\n",
    "            a=0\n",
    "        else:\n",
    "            seq3.append(float(j))\n",
    "    return seq3\n",
    "\n",
    "verif = pd.read_csv(\"genomes/negatifs.csv\", sep = \"\\t\",header=None)  #ou positifs\n",
    "verif = np.array(verif)\n",
    "for i in range(len(verif)):\n",
    "    for j in range(4):\n",
    "        if len(verif[i,j]) <= 15:\n",
    "            print(i,\"erreur\")\n",
    "            \n",
    "\n",
    "for i in range(len(verif)):\n",
    "    verif[i,2] = clean(verif[i,2])\n",
    "    verif[i,3] = clean(verif[i,3])    \n",
    "verif[20,2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau de neurones basé sur iDeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D,Conv1D, MaxPooling1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, model_from_config\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "from keras.layers import normalization\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D,Convolution1D, MaxPooling1D\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import load_model\n",
    "#from keras.optimizers import kl_divergence\n",
    "from sklearn import svm, grid_search\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import gzip\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals import joblib \n",
    "from scipy import sparse\n",
    "import pdb\n",
    "from math import  sqrt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import theano\n",
    "import subprocess as sp\n",
    "import scipy.stats as stats\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(test_num, pred_y,  labels):\n",
    "    tp =0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index in range(test_num):\n",
    "        if labels[index] ==1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp = tp +1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn = tn +1\n",
    "            else:\n",
    "                fp = fp + 1               \n",
    "            \n",
    "    acc = float(tp + tn)/test_num\n",
    "    precision = float(tp)/(tp+ fp)\n",
    "    sensitivity = float(tp)/ (tp+fn)\n",
    "    specificity = float(tn)/(tn + fp)\n",
    "    MCC = float(tp*tn-fp*fn)/(np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "    return acc, precision, sensitivity, specificity, MCC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_networks_train_predict():\n",
    "    data = load_data()[0]\n",
    "    print 'training', len(training_data)\n",
    "    go_hid = 512\n",
    "    kmer_hid = 512\n",
    "    rg_hid = 128\n",
    "    clip_hid = 256\n",
    "    rna_hid=64\n",
    "    cnn_hid = 64\n",
    "    motif_hid = 64\n",
    "    seq_hid = 102\n",
    "    training_indice, training_label, validation_indice, validation_label = split_training_validation(training_data[\"Y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-aa673ac99eeb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(5, 5), strides=(1, 1),activation='relu',input_shape=s.shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ARCHIVES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération rapide des séquences à partir de chr_nb start end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# download genome at ftp://ftp.sanger.ac.uk/pub/gencode/Gencode_human/release_24/GRCh38.primary_assembly.genome.fa.gz\n",
    "\n",
    "parser = SeqIO.parse(open(\"genomes/GRCh38.genome.fa\"),\"fasta\")\n",
    "\n",
    "dict_fasta = dict([(seq.id, seq) for seq in parser])\n",
    "\n",
    "ide, begin, end = ['chr17',8222876,8222895]\n",
    "\n",
    "dict_fasta[ide][begin:end].format(\"fasta\").split('\\n')[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A partir de là c'est l'ancienne méthode (à conserver au cas où, archive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On  sauvegarde la base de données dans un fichier csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "browser = webdriver.Chrome()\n",
    "import csv\n",
    "\n",
    "writer = csv.writer(open(\"genomes/database.csv\", 'w',newline=''),delimiter=\"\\t\")\n",
    "for i,el in enumerate(varrbdd):\n",
    "    row = transformer_database2(varrbdd[i])    \n",
    "    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On cherche les trous dans les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdd_5000_trouee = pd.read_csv(\"genomes/database.csv\", sep = \"\\t\",header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4983"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bdd_5000_trouee = np.array(bdd_5000_trouee)\n",
    "l = []\n",
    "for i,el in enumerate(bdd_5000_trouee):\n",
    "    if type(bdd_5000_trouee[i,0])==float or type(bdd_5000_trouee[i,1])==float:\n",
    "        a=0\n",
    "    elif len(bdd_5000_trouee[i,0])==0 or len(bdd_5000_trouee[i,0])==0:\n",
    "        a=0\n",
    "    else:\n",
    "        l.append(i)\n",
    "l = np.array(l)\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdd_miRNA_mRNA = bdd_5000_trouee[l]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdd_miRNA_mRNA = nettoyer(bdd_miRNA_mRNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdd_miRNA_mRNA = traduire_séquences(bdd_miRNA_mRNA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bdd_apprentissage = construire_seq_et_structure_bdd(bdd_miRNA_mRNA[:15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A partir de mainenant, on essaye d'obtenir les probabilités d'accesibilité de chaque nucléotide sur une séquence quelconque ARN par exemple 'ACGUUGUCACACGAU'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traduire_test(seq,strand):\n",
    "    nucleotides = ''\n",
    "    if strand:\n",
    "        string = ''\n",
    "        for i in seq:\n",
    "            string = i + string\n",
    "        seq = string\n",
    "        for lettre in seq:\n",
    "            if lettre=='a':\n",
    "                nucleotides=nucleotides+'u'\n",
    "            elif lettre=='c':\n",
    "                nucleotides=nucleotides+'g'\n",
    "            elif lettre=='g':\n",
    "                nucleotides=nucleotides+'c'\n",
    "            else:\n",
    "                nucleotides=nucleotides+'a'\n",
    "    else:\n",
    "        for lettre in seq:\n",
    "            if lettre=='a':\n",
    "                nucleotides=nucleotides+'a'\n",
    "            elif lettre=='c':\n",
    "                nucleotides=nucleotides+'c'\n",
    "            elif lettre=='g':\n",
    "                nucleotides=nucleotides+'g'\n",
    "            else:\n",
    "                nucleotides=nucleotides+'u'    \n",
    "    return nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cacuacagcaagccuggcacgaccucuaaggcgguucgcggcaacguccgcacgucggcucguuggucuagggguaugauucucgcuucgggugcgagaggucccggguucaaaucccggacgagcccuccuuuaccuuuuacugagacaagagugucuuc'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traduire_test('gaagacactcttgtctcagtaaaaggtaaaggagggctcgtccgggatttgaacccgggacctctcgcacccgaagcgagaatcatacccctagaccaacgagccgacgtgcggacgttgccgcgaaccgccttagaggtcgtgccaggcttgctgtagtg',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'gaagacactcttgtctcagtaaaaggtaaaggagggctcgtccgggatttgaacccgggacctctcgcacccgaagcgagaatcatacccctagaccaacgagccgacgtgcggacgttgccgcgaaccgccttagaggtcgtgccaggcttgctgtagtg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/DATA/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (1,2,4,5) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "bdd = pd.read_csv(\"rise_human_transcriptome (copie).csv\", sep = \"\\t\",header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bdd convertie panda -> numpy array et seuls les 70 000 premiers RRIs retenus\n",
    "arrbdd = np.array(bdd)[:70000]\n",
    "\n",
    "#enlever 'chr' et formater les numéros de chromosomes\n",
    "for i,el in enumerate(arrbdd[:,0]):\n",
    "    arrbdd[i,0] = arrbdd[i,0][3:]\n",
    "\n",
    "for i,el in enumerate(arrbdd[:,0]):\n",
    "    if arrbdd[i,0] == 'X':\n",
    "        arrbdd[i,0] = '23'\n",
    "    if arrbdd[i,0] == 'Y':\n",
    "        arrbdd[i,0] = '24'\n",
    "    if arrbdd[i,0] == '1':\n",
    "        arrbdd[i,0] = '01'\n",
    "    if arrbdd[i,0] == '2':\n",
    "        arrbdd[i,0] = '02'\n",
    "    if arrbdd[i,0] == '3':\n",
    "        arrbdd[i,0] = '03'\n",
    "    if arrbdd[i,0] == '4':\n",
    "        arrbdd[i,0] = '04'\n",
    "    if arrbdd[i,0] == '5':\n",
    "        arrbdd[i,0] = '05'\n",
    "    if arrbdd[i,0] == '6':\n",
    "        arrbdd[i,0] = '06'\n",
    "    if arrbdd[i,0] == '7':\n",
    "        arrbdd[i,0] = '07'\n",
    "    if arrbdd[i,0] == '8':\n",
    "        arrbdd[i,0] = '08'\n",
    "    if arrbdd[i,0] == '9':\n",
    "        arrbdd[i,0] = '09'\n",
    "\n",
    "for i,el in enumerate(arrbdd[:,3]):\n",
    "    arrbdd[i,3] = arrbdd[i,3][3:]\n",
    "\n",
    "for i,el in enumerate(arrbdd[:,3]):\n",
    "    if arrbdd[i,3] == 'X':\n",
    "        arrbdd[i,3] = '23'\n",
    "    elif arrbdd[i,3] == 'Y':\n",
    "        arrbdd[i,3] = '24'  \n",
    "    elif arrbdd[i,3] == '1':\n",
    "        arrbdd[i,3] = '01'\n",
    "    elif arrbdd[i,3] == '2':\n",
    "        arrbdd[i,3] = '02'\n",
    "    elif arrbdd[i,3] == '3':\n",
    "        arrbdd[i,3] = '03'\n",
    "    elif arrbdd[i,3] == '4':\n",
    "        arrbdd[i,3] = '04'\n",
    "    elif arrbdd[i,3] == '5':\n",
    "        arrbdd[i,3] = '05'\n",
    "    elif arrbdd[i,3] == '6':\n",
    "        arrbdd[i,3] = '06'\n",
    "    elif arrbdd[i,3] == '7':\n",
    "        arrbdd[i,3] = '07'\n",
    "    elif arrbdd[i,3] == '8':\n",
    "        arrbdd[i,3] = '08'\n",
    "    elif arrbdd[i,3] == '9':\n",
    "        arrbdd[i,3] = '09'\n",
    "\n",
    "\n",
    "#enlever les chromosomes M\n",
    "arg_sansM = np.argwhere((arrbdd[:,0] != 'M') & (arrbdd[:,3] != 'M'))\n",
    "varrbdd = arrbdd[arg_sansM[:,0]]\n",
    "\n",
    "#changement strand\n",
    "for i,el in enumerate(varrbdd[:,8]):\n",
    "    if varrbdd[i,8] == '+':\n",
    "        varrbdd[i,8] = 'true'\n",
    "    else:\n",
    "        varrbdd[i,8] = 'false'\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,9]):\n",
    "    if varrbdd[i,9] == '+':\n",
    "        varrbdd[i,9] = 'true'\n",
    "    else:\n",
    "        varrbdd[i,9] = 'false'\n",
    "\n",
    "\n",
    "#int str\n",
    "for i,el in enumerate(varrbdd[:,1]):\n",
    "    if type(el) == int:\n",
    "        varrbdd[i,1] = str(el)\n",
    "for i,el in enumerate(varrbdd[:,2]):\n",
    "    if type(el) == int:\n",
    "        varrbdd[i,2] = str(el)\n",
    "for i,el in enumerate(varrbdd[:,4]):\n",
    "    if type(el) == int:\n",
    "        varrbdd[i,4] = str(el)\n",
    "for i,el in enumerate(varrbdd[:,5]):\n",
    "    if type(el) == int:\n",
    "        varrbdd[i,5] = str(el)\n",
    "\n",
    "#génération position début et fin de séquence (nucléotides)\n",
    "\n",
    "for i,el in enumerate(varrbdd[:,1]):\n",
    "    milieu = int((int(varrbdd[i,1])+int(varrbdd[i,2]))/2)\n",
    "    varrbdd[i,1] = str(milieu-50)\n",
    "    varrbdd[i,2] = str(milieu+50)\n",
    "    milieu = int((int(varrbdd[i,4])+int(varrbdd[i,5]))/2)\n",
    "    varrbdd[i,4] = str(milieu-50)\n",
    "    varrbdd[i,5] = str(milieu+50)\n",
    "\n",
    "# Génération URLs\n",
    "\n",
    "#for i,el in enumerate(varrbdd[:,6]):\n",
    " #   varrbdd[i,6] = \"https://www.ncbi.nlm.nih.gov/nuccore/NC_0000\"+varrbdd[i,0]+\"?report=genbank&from=\"+varrbdd[i,1]+\"&to=\"+varrbdd[i,2]+\"&strand=\"+varrbdd[i,8]+\".html\"\n",
    "#for i,el in enumerate(varrbdd[:,6]):\n",
    " #   varrbdd[i,6] = 'https://www.ncbi.nlm.nih.gov/nuccore/NC_0000'+varrbdd[i,0]+'?report=fasta&log$=seqview&format=text&from='+varrbdd[i,1]+'&to='+varrbdd[i,2]\n",
    "\n",
    "#for i,el in enumerate(varrbdd[:,7]):\n",
    " #   varrbdd[i,7] = \"https://www.ncbi.nlm.nih.gov/nuccore/NC_0000\"+varrbdd[i,3]+\"?report=genbank&from=\"+varrbdd[i,4]+\"&to=\"+varrbdd[i,5]+\"&strand=\"+varrbdd[i,9]+\".html\"\n",
    "#for i,el in enumerate(varrbdd[:,7]):\n",
    " #   varrbdd[i,7] = 'https://www.ncbi.nlm.nih.gov/nuccore/NC_0000'+varrbdd[i,3]+'?report=fasta&log$=seqview&format=text&from='+varrbdd[i,4]+'&to='+varrbdd[i,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def recuperer_sequence(url):\n",
    "    browser = webdriver.Chrome()\n",
    "    browser.get(url)\n",
    "    time.sleep(4)\n",
    "    innerHTML = browser.execute_script(\"return document.body.innerHTML\")\n",
    "    browser.quit()\n",
    "    soup = BeautifulSoup(innerHTML,\"lxml\")\n",
    "    seq = soup.find_all(\"span\",{'class':\"ff_line\"})\n",
    "    rep = seq[0].text+seq[1].text+seq[2].text+seq[3].text\n",
    "    rep = ''.join(rep.split())\n",
    "    return rep\n",
    "\n",
    "def recuperer_sequence2(url):\n",
    "    browser.get(url)\n",
    "    time.sleep(1.3)\n",
    "    innerHTML = browser.execute_script(\"return document.body.innerHTML\")\n",
    "    soup = BeautifulSoup(innerHTML,\"lxml\")\n",
    "    seq = soup.find_all(\"div\",{'class':\"seq gbff\"})\n",
    "    rep = seq[0].text   \n",
    "    return rep\n",
    "\n",
    "def transformer_database(bddrow):\n",
    "    sequence=recuperer_sequence(bddrow[6])\n",
    "    sequence=transformer_sequence(sequence,len(sequence))\n",
    "    sequencebis=recuperer_sequence(bddrow[7])\n",
    "    sequencebis=transformer_sequence(sequencebis,len(sequencebis))    \n",
    "    bddrow = np.array([bddrow[18],bddrow[19],bddrow[20],bddrow[21],sequence,bddrow[0],bddrow[1],bddrow[2],bddrow[8],bddrow[10],bddrow[11],bddrow[14],bddrow[16],sequencebis,bddrow[3],bddrow[4],bddrow[5],bddrow[9],bddrow[12],bddrow[13],bddrow[15],bddrow[17]], dtype=object)\n",
    "    return bddrow\n",
    "\n",
    "def transformer_database2(bddrow):\n",
    "    sequence=recuperer_sequence2(bddrow[6])\n",
    "    sequencebis=recuperer_sequence2(bddrow[7])\n",
    "    bddrow = np.array([sequence,sequencebis,bddrow[8],bddrow[9]], dtype=object)\n",
    "    return bddrow\n",
    "\n",
    "def construire_seq_et_structure_bdd(bdd):\n",
    "    for i,el in enumerate(bdd):\n",
    "        bdd[i,2] = np.array(RNA.pfl_fold_up(bdd[i,0],1,201,201))[1:,1]\n",
    "        bdd[i,3] = np.array(RNA.pfl_fold_up(bdd[i,1],1,201,201))[1:,1]\n",
    "        #bdd[i,0] = transformer_sequence(bdd[i,0],201)\n",
    "        #bdd[i,1] = transformer_sequence(bdd[i,1],201)\n",
    "    return bdd\n",
    "\n",
    "def nettoyer(bdd):\n",
    "    for i,el in enumerate(bdd):\n",
    "        bdd[i,0]=bdd[i,0].split('\\n')[1]+bdd[i,0].split('\\n')[2]+bdd[i,0].split('\\n')[3]\n",
    "        bdd[i,1]=bdd[i,1].split('\\n')[1]+bdd[i,1].split('\\n')[2]+bdd[i,1].split('\\n')[3]\n",
    "    return bdd\n",
    "\n",
    "def traduire_séquences(bdd):\n",
    "    for i,el in enumerate(bdd):\n",
    "        bdd[i,0]=traduire(bdd[i,0],bdd[i,2])\n",
    "        bdd[i,1]=traduire(bdd[i,1],bdd[i,3])\n",
    "    return bdd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All the import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conspiracy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/conspiracy/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/conspiracy/anaconda3/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Concatenate, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D,Conv1D, MaxPooling1D\n",
    "from keras.models import model_from_config\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import load_model\n",
    "from keras.layers.convolutional import AveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn import svm, grid_search\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "import RNA\n",
    "\n",
    "import random\n",
    "import gzip\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals import joblib \n",
    "from scipy import sparse\n",
    "import pdb\n",
    "from math import  sqrt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import theano\n",
    "import subprocess as sp\n",
    "import scipy.stats as stats\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import csv\n",
    "from random import shuffle\n",
    "from keras.layers import Merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99515374, 0.98200108, 0.97327828, 0.83831717, 0.71386684,\n",
       "       0.70952593, 0.79190253, 0.74114161, 0.24841253, 0.20895404,\n",
       "       0.37044396, 0.07146792, 0.09764458, 0.13250682, 0.1708176 ,\n",
       "       0.30276394, 0.90875754, 0.84469873, 0.79897224, 0.34805775,\n",
       "       0.62012246, 0.22103493, 0.05596614, 0.39760585, 0.50417549,\n",
       "       0.45270863, 0.77728394, 0.78237052, 0.35248909, 0.27293962,\n",
       "       0.40199972, 0.82078131, 0.26921011, 0.79933257, 0.63717472,\n",
       "       0.42815308, 0.4700229 , 0.01334941, 0.25455379, 0.22365579,\n",
       "       0.20206252, 0.21610497, 0.92423724, 0.77800337, 0.34187502,\n",
       "       0.1734228 , 0.17031566, 0.79341276])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqtest = 'augugacugaugcuagugaugucgucgucgaggggaucuagcugaucg'\n",
    "z = len(seqtest)\n",
    "np.array(RNA.pfl_fold_up(seqtest,1,z,z))[1:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traduire(seq):\n",
    "    nucleotides = ''\n",
    "    for lettre in seq:\n",
    "            if lettre=='A' || lettre=='a':\n",
    "                nucleotides=nucleotides+'a'\n",
    "            elif lettre=='C' || lettre=='c':\n",
    "                nucleotides=nucleotides+'c'\n",
    "            elif lettre=='G' || lettre=='g':\n",
    "                nucleotides=nucleotides+'g'\n",
    "            else:\n",
    "                nucleotides=nucleotides+'u'\n",
    "    return nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_sequence(sequence):\n",
    "    matrice = np.zeros((36,4))\n",
    "    for i in range(len(sequence)):\n",
    "            if sequence[i]=='a':\n",
    "                matrice[i,0] = 1\n",
    "            elif sequence[i]=='u':\n",
    "                matrice[i,1] = 1\n",
    "            elif sequence[i]=='g':\n",
    "                matrice[i,2] = 1\n",
    "            elif sequence[i]=='c':\n",
    "                matrice[i,3] = 1\n",
    "    return matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_matrice3D(seq1,seq2):\n",
    "    matrice = np.zeros((36,36,1))\n",
    "    for j in range(len(seq1)):\n",
    "        for k in range(len(seq2)):\n",
    "            if (seq1[j][0]==1 and seq2[k][1]==1) or (seq1[j][1]==1 and seq2[k][0]==1):\n",
    "                matrice[j,k,0] = 1\n",
    "            elif (seq1[j][2]==1 and seq2[k][3]==1) or (seq1[j][3]==1 and seq2[k][2]==1):\n",
    "                matrice[j,k,0] = 1\n",
    "            elif (seq1[j][2]==1 and seq2[k][1]==1) or (seq1[j][1]==1 and seq2[k][2]==1):\n",
    "                matrice[j,k,0] = 1\n",
    "    return matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_proba(proba1,proba2):\n",
    "    product = np.zeros((36,36,1))\n",
    "    for j in range(len(proba1)):\n",
    "            for k in range(len(proba2)):\n",
    "                product[j][k] = proba1[j] * proba2[k]\n",
    "    return product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum_proba(proba1,proba2):\n",
    "    somme = np.zeros((36,36,1))\n",
    "    for j in range(len(proba1)):\n",
    "            for k in range(len(proba2)):\n",
    "                somme[j][k] = proba1[j] + proba2[k]\n",
    "    return somme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_datatest():\n",
    "    datatest = pd.read_csv(\"genomes/nar-03123-met-g-2015-File010.csv\", sep = \",\", header=None)\n",
    "    datatest = np.array(datatest)\n",
    "    l = len(datatest)\n",
    "    seq1 = []\n",
    "    seq2 = []\n",
    "    matrice3D = []\n",
    "    product = []\n",
    "    somme = []\n",
    "    index = 0\n",
    "    for i in range(1,l):\n",
    "        \n",
    "        begin1 = int(datatest[i,9])\n",
    "        end1 = int(datatest[i,10])\n",
    "        size1 = end1-begin1\n",
    "        if(size1 <= 36):\n",
    "    \n",
    "            begin2 = int(datatest[i,11])\n",
    "            end2 = int(datatest[i,12])\n",
    "            size2 = end2-begin2\n",
    "    \n",
    "            if(size2 <= 36):\n",
    "                \n",
    "                print(\"size 1 : \",size1)\n",
    "                print(\"size 2 : \",size2)\n",
    "                \n",
    "                proba1 = []\n",
    "                proba2 = []\n",
    "            \n",
    "                sequence = traduire(datatest[i,23][begin1:end1])\n",
    "                z = len(sequence)\n",
    "                proba1 = np.array(RNA.pfl_fold_up(sequence,1,z,z))[1:,1]\n",
    "                seq1.append(convert_sequence(sequence))\n",
    "                \n",
    "                sequence = traduire(datatest[i,24][begin2:end2])\n",
    "                z = len(sequence)\n",
    "                proba2 = np.array(RNA.pfl_fold_up(sequence, 1, z, z))[1:,1]\n",
    "                seq2.append(convert_sequence(sequence))\n",
    "                \n",
    "                print(index)\n",
    "                matrice3D.append(convert_matrice3D(seq1[index],seq2[index]))\n",
    "                product.append(get_product_proba(proba1,proba2))\n",
    "                somme.append(get_sum_proba(proba1,proba2))\n",
    "                index+=1\n",
    "    test = []\n",
    "    test.append(matrice3D)\n",
    "    test.append(product)\n",
    "    test.append(seq1)\n",
    "    test.append(seq2)\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(seq):\n",
    "    seq = seq.split('\\n')\n",
    "    seq2 = ''\n",
    "    for j in seq:\n",
    "        seq2 = seq2 + j\n",
    "    seq2 = seq2[2:len(seq2)-1]\n",
    "    seq2 = seq2.split(' ')\n",
    "    #print(seq2)\n",
    "    seq3=[]\n",
    "    for j in seq2:\n",
    "        #print(j)\n",
    "        if j=='':\n",
    "            a=0\n",
    "        else:\n",
    "            seq3.append(float(j))\n",
    "    return seq3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # load your data using this function\n",
    "    neg1 = []\n",
    "\n",
    "    neg1 = pd.read_csv(\"genomes/negatifs_m-m-str.csv\", sep = \"\\t\",header=None)\n",
    "    neg1 = np.array(neg1)\n",
    "    print(len(neg1))\n",
    "    for i in range(len(neg1)):\n",
    "        for j in range(2):\n",
    "            if len(neg1[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "            \n",
    "\n",
    "    neg2 = pd.read_csv(\"genomes/negatifs_divers-str.csv\", sep = \"\\t\",header=None)\n",
    "    neg2 = np.array(neg2)\n",
    "    print(len(neg2))\n",
    "    for i in range(len(neg2)):\n",
    "        for j in range(2):\n",
    "            if len(neg2[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "    \n",
    "    neg3 = pd.read_csv(\"genomes/negatifs_mouse_divers-str.csv\", sep = \"\\t\",header=None)\n",
    "    neg3 = np.array(neg3)\n",
    "    print(len(neg3))\n",
    "    for i in range(len(neg3)):\n",
    "        for j in range(2):\n",
    "            if len(neg3[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "\n",
    "    pos1 = pd.read_csv(\"genomes/positifs_m-m-str.csv\", sep = \"\\t\",header=None)  \n",
    "    pos1 = np.array(pos1)\n",
    "    print(len(pos1))\n",
    "    for i in range(len(pos1)):\n",
    "        for j in range(2):\n",
    "            if len(pos1[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "    l = len(pos1)\n",
    "    \n",
    "    pos2 = pd.read_csv(\"genomes/positifs_divers-str.csv\", sep = \"\\t\",header=None)  \n",
    "    pos2 = np.array(pos2)\n",
    "    print(len(pos2))\n",
    "    for i in range(len(pos2)):\n",
    "        for j in range(2):\n",
    "            if len(pos2[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "    l=l+len(pos2)\n",
    "\n",
    "    pos3 = pd.read_csv(\"genomes/positifs_mouse_divers-str.csv\", sep = \"\\t\",header=None)  \n",
    "    pos3 = np.array(pos3)\n",
    "    print(len(pos3))\n",
    "    for i in range(len(pos3)):\n",
    "        for j in range(2):\n",
    "            if len(pos3[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "    l=l+len(pos3)\n",
    "\n",
    "    bdd = np.concatenate((pos1,pos2,pos3,neg1,neg2,neg3))\n",
    "\n",
    "    pos1 = []\n",
    "    neg1 = []\n",
    "    pos2 = []\n",
    "    neg2 = []\n",
    "    pos3 = []\n",
    "    neg3 = []\n",
    "\n",
    "    labels = np.zeros((len(bdd),1))\n",
    "\n",
    "    bdd = np.concatenate((bdd,labels),axis=1)\n",
    "    for i in range(l):\n",
    "        bdd[i,4]=1\n",
    "    labels=[]\n",
    "    \n",
    "    # shuffle total\n",
    "\n",
    "    indices = np.arange(len(bdd))\n",
    "    shuffle(indices)\n",
    "    bdd = bdd[indices]\n",
    "    indices=[]\n",
    "\n",
    "    l = len(bdd)\n",
    "    matrice = np.zeros((l,36,36,1))\n",
    "    matrice1 = np.zeros((l,36,36,1))\n",
    "    matrice2 = np.zeros((l,36,4))\n",
    "    matrice3 = np.zeros((l,36,4))\n",
    "\n",
    "    for i in range(l):\n",
    "        seq1 = bdd[i,0]\n",
    "        seq2 = bdd[i,1]\n",
    "        prob1 = np.array(clean(bdd[i,2]))\n",
    "        prob2 = np.array(clean(bdd[i,3]))\n",
    "        for j in range(len(seq1)):\n",
    "            for k in range(len(seq2)):\n",
    "                if (seq1[j]=='a' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='a'):\n",
    "                    matrice[i,j,k,0] = 1\n",
    "                elif (seq1[j]=='g' and seq2[k]=='c') or (seq1[j]=='c' and seq2[k]=='g'):\n",
    "                    matrice[i,j,k,0] = 1\n",
    "                elif (seq1[j]=='g' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='g'):\n",
    "                    matrice[i,j,k,0] = 1\n",
    "                matrice1[i,j,k,0] = prob1[j]+prob2[k]\n",
    "        for j in range(len(seq1)):\n",
    "            if seq1[j]=='a':\n",
    "                matrice2[i,j,0] = 1\n",
    "            elif seq1[j]=='u':\n",
    "                matrice2[i,j,1] = 1\n",
    "            elif seq1[j]=='g':\n",
    "                matrice2[i,j,2] = 1\n",
    "            elif seq1[j]=='c':\n",
    "                matrice2[i,j,3] = 1\n",
    "        for j in range(len(seq2)):\n",
    "            if seq2[j]=='a':\n",
    "                matrice3[i,j,0] = 1\n",
    "            elif seq2[j]=='u':\n",
    "                matrice3[i,j,1] = 1\n",
    "            elif seq2[j]=='g':\n",
    "                matrice3[i,j,2] = 1\n",
    "            elif seq2[j]=='c':\n",
    "                matrice3[i,j,3] = 1  \n",
    "    return matrice, matrice1, matrice2, matrice3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(nb_train = 165000,nb_val = 6000,nb_test = 5000):\n",
    "    data = load_dataset()\n",
    "    matrice = data[0]\n",
    "    matrice1 = data[1]\n",
    "    matrice2 = data[2]\n",
    "    matrice3 = data[3]\n",
    "    \n",
    "    training = []\n",
    "    training.append(matrice[:nb_train])\n",
    "    training.append(matrice1[:nb_train])\n",
    "    training.append(matrice2[:nb_train])\n",
    "    training.append(matrice3[:nb_train])\n",
    "\n",
    "    validation = []\n",
    "    validation.append(matrice[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice1[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice2[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice3[nb_train:nb_train+nb_val])\n",
    "\n",
    "    testing = []\n",
    "    testing.append(matrice[-nb_test:])\n",
    "    testing.append(matrice1[-nb_test:])\n",
    "    testing.append(matrice2[-nb_test:])\n",
    "    testing.append(matrice3[-nb_test:])\n",
    "\n",
    "    labels = bdd[:,4]\n",
    "    bdd = []\n",
    "    y = labels[:nb_train]\n",
    "    y = keras.utils.np_utils.to_categorical(y,2)\n",
    "    val_y = labels[nb_train:nb_train+nb_val]\n",
    "    val_y = keras.utils.np_utils.to_categorical(val_y,2)\n",
    "    true_y = labels[-nb_test:]\n",
    "    argtest=[]\n",
    "    np.sum(y[:,1])\n",
    "    return training, y, validation, val_y, testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(test_num, pred_y,  labels):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index in range(test_num):\n",
    "        if labels[index] ==1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp = tp +1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn = tn +1\n",
    "            else:\n",
    "                fp = fp + 1               \n",
    "            \n",
    "    acc = float(tp + tn)/test_num\n",
    "    precision = float(tp)/(tp+ fp)\n",
    "    sensitivity = float(tp)/ (tp+fn)\n",
    "    specificity = float(tn)/(tn + fp)\n",
    "    MCC = float(tp*tn-fp*fn)/(np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "    return acc, precision, sensitivity, specificity, MCC "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_network(matrixsize = 6, nbfilter = 24, matrixsize2 = 7, nbfilter2 = 6):    \n",
    "    k = matrixsize\n",
    "    # init_weights\n",
    "    I = np.eye(k)\n",
    "    M = np.diag(np.ones(k-1),1) + np.diag(np.ones(k-1),-1) + np.eye(k)\n",
    "    I2 = np.zeros((k,k))\n",
    "    M2 = np.zeros((k,k))\n",
    "    for j in range(k):\n",
    "        I2[:,j] = I[:,k-j-1]\n",
    "        M2[:,j] = M[:,k-j-1]        \n",
    "    W = np.zeros((k,k,1,nbfilter))\n",
    "    W[:,:,0,0] = I\n",
    "    W[:,:,0,1] = I2\n",
    "    W[:,:,0,2] = M\n",
    "    W[:,:,0,3] = M2\n",
    "    for j in range(4,nbfilter):\n",
    "        W[:,:,0,j] = np.random.randn(k,k)*0.2\n",
    "    print('configure cnn network')\n",
    " \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(filters = nbfilter, kernel_size=(k,k), padding='valid', input_shape=(36,36,1),strides=(1,1),weights=[W,np.zeros(nbfilter)]))    \n",
    "    model.add(AveragePooling2D(pool_size=(3,3)))\n",
    "    print(model.output_shape)\n",
    "    \n",
    "    k2 = matrixsize2\n",
    "    I = np.eye(k2)\n",
    "    M = np.diag(np.ones(k2-1),1) + np.diag(np.ones(k2-1),-1) + np.eye(k2)\n",
    "    I2=np.zeros((k2,k2))\n",
    "    M2=np.zeros((k2,k2))\n",
    "    for j in range(k2):\n",
    "        I2[:,j] = I[:,k2-j-1]\n",
    "        M2[:,j] = M[:,k2-j-1]   \n",
    "    \n",
    "    Z = np.zeros((k2,k2,nbfilter,nbfilter2))\n",
    "    \n",
    "    for u in range(nbfilter):\n",
    "        Z[:,:,u,0] = I\n",
    "        Z[:,:,u,1] = I2\n",
    "        Z[:,:,u,2] = M\n",
    "        Z[:,:,u,3] = M2\n",
    "        for p in range(4,nbfilter2):\n",
    "            Z[:,:,u,p]=np.random.randn(k2,k2)*0.3            \n",
    "\n",
    "    model.add(Conv2D(filters = nbfilter2, kernel_size = (k2, k2),strides=(1,1),padding='valid',weights=[Z,np.zeros(nbfilter2)]))\n",
    "    print(model.output_shape)    \n",
    "    model.add(Flatten())\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_network_seq(nbfilter = 64, kernelsize = 7):        \n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = nbfilter, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None)))\n",
    "    model.add(MaxPooling1D(pool_size=6))\n",
    "    print(model.output_shape)\n",
    "    model.add(Flatten())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(matrixsize11 = 6, nbfilter11 = 24, matrixsize12 = 7, nbfilter12 = 6, \n",
    "                 matrixsize21 = 6, nbfilter21 = 24, matrixsize22 = 7, nbfilter22 = 6,\n",
    "                 nbfilter1 = 64, kernel_size1 = 7, nbfilters2 = 64,kernel_size2 = 7,\n",
    "                 Dense1 = 512, Dense2 = 128, Dense3 = 512, Dense4 = 128, Dense5 = 64):\n",
    "    training_net=[]\n",
    "    training_net1 = []\n",
    "    training_net2 = []\n",
    "    training_net1.append(get_cnn_network(matrixsize11, nbfilter11, matrixsize12, nbfilter12))\n",
    "    training_net1.append(get_cnn_network(matrixsize21, nbfilter21, matrixsize22, nbfilter22))\n",
    "    training_net2.append(get_cnn_network_seq(nbfilter1,kernel_size1))\n",
    "    training_net2.append(get_cnn_network_seq(nbfilters2,kernel_size2))\n",
    "    \n",
    "    \n",
    "    model2 = Sequential()\n",
    "    model2.add(Merge(training_net2, mode ='concat'))\n",
    "    model2.add(Dense(Dense1,kernel_initializer=keras.initializers.lecun_uniform(seed=None)))\n",
    "    model2.add(BatchNormalization())\n",
    "    model2.add(Activation('relu'))\n",
    "    #model2.add(Dropout(0.1))\n",
    "    \n",
    "    model1 = Sequential()\n",
    "    model1.add(Merge(training_net1, mode ='concat'))\n",
    "    model1.add(Dense(Dense2,kernel_initializer=keras.initializers.lecun_uniform(seed=None)))\n",
    "    #model1.add(Dropout(0.1))\n",
    "    model1.add(BatchNormalization())\n",
    "    model1.add(Activation('relu'))\n",
    "    \n",
    "    training_net.append(model1)\n",
    "    training_net.append(model2)\n",
    "    model = Sequential()\n",
    "    model.add(Merge(training_net, mode='concat'))\n",
    "    \n",
    "    model.add(Dense(Dense3,kernel_initializer=keras.initializers.lecun_uniform(seed=None)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(Dense4,kernel_initializer=keras.initializers.lecun_uniform(seed=None)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(Dense5,kernel_initializer=keras.initializers.lecun_uniform(seed=None)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('relu'))\n",
    "    #model.add(Dropout(0.5))\n",
    "    model.add(Dense(2,kernel_initializer=keras.initializers.lecun_uniform(seed=None)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    #sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop',metrics=['accuracy','roc_curve','auc'])\n",
    "          \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Data = load_data(165000,6000,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(training = [], y = [], batch_size=16, epochs=6, verbose1 = 1, verbose2 = 1,\n",
    "                              validation = [], val_y = [], testing = [], matrixsize11 = 6, nbfilter11 = 24, \n",
    "                              matrixsize12 = 7, nbfilter12 = 6, matrixsize21 = 6, nbfilter21 = 24, matrixsize22 = 7,\n",
    "                              nbfilter22 = 6, nbfilter1 = 64, kernel_size1 = 7, nbfilters2 = 64,kernel_size2 = 7,\n",
    "                              Dense1 = 512, Dense2 = 128, Dense3 = 512, Dense4 = 128, Dense5 = 64):\n",
    "    model = create_model(matrixsize11, nbfilter11, matrixsize12, nbfilter12, matrixsize21, nbfilter21, \n",
    "                         matrixsize22, nbfilter22, nbfilter1, kernel_size1, nbfilters2,kernel_size2,\n",
    "                         Dense1, Dense2, Dense3, Dense4, Dense5)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=2, verbose = verbose1)\n",
    "    print('model training')\n",
    "    model.fit(training, y, batch_size, epochs, verbose = verbose2, validation_data=(validation, val_y), callbacks=[earlystopper])\n",
    "    \n",
    "    # test   \n",
    "    \n",
    "    print('predicting')\n",
    "    \n",
    "        \n",
    "    predictions = model.predict_proba(testing)[:,1]\n",
    "    print(predictions)\n",
    "    for i,nulll in enumerate(predictions):\n",
    "        predictions[i] = round(predictions[i])\n",
    "    print(predictions,true_y)\n",
    "    perfs = calculate_performance(len(predictions), predictions, true_y)\n",
    "    print(\"batch_size : \", batch_size)\n",
    "    print(\"epochs : \",epochs)\n",
    "    print(\"acc : \", perfs[0])\n",
    "    print(\"precision : \", perfs[1])\n",
    "    print(\"sensitivity : \", perfs[2])\n",
    "    print(\"specificity : \", perfs[3])\n",
    "    print(\"MCC : \", perfs[4])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, filename = \"model\"):\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    with open(filename+\".json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(filename+\".h5\")\n",
    "    json_file.close()\n",
    "    print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(filename = 'model'):\n",
    "    # load json and create model\n",
    "    json_file = open(filename+'.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    json_file.close()\n",
    "    # load weights into new model\n",
    "    loaded_model.load_weights(filename+\".h5\")\n",
    "    print(\"Loaded model from disk\")\n",
    "    return loaded_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transf(seq1, seq2):\n",
    "    z = len(seq1)\n",
    "    proba1 = np.array(RNA.pfl_fold_up(seq1,1,z,z))[1:,1]\n",
    "    sequ1 = convert_sequence(seq1)\n",
    "    \n",
    "    z = len(seq2)\n",
    "    proba2 = np.array(RNA.pfl_fold_up(seq1,1,z,z))[1:,1]\n",
    "    sequ2 = convert_sequence(seq2)\n",
    "    \n",
    "    matrice3D = convert_matrice3D(sequ1,sequ2)\n",
    "    product = get_product_proba(proba1,proba2)\n",
    "       \n",
    "    test = []\n",
    "    test.append(matrice3D)\n",
    "    test.append(product)\n",
    "    test.append(seq1)\n",
    "    test.append(seq2)\n",
    "    \n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(seq1,seq2,window = 36, filename = 'model'):\n",
    "    model = load_model(filename)\n",
    "    l1 = len(seq1)\n",
    "    l2 = len(seq2)\n",
    "    output = np.zeros((max(1,l1-window),max(1,l2-window)))\n",
    "    for i in range(max(1,l1-window)):\n",
    "        for j in range(max(1,l2-window)):\n",
    "            test = transf(seq1[i:i+35],seq2[j:j+35])\n",
    "            output[i,j] = (model.predict_proba(test)[:,1])\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_benchmark(filename = 'model'):\n",
    "    model = load_model(filename)\n",
    "    test = load_datatest()\n",
    "    model.predict_proba(test)[:,1]\n",
    "    print(predictions)\n",
    "    for i,nulll in enumerate(predictions):\n",
    "        predictions[i] = round(predictions[i])\n",
    "    print(predictions,true_y)\n",
    "    perfs = calculate_performance(len(predictions), predictions, true_y)\n",
    "    print(\"batch_size : \", batch_size)\n",
    "    print(\"epochs : \",epochs)\n",
    "    print(\"acc : \", perfs[0])\n",
    "    print(\"precision : \", perfs[1])\n",
    "    print(\"sensitivity : \", perfs[2])\n",
    "    print(\"specificity : \", perfs[3])\n",
    "    print(\"MCC : \", perfs[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = train_model(Data[0],Data[1],16,6,1,1,Data[2],Data[3],Data[4],6,24,7,6,6,24,7,6,64,7,64,7,512,128,512,128,64)\n",
    "#save_model(model, \"model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

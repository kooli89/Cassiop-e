{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apprentissage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/louis_jeay/downloads/3-5-2-test/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Imports : keras 2.6.1 / tensorflow / theano / ViennaRNA package python (installer via 'conda install viennarna')\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D,Conv1D, MaxPooling1D\n",
    "from keras.models import model_from_config\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import load_model\n",
    "from keras.layers.convolutional import AveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "import RNA\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import gzip\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy import sparse\n",
    "import pdb\n",
    "from math import  sqrt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import theano\n",
    "import subprocess as sp\n",
    "import scipy.stats as stats\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import csv\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de lecture des probabilités d'accessibilité après lecture en csv\n",
    "\n",
    "def clean(seq):\n",
    "    seq = seq.split('\\n')\n",
    "    seq2 = ''\n",
    "    for j in seq:\n",
    "        seq2 = seq2 + j\n",
    "    seq2 = seq2[1:len(seq2)-1]\n",
    "    seq2 = seq2.split(' ')\n",
    "    #print(seq2)\n",
    "    seq3=[]\n",
    "    for j in seq2:\n",
    "        #print(j)\n",
    "        if j=='':\n",
    "            a=0\n",
    "        else:\n",
    "            seq3.append(float(j))\n",
    "    return seq3\n",
    "\n",
    "# Fonction de chargement des données d'apprentissage et de benchmark\n",
    "\n",
    "def load_data(nb_train = 134000,nb_val = 6000,nb_test = 25000, nb_benchmark=5000):\n",
    "    # load your data using this function\n",
    "    verif = []\n",
    "\n",
    "    verif = pd.read_csv(\"genomes/human_divers_negatifsv2.csv\", sep = \"\\t\",header=None)\n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")            \n",
    "    neg1 = verif\n",
    "    verif=[]\n",
    "\n",
    "    verif = pd.read_csv(\"genomes/human_mRNA-mRNA_negatifsv2.csv\", sep = \"\\t\",header=None)\n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "    neg2 = verif\n",
    "    verif=[]\n",
    "    verif = pd.read_csv(\"genomes/mouse_divers_negv2.csv\", sep = \"\\t\",header=None)\n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "    neg3 = verif\n",
    "    verif=[]\n",
    "    verif = pd.read_csv(\"genomes/human_diversv2_neg_suppl.csv\", sep = \"\\t\",header=None)\n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "    neg4 = verif\n",
    "    verif=[]\n",
    "    verif = pd.read_csv(\"genomes/human_mRNA-mRNA_negatifsv2_suppl.csv\", sep = \"\\t\",header=None)\n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "    neg5 = verif\n",
    "    verif=[]\n",
    "\n",
    "    verif = pd.read_csv(\"genomes/human_diversv2.csv\", sep = \"\\t\",header=None)  \n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "            \n",
    "    pos1 = verif\n",
    "    l = len(pos1)\n",
    "    verif=[]\n",
    "\n",
    "    verif = pd.read_csv(\"genomes/human_mRNA-mRNAv2.csv\", sep = \"\\t\",header=None)  \n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "            \n",
    "    pos2 = verif\n",
    "    l=l+len(pos2)\n",
    "    verif=[]\n",
    "\n",
    "    verif = pd.read_csv(\"genomes/mouse_divers_posv2.csv\", sep = \"\\t\",header=None)  \n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "            \n",
    "    pos3 = verif\n",
    "    l=l+len(pos3)\n",
    "    verif=[]\n",
    "\n",
    "    bdd = np.concatenate((pos1,pos2,pos3,neg1,neg2,neg3,neg4,neg5))\n",
    "\n",
    "    pos1 = []\n",
    "    neg1 = []\n",
    "    pos2 = []\n",
    "    neg2 = []\n",
    "    pos3 = []\n",
    "    neg3 = []\n",
    "\n",
    "    labels = np.zeros((len(bdd),1))\n",
    "\n",
    "    bdd = np.concatenate((bdd,labels),axis=1)\n",
    "    for i in range(l):\n",
    "        bdd[i,4]=1\n",
    "    labels=[]\n",
    "    \n",
    "    # shuffle total\n",
    "\n",
    "    indices = np.arange(len(bdd))\n",
    "    shuffle(indices)\n",
    "    bdd = bdd[indices]\n",
    "    indices=[]\n",
    "    print(len(bdd))\n",
    "    # \n",
    "    l = len(bdd) - nb_benchmark\n",
    "    matrice = np.zeros((l,36,36,1)) \n",
    "    matrice2 = np.zeros((l,36,4))\n",
    "    matrice3 = np.zeros((l,36,4))\n",
    "    matrice4 = np.zeros((l,36,4))\n",
    "    matrice5 = np.zeros((l,36,4))\n",
    "\n",
    "    for i in range(l):\n",
    "        seq1 = bdd[i,0][85:121]\n",
    "        seq2 = bdd[i,1][85:121]\n",
    "       \n",
    "        for j in range(len(seq1)):\n",
    "            for k in range(len(seq2)):\n",
    "                if (seq1[j]=='a' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='a'):\n",
    "                    matrice[i,j,k,0] = 1\n",
    "                elif (seq1[j]=='g' and seq2[k]=='c') or (seq1[j]=='c' and seq2[k]=='g'):\n",
    "                    matrice[i,j,k,0] = 1\n",
    "                elif (seq1[j]=='g' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='g'):\n",
    "                    matrice[i,j,k,0] = 1\n",
    "        for j in range(len(seq1)):\n",
    "            if seq1[j]=='a':\n",
    "                matrice2[i,j,0] = 1\n",
    "            elif seq1[j]=='u':\n",
    "                matrice2[i,j,1] = 1\n",
    "            elif seq1[j]=='g':\n",
    "                matrice2[i,j,2] = 1\n",
    "            elif seq1[j]=='c':\n",
    "                matrice2[i,j,3] = 1\n",
    "        for j in range(len(seq2)):\n",
    "            if seq2[j]=='a':\n",
    "                matrice3[i,j,0] = 1\n",
    "            elif seq2[j]=='u':\n",
    "                matrice3[i,j,1] = 1\n",
    "            elif seq2[j]=='g':\n",
    "                matrice3[i,j,2] = 1\n",
    "            elif seq2[j]=='c':\n",
    "                matrice3[i,j,3] = 1\n",
    "\n",
    "    for i in range(36):\n",
    "        matrice4[:,36-i-1,:] = matrice2[:,i,:]\n",
    "    for i in range(36):\n",
    "        matrice5[:,36-i-1,:] = matrice3[:,i,:]\n",
    "    \n",
    "    training = []\n",
    "    training.append(matrice[:nb_train])\n",
    "    training.append(matrice2[:nb_train])\n",
    "    training.append(matrice4[:nb_train])\n",
    "    training.append(matrice3[:nb_train])\n",
    "    training.append(matrice5[:nb_train])    \n",
    "    \n",
    "    validation = []\n",
    "    validation.append(matrice[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice2[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice4[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice3[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice5[nb_train:nb_train+nb_val])\n",
    "\n",
    "    testing = []\n",
    "    testing.append(matrice[-nb_test:])\n",
    "    testing.append(matrice2[-nb_test:])\n",
    "    testing.append(matrice4[-nb_test:])\n",
    "    testing.append(matrice3[-nb_test:])\n",
    "    testing.append(matrice5[-nb_test:])\n",
    "    \n",
    "    data_benchmark = bdd[-nb_benchmark:]\n",
    "    \n",
    "    labels = bdd[:l,4]\n",
    "    bdd = []\n",
    "    y = labels[:nb_train]\n",
    "    y = keras.utils.np_utils.to_categorical(y,2)\n",
    "    val_y = labels[nb_train:nb_train+nb_val]\n",
    "    val_y = keras.utils.np_utils.to_categorical(val_y,2)\n",
    "    true_y = labels[-nb_test:]\n",
    "\n",
    "    return training, y, validation, val_y, testing, true_y, data_benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de performances pour l'apprentissage et le benchmark : acc et MCC\n",
    "def calculate_performance(test_num, pred_y,  labels):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index in range(test_num):\n",
    "        if labels[index] ==1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp = tp +1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn = tn +1\n",
    "            else:\n",
    "                fp = fp + 1               \n",
    "            \n",
    "    acc = float(tp + tn)/test_num\n",
    "    precision = float(tp)/(tp+ fp)\n",
    "    sensitivity = float(tp)/ (tp+fn)\n",
    "    specificity = float(tn)/(tn + fp)\n",
    "    MCC = float(tp*tn-fp*fn)/(np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "    return acc, precision, sensitivity, specificity, MCC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Décommenter pour charger les données d'apprentissage :\n",
    "\n",
    "#Data = load_data(210000,6000,10000,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n"
     ]
    }
   ],
   "source": [
    "# Chargement du réseau, sans apprentissage, car les poids sont enregistrés\n",
    "\n",
    "# Décommenter pour effectuer la partie d'apprentissage et de test\n",
    "\n",
    "# Résultat de l'apprentissage : acc 75% / precision sensitivity specifity 75% / MCC = 0.51\n",
    "\n",
    "# paramètres :\n",
    "\n",
    "#true_y = Data[5]\n",
    "#training = Data[0]\n",
    "#y = Data[1]\n",
    "batch_size=96\n",
    "epochs=25\n",
    "verbose1 = 1\n",
    "verbose2 = 1\n",
    "#validation = Data[2]\n",
    "#val_y = Data[3]\n",
    "#testing = Data[4]\n",
    "matrixsize11 = 6\n",
    "nbfilter11 = 24\n",
    "matrixsize12 = 7\n",
    "nbfilter12 = 4\n",
    "matrixsize21 = 6\n",
    "nbfilter21 = 24\n",
    "matrixsize22 = 7\n",
    "nbfilter22 = 4\n",
    "nbfilter1 = 64\n",
    "kernelsize = 7\n",
    "nbfilters2 = 64\n",
    "kernel_size2 = 7\n",
    "Dense1 = 64\n",
    "Dense2 = 512\n",
    "Dense3 = 512\n",
    "Dense4 = 128\n",
    "Dense5 = 0\n",
    "\n",
    "k = matrixsize11\n",
    "# init_weights\n",
    "I = np.eye(k)\n",
    "M = np.diag(np.ones(k-1),1) + np.diag(np.ones(k-1),-1) + np.eye(k)\n",
    "I2 = np.zeros((k,k))\n",
    "M2 = np.zeros((k,k))\n",
    "for j in range(k):\n",
    "    I2[:,j] = I[:,k-j-1]\n",
    "    M2[:,j] = M[:,k-j-1]        \n",
    "W = np.zeros((k,k,1,nbfilter11))\n",
    "W[:,:,0,0] = I\n",
    "W[:,:,0,1] = I2\n",
    "W[:,:,0,2] = M\n",
    "W[:,:,0,3] = M2\n",
    "for j in range(4,nbfilter11):\n",
    "    W[:,:,0,j] = np.random.randn(k,k)*0.2\n",
    "\n",
    "\n",
    "k2 = matrixsize12\n",
    "I = np.eye(k2)\n",
    "M = np.diag(np.ones(k2-1),1) + np.diag(np.ones(k2-1),-1) + np.eye(k2)\n",
    "I2=np.zeros((k2,k2))\n",
    "M2=np.zeros((k2,k2))\n",
    "for j in range(k2):\n",
    "    I2[:,j] = I[:,k2-j-1]\n",
    "    M2[:,j] = M[:,k2-j-1]   \n",
    "\n",
    "Z = np.zeros((k2,k2,nbfilter11,nbfilter12))\n",
    "\n",
    "for u in range(nbfilter12):\n",
    "    Z[:,:,u,0] = I\n",
    "    Z[:,:,u,1] = I2\n",
    "    Z[:,:,u,2] = M\n",
    "    Z[:,:,u,3] = M2\n",
    "    for p in range(4,nbfilter12):\n",
    "        Z[:,:,u,p]=np.random.randn(k2,k2)*0.3            \n",
    "\n",
    "c2d1_input = keras.Input(shape=(36,36,1))\n",
    "cnn2d1 = Conv2D(filters = nbfilter11, kernel_size=(k,k), padding='valid', input_shape=(36,36,1),strides=(1,1),weights=[W,np.zeros(nbfilter11)])(c2d1_input)\n",
    "cnn2d1 = AveragePooling2D(pool_size=(3,3))(cnn2d1)\n",
    "cnn2d1 = Conv2D(filters = nbfilter12, kernel_size = (k2, k2),strides=(1,1),padding='valid',weights=[Z,np.zeros(nbfilter12)])(cnn2d1)\n",
    "cnn2d1 = Dropout(0.2)(cnn2d1)\n",
    "cnn2d1 = Flatten()(cnn2d1)\n",
    "\n",
    "c1d1_input = keras.Input(shape=(36,4))\n",
    "cnn1d1 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d1_input)\n",
    "cnn1d1 = MaxPooling1D(pool_size=8)(cnn1d1)\n",
    "cnn1d1 = Dropout(0.2)(cnn1d1)\n",
    "cnn1d1 = Flatten()(cnn1d1)\n",
    "\n",
    "c1d2_input = keras.Input(shape=(36,4))\n",
    "cnn1d2 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d2_input)\n",
    "cnn1d2 = MaxPooling1D(pool_size=8)(cnn1d2)\n",
    "cnn1d2 = Dropout(0.2)(cnn1d2)\n",
    "cnn1d2 = Flatten()(cnn1d2)\n",
    "\n",
    "c1d3_input = keras.Input(shape=(36,4))\n",
    "cnn1d3 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d3_input)\n",
    "cnn1d3 = MaxPooling1D(pool_size=8)(cnn1d3)\n",
    "cnn1d3 = Dropout(0.2)(cnn1d3)\n",
    "cnn1d3 = Flatten()(cnn1d3)\n",
    "\n",
    "c1d4_input = keras.Input(shape=(36,4))\n",
    "cnn1d4 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d4_input)\n",
    "cnn1d4 = MaxPooling1D(pool_size=8)(cnn1d4)\n",
    "cnn1d4 = Dropout(0.2)(cnn1d4)\n",
    "cnn1d4 = Flatten()(cnn1d4)\n",
    "\n",
    "model21 = keras.layers.concatenate([cnn1d1,cnn1d2])\n",
    "model21 = Dense(int(Dense2/2),kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model21)\n",
    "model21 = BatchNormalization()(model21)\n",
    "model21 = Activation('relu')(model21)\n",
    "model21 = Dropout(0.3)(model21)\n",
    "\n",
    "model22 = keras.layers.concatenate([cnn1d3,cnn1d4])\n",
    "model22 = Dense(int(Dense2/2),kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model22)\n",
    "model22 = BatchNormalization()(model22)\n",
    "model22 = Activation('relu')(model22)\n",
    "model22 = Dropout(0.3)(model22)\n",
    "\n",
    "model2 = keras.layers.concatenate([model21,model22])\n",
    "model2 = Dense(Dense2,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model2)\n",
    "model2 = BatchNormalization()(model2)\n",
    "model2 = Activation('relu')(model2)\n",
    "model2 = Dropout(0.3)(model2)\n",
    "\n",
    "model1 = Dense(Dense1,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(cnn2d1)\n",
    "model1 = BatchNormalization()(model1)\n",
    "model1 = Activation('relu')(model1)\n",
    "\n",
    "model = keras.layers.concatenate([model1,model2])\n",
    "model = Dense(Dense3,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Activation('relu')(model)\n",
    "model = Dense(Dense4,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Activation('relu')(model)\n",
    "\n",
    "if Dense5>0:\n",
    "    model = Dense(Dense5,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "\n",
    "model = Dense(2,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "interaction_output = Activation('softmax')(model)\n",
    "\n",
    "interaction = Model(inputs=[c2d1_input,c1d1_input,c1d2_input,c1d3_input,c1d4_input],outputs=[interaction_output])\n",
    "\n",
    "interaction.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "\n",
    "#earlystopper = EarlyStopping(monitor='val_loss', patience=3, verbose = verbose1)\n",
    "\n",
    "#print('model training')\n",
    "#interaction.fit(training, y, batch_size, epochs, verbose = verbose2, validation_data=(validation, val_y), callbacks=[earlystopper])\n",
    "\n",
    "# test   \n",
    "#print('predicting')\n",
    "#predictions = interaction.predict(testing)[:,1]\n",
    "#print(predictions)\n",
    "#for i,nulll in enumerate(predictions):\n",
    "#    predictions[i] = round(predictions[i])\n",
    "#print(predictions,true_y)\n",
    "#perfs = calculate_performance(len(predictions), predictions, true_y)\n",
    "#print(\"batch_size : \", batch_size)\n",
    "#print(\"epochs : \",epochs)\n",
    "#print(\"acc : \", perfs[0])\n",
    "#print(\"precision : \", perfs[1])\n",
    "#print(\"sensitivity : \", perfs[2])\n",
    "#print(\"specificity : \", perfs[3])\n",
    "#print(\"MCC : \", perfs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des poids du réseau : \n",
    "\n",
    "interaction.load_weights(\"model_rna-rna_deep_livrablev2sansproba.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Test benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enregistrement des données benchmark non apprises par le réseau\n",
    "benchmark = Data[6]\n",
    "bdd = benchmark\n",
    "ind_positifs = np.argwhere(bdd[:,4]==1)[:,0]\n",
    "bdd = bdd[ind_positifs]\n",
    "l = len(bdd)\n",
    "writer = csv.writer(open(\"genomes/benchmark_interactionsv2.csv\", 'w',newline=''),delimiter=\"\\t\")\n",
    "for i in range(l):\n",
    "    writer.writerow(bdd[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement des données benchmark\n",
    "datatest = pd.read_csv(\"genomes/benchmark_interactionsv2.csv\", sep = \"\\t\",header=None)\n",
    "datatest = np.array(datatest)\n",
    "sequence1=[]\n",
    "sequence2=[]\n",
    "longueur1=[]\n",
    "longueur2=[]\n",
    "l = len(datatest)\n",
    "for i in range(l):\n",
    "    data = datatest[i][0].split(' ')\n",
    "    data[0] = data[0].split('[')\n",
    "    data[0][1] = data[0][1].split('\\n')\n",
    "    data[1] = data[1].split('\\n')\n",
    "    seq1=data[0][1][0][1:-1]\n",
    "    seq2=data[1][0][1:-1]\n",
    "    len1=int(data[2])\n",
    "    len2=int(data[3])\n",
    "    sequence1.append(seq1)\n",
    "    sequence2.append(seq2)\n",
    "    longueur1.append(len1)\n",
    "    longueur2.append(len2)\n",
    "sequence1=np.array(sequence1,dtype=None,ndmin=2)\n",
    "sequence2=np.array(sequence2,dtype=None,ndmin=2)\n",
    "longueur1=np.array(longueur1,dtype=None,ndmin=2)\n",
    "longueur2=np.array(longueur2,dtype=None,ndmin=2)\n",
    "\n",
    "bdd = np.zeros((len(datatest),4))\n",
    "bdd = np.array(bdd,dtype='<U206',copy=True)\n",
    "bdd[:,0]=sequence1\n",
    "bdd[:,1]=sequence2\n",
    "bdd[:,2]=longueur1\n",
    "bdd[:,3]=longueur2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remplissage(matrice,f):\n",
    "    matrice_out = np.zeros((1,36,36,1))\n",
    "    matrice_out[0,:f,:f,0] = matrice[0,:f,:f,0]\n",
    "    return matrice_out\n",
    "def remplissage_seq(matrice,f):\n",
    "    matrice_out = np.zeros((1,36,4))\n",
    "    matrice_out[0,:f] = matrice[0,:f]\n",
    "    return matrice_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f longueur des sites à tester sur chaque séquence\n",
    "f = 25\n",
    "# s vitesse de glissement de la fenêtre de test le long des deux séquences\n",
    "s = 12\n",
    "# facteur_seuil afin de décider quelles prédictions sont considérées comme des vraies interactions\n",
    "facteur_seuil = 0.95\n",
    "#calcul des MCC sur la base de données benchmark constituées de 2433 paires de séquences dont les milieux interagissent ensemble\n",
    "mcc = np.zeros(len(bdd))\n",
    "\n",
    "for r in range(len(bdd)):\n",
    "    \n",
    "    seq1 = bdd[r,0]\n",
    "    seq2 = reverse(bdd[r,1])\n",
    "    dim = len(seq1)\n",
    "    dim2 = len(seq2)\n",
    "    matrice = np.zeros((1,dim,dim2,1)) \n",
    "    matrice2 = np.zeros((1,dim,4))\n",
    "    matrice3 = np.zeros((1,dim2,4))\n",
    "\n",
    "\n",
    "    for j in range(dim):\n",
    "        for k in range(dim2):\n",
    "            if (seq1[j]=='a' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='a'):\n",
    "                matrice[0,j,k,0] = 1\n",
    "            elif (seq1[j]=='g' and seq2[k]=='c') or (seq1[j]=='c' and seq2[k]=='g'):\n",
    "                matrice[0,j,k,0] = 1\n",
    "            elif (seq1[j]=='g' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='g'):\n",
    "                matrice[0,j,k,0] = 1\n",
    "    for j in range(dim):\n",
    "        if seq1[j]=='a':\n",
    "            matrice2[0,j,0] = 1\n",
    "        elif seq1[j]=='u':\n",
    "            matrice2[0,j,1] = 1\n",
    "        elif seq1[j]=='g':\n",
    "            matrice2[0,j,2] = 1\n",
    "        elif seq1[j]=='c':\n",
    "            matrice2[0,j,3] = 1\n",
    "    for j in range(dim2):\n",
    "        if seq2[j]=='a':\n",
    "            matrice3[0,j,0] = 1\n",
    "        elif seq2[j]=='u':\n",
    "            matrice3[0,j,1] = 1\n",
    "        elif seq2[j]=='g':\n",
    "            matrice3[0,j,2] = 1\n",
    "        elif seq2[j]=='c':\n",
    "            matrice3[0,j,3] = 1\n",
    "    u = int((dim-f+1)/s)\n",
    "    u2 = int((dim2-f+1)/s)\n",
    "    resultats = np.zeros((u,u2))\n",
    "\n",
    "    for i in range(u):\n",
    "        for j in range(u2):        \n",
    "            test = []\n",
    "            test.append(remplissage(matrice[:,i*s:i*s+36,j:j+36,:],f))\n",
    "            test.append(remplissage_seq(matrice2[:,i*s:i*s+36],f))\n",
    "            rev = np.zeros((1,36,4))\n",
    "            for q in range(36):\n",
    "                rev[:,36-q-1,:] = matrice2[:,q,:]\n",
    "            test.append(remplissage_seq(rev,f))\n",
    "            test.append(remplissage_seq(matrice3[:,j*s:j*s+36],f))\n",
    "            rev2 = np.zeros((1,36,4))\n",
    "            for q in range(36):\n",
    "                rev2[:,36-q-1,:] = matrice3[:,q,:]\n",
    "            test.append(remplissage_seq(rev2,f))\n",
    "\n",
    "            resultats[i,j] = interaction.predict(test)[:,1]\n",
    "    # seuil :\n",
    "    seuil = np.max(resultats)*facteur_seuil\n",
    "    pred = np.zeros(dim+dim2)\n",
    "    for i in range(u):\n",
    "        for j in range(u2):\n",
    "            if resultats[i,j]>seuil:\n",
    "                pred[i*s:i*s+f] = np.ones(f)\n",
    "                pred[j*s:j*s+f] = np.ones(f)\n",
    "    label = np.zeros(dim+dim2)\n",
    "    label[85:85+int(bdd[r,2])]=np.ones(int(bdd[r,2]))\n",
    "    label[dim+85:dim+85+int(bdd[r,3])]=np.ones(int(bdd[r,3]))\n",
    "    # MCC : \n",
    "    mcc[r] = calculate_performance(dim+dim2,pred,label)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06807466038244833"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

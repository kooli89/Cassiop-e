{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau de neurones basé sur iDeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential,load_model\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Concatenate, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D,Conv1D, MaxPooling1D\n",
    "from keras.models import model_from_config\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.layers import Merge\n",
    "#from keras.optimizers import kl_divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm, grid_search\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.cross_validation import train_test_split, StratifiedKFold\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, auc, roc_curve\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals import joblib \n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from random import shuffle\n",
    "import gzip\n",
    "import pdb\n",
    "from math import  sqrt\n",
    "#import theano\n",
    "import subprocess as sp\n",
    "import scipy.stats as stats\n",
    "import argparse\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_structure(structure):\n",
    "    long = len(structure)\n",
    "    a = np.zeros(25)\n",
    "    a[:long] = structure\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformer_sequence(sequence,long):\n",
    "    nucleotides = np.zeros((4,int(max(long,25))))\n",
    "    cnt = 0\n",
    "    for lettre in sequence:\n",
    "        if lettre=='a':\n",
    "            nucleotides[0,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "        elif lettre=='c':\n",
    "            nucleotides[1,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "        elif lettre=='g':\n",
    "            nucleotides[2,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "        else:\n",
    "            nucleotides[3,cnt] = 1\n",
    "            cnt = cnt+1\n",
    "    return nucleotides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_network_microRNA(nbfilter = 22):    \n",
    "    #print('configure cnn network for micro RNA sequence')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(activation=\"relu\", input_shape=(25, 4), filters=nbfilter, kernel_size=7, strides=1, padding=\"valid\"))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    \n",
    "    model.add(Dropout(0.3))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(nbfilter, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(PReLU())\n",
    "    #model.add(BatchNormalization(mode=2))\n",
    "    #model.add(Dense(64))\n",
    " \n",
    "    #model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_network_messengerRNA(nbfilter = 100):    \n",
    "    #print('configure cnn network for messenger sequence')\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(activation=\"relu\", input_shape=(101, 4), filters=nbfilter, kernel_size=7, strides=1, padding=\"valid\"))\n",
    "\n",
    "    model.add(MaxPooling1D(pool_size=3))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    #model.add(Dense(nbfilter, activation='relu'))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(PReLU())\n",
    "    #model.add(BatchNormalization(mode=2))\n",
    "    #model.add(Dense(64))    \n",
    "    \n",
    "    #model.fit(X_train, y_train)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn2D():\n",
    "    nb_conv = 4\n",
    "    nb_pool = 2\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (nb_conv, nb_conv), padding='valid', input_shape=(1, 101,4),strides=(1,1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(64, (4, 4)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp_microRNA(num_hidden = 64):\n",
    "    model = Sequential()\n",
    "\n",
    "    #model.add(Dense(num_hidden, input_dim=train.shape[1], activation='relu'))\n",
    "    model.add(Dense(num_hidden, input_shape=(25,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(num_hidden, input_dim=num_hidden, activation='relu'))\n",
    "    #model.add(Dense(num_hidden, input_shape=(num_hidden,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    '''\n",
    "    model.add(Dense(sec_num_hidden, input_shape=(num_hidden,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    '''\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mlp_messengerRNA(num_hidden = 128):\n",
    "    model = Sequential()\n",
    "\n",
    "    #model.add(Dense(num_hidden, input_dim=train.shape[1], activation='relu'))\n",
    "    model.add(Dense(num_hidden, input_shape=(101,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_hidden, input_dim=num_hidden, activation='relu'))\n",
    "    #model.add(Dense(num_hidden, input_shape=(num_hidden,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    '''\n",
    "    model.add(Dense(sec_num_hidden, input_shape=(num_hidden,), activation='relu'))\n",
    "    model.add(PReLU())\n",
    "    model.add(BatchNormalization())\n",
    "    #model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    '''\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_performance(test_num, pred_y,  labels):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    tn = 0\n",
    "    fn = 0\n",
    "    for index in range(test_num):\n",
    "        if labels[index] ==1:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tp = tp +1\n",
    "            else:\n",
    "                fn = fn + 1\n",
    "        else:\n",
    "            if labels[index] == pred_y[index]:\n",
    "                tn = tn +1\n",
    "            else:\n",
    "                fp = fp + 1               \n",
    "            \n",
    "    acc = float(tp + tn)/test_num\n",
    "    precision = float(tp)/(tp+ fp)\n",
    "    sensitivity = float(tp)/ (tp+fn)\n",
    "    specificity = float(tn)/(tn + fp)\n",
    "    MCC = float(tp*tn-fp*fn)/(np.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn)))\n",
    "    return acc, precision, sensitivity, specificity, MCC \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(seq):\n",
    "    seq = seq.split('\\n')\n",
    "    seq2 = ''\n",
    "    for j in seq:\n",
    "        seq2 = seq2 + j\n",
    "    seq2 = seq2[2:len(seq2)-1]\n",
    "    seq2 = seq2.split(' ')\n",
    "    #print(seq2)\n",
    "    seq3=[]\n",
    "    for j in seq2:\n",
    "        #print(j)\n",
    "        if j=='':\n",
    "            a=0\n",
    "        else:\n",
    "            seq3.append(float(j))\n",
    "    return seq3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lecture des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "verif = pd.read_csv(\"negatifs.csv\", sep = \"\\t\",header=None)\n",
    "verif = np.array(verif)\n",
    "for i in range(len(verif)):\n",
    "    for j in range(4):\n",
    "        if len(verif[i,j]) <= 15:\n",
    "            print(i,\"erreur\")\n",
    "            \n",
    "\n",
    "for i in range(len(verif)):\n",
    "    verif[i,2] = np.array(clean(verif[i,2]))\n",
    "    verif[i,3] = np.array(clean(verif[i,3]))    \n",
    "\n",
    "neg = verif\n",
    "\n",
    "verif = pd.read_csv(\"positifs.csv\", sep = \"\\t\",header=None)  \n",
    "verif = np.array(verif)\n",
    "for i in range(len(verif)):\n",
    "    for j in range(4):\n",
    "        if len(verif[i,j]) <= 15:\n",
    "            print(i,\"erreur\")\n",
    "            \n",
    "\n",
    "for i in range(len(verif)):\n",
    "    verif[i,2] = np.array(clean(verif[i,2]))\n",
    "    verif[i,3] = np.array(clean(verif[i,3]))\n",
    "\n",
    "pos = verif\n",
    "verif = []\n",
    "bdd = np.concatenate((pos,neg))\n",
    "pos = []\n",
    "neg = []\n",
    "labels = np.zeros((len(bdd),1))\n",
    "\n",
    "bdd = np.concatenate((bdd,labels),axis=1)\n",
    "for i in range(int(len(bdd)/2)):\n",
    "    bdd[i,4]=1    \n",
    "labels=[]\n",
    "for i in range(len(bdd)):\n",
    "    bdd[i,0] = transformer_sequence(bdd[i,0],len(bdd[i,0]))\n",
    "    bdd[i,1] = transformer_sequence(bdd[i,1],101)\n",
    "    bdd[i,2] = transformer_structure(bdd[i,2])\n",
    "\n",
    "# shuffle pour mélanger positifs et négatifs\n",
    "\n",
    "indices = np.zeros(len(bdd),dtype=int)\n",
    "for i in range(int(len(bdd)/2)):\n",
    "    indices[2*i] = int(i)\n",
    "    indices[2*i+1] = int(i + int(len(bdd)/2))\n",
    "bdd = bdd[indices]\n",
    "indices = []\n",
    "\n",
    "# shuffle total\n",
    "\n",
    "indices = np.arange(len(bdd))\n",
    "shuffle(indices)\n",
    "bdd = bdd[indices]\n",
    "\n",
    "for i in range(len(bdd)):\n",
    "    bdd[i,0] = bdd[i,0].transpose()\n",
    "    bdd[i,1] = bdd[i,1].transpose()\n",
    "\n",
    "resh0 = np.zeros((20048,25,4))\n",
    "resh1 = np.zeros((20048,101,4))\n",
    "resh2 = np.zeros((20048,25))\n",
    "resh3 = np.zeros((20048,101))\n",
    "\n",
    "for i in range(len(bdd)):\n",
    "    resh0[i,:,:] = bdd[i,0]\n",
    "    resh1[i,:,:] = bdd[i,1]\n",
    "    resh2[i,:] = bdd[i,2]\n",
    "    resh3[i,:] = bdd[i,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train = 17000\n",
    "nb_val = 500\n",
    "nb_test = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "resh0_train = resh0[:nb_train]\n",
    "resh0_val = resh0[nb_train:nb_train+nb_val]\n",
    "resh1_train = resh1[:nb_train]\n",
    "resh1_val = resh1[nb_train:nb_train+nb_val]\n",
    "resh2_train = resh2[:nb_train]\n",
    "resh2_val = resh2[nb_train:nb_train+nb_val]\n",
    "resh3_train = resh3[:nb_train]\n",
    "resh3_val = resh3[nb_train:nb_train+nb_val]\n",
    "resh0_test = resh0[-nb_test:]\n",
    "resh1_test = resh1[-nb_test:]\n",
    "resh2_test = resh2[-nb_test:]\n",
    "resh3_test = resh3[-nb_test:]\n",
    "resh0=[]\n",
    "resh1=[]\n",
    "resh2=[]\n",
    "resh3=[]\n",
    "train = bdd[:nb_train]\n",
    "valid = bdd[nb_train:nb_train+nb_val]\n",
    "y = train[:,4]\n",
    "y = keras.utils.np_utils.to_categorical(y,2)\n",
    "val_y = valid[:,4]\n",
    "val_y = keras.utils.np_utils.to_categorical(val_y,2)\n",
    "train=[]\n",
    "valid=[]\n",
    "test = bdd[-nb_test:]\n",
    "bdd = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_networks_train_predict(micro_seq_hid = 22, messenger_seq_hid = 100, batch=10000, epoch=1000, mode = True):\n",
    "    start_time = time.time()\n",
    "\n",
    "    if mode :\n",
    "        print(\"Fusion des réseaux deux à deux\")\n",
    "    else :\n",
    "        print(\"Fusion simultané\")\n",
    "    \n",
    "    print(\"Neural Network run with the following parameter : \")\n",
    "    print(\"Number of filter for the micro sequence CNN : \", micro_seq_hid)\n",
    "    print(\"Number of filter for the messenger sequence CNN : \", messenger_seq_hid)\n",
    "    print(\"Batch size : \",batch)\n",
    "    print(\"Number of epochs : \", epoch)\n",
    "    \n",
    "    print('Size of training database : ', nb_train, 'elements')\n",
    "    \n",
    "    print(\"Settings the Neural Network\")\n",
    "    \n",
    "    micro_structure_hid = 64\n",
    "    messenger_structure_hid = 128\n",
    "    \n",
    "    micro_seq_train = resh0_train\n",
    "    micro_seq_validation = resh0_val\n",
    "    micro_seq_net =  get_cnn_network_microRNA(micro_seq_hid)\n",
    "    \n",
    "    messenger_seq_train = resh1_train\n",
    "    messenger_seq_validation = resh1_val\n",
    "    messenger_seq_net = get_cnn_network_messengerRNA(messenger_seq_hid)\n",
    "    \n",
    "    micro_structure_train = resh2_train\n",
    "    micro_structure_validation = resh2_val\n",
    "    micro_structure_net = get_mlp_microRNA()\n",
    "    \n",
    "    messenger_structure_train = resh3_train\n",
    "    messenger_structure_validation = resh3_val\n",
    "    messenger_structure_net = get_mlp_messengerRNA()        \n",
    "    \n",
    "    #y, encoder = preprocess_labels(training_label)\n",
    "    #val_y, encoder = preprocess_labels(validation_label, encoder = encoder)\n",
    "       \n",
    "    training = []\n",
    "    validation = []\n",
    "    total_hid = 0\n",
    "\n",
    "    #print(\"Création des réseaux pour les deux séquences\")\n",
    "\n",
    "    training_net=[]\n",
    "    training_net.append(micro_seq_net)\n",
    "    training.append(micro_seq_train)\n",
    "    validation.append(micro_seq_validation)\n",
    "    total_hid = total_hid + micro_seq_hid\n",
    "    micro_seq_train = []\n",
    "    micro_seq_validation = [] \n",
    "    \n",
    "    training_net.append(messenger_seq_net)\n",
    "    training.append(messenger_seq_train)\n",
    "    validation.append(messenger_seq_validation)\n",
    "    total_hid = total_hid + messenger_seq_hid\n",
    "    messenger_seq_train = []\n",
    "    messenger_seq_validation = []\n",
    "    \n",
    "    if mode :\n",
    "        #print(\"Concaténation des deux séquences\")\n",
    "    \n",
    "        left = Sequential()\n",
    "        left.add(Merge(training_net, mode='concat'))\n",
    "        left.add(Dropout(0.6))\n",
    "        #print(total_hid)\n",
    "        left.add(Dense((micro_seq_hid+messenger_seq_hid), input_shape=((micro_seq_hid+messenger_seq_hid),)))\n",
    "        left.add(Activation('softmax'))\n",
    "    \n",
    "        #print(\"Création des réseaux pour les deux structures\")\n",
    "    \n",
    "        training_net=[]\n",
    "        #'''\n",
    "    \n",
    "    training_net.append(micro_structure_net)\n",
    "    training.append(micro_structure_train)\n",
    "    validation.append(micro_structure_validation)\n",
    "    total_hid = total_hid + micro_structure_hid\n",
    "    micro_structure_train = []\n",
    "    micro_structure_validation = []\n",
    "    \n",
    "    training_net.append(messenger_structure_net)\n",
    "    training.append(messenger_structure_train)\n",
    "    validation.append(messenger_structure_validation)\n",
    "    total_hid = total_hid + messenger_structure_hid\n",
    "    messenger_structure_train = []\n",
    "    messenger_structure_validation = []\n",
    "    \n",
    "    if mode :\n",
    "        #print(\"Concaténation des deux structures\")\n",
    "    \n",
    "        right = Sequential()\n",
    "        right.add(Merge(training_net, mode='concat'))\n",
    "        right.add(Dropout(0.6))\n",
    "        #print(total_hid)\n",
    "        right.add(Dense(192, input_shape=(192,)))\n",
    "        right.add(Activation('softmax'))\n",
    "    \n",
    "        #print(\"Concaténation des deux modèles\")\n",
    "        #'''\n",
    "    \n",
    "    model = Sequential()\n",
    "    if mode :\n",
    "        model.add(Merge([left,right], mode='concat'))\n",
    "    else :\n",
    "        model.add(Merge(training_net, mode='concat'))\n",
    " \n",
    "    #model.add(Dense(total_hid, input_shape=(total_hid,)))\n",
    "    #model.add(Activation('relu'))\n",
    "    #model.add(PReLU())\n",
    "    #model.add(BatchNormalization(mode=2))\n",
    "    #model.add(Activation('relu'))\n",
    "    \n",
    "    model.add(Dropout(0.6))\n",
    "    #print(total_hid)\n",
    "    model.add(Dense(2, input_shape=(total_hid,)))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    #sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop')\n",
    "    \n",
    "    \n",
    "    #checkpointer = ModelCheckpoint(filepath=\"models/bestmodel.hdf5\", verbose=0, save_best_only=True)\n",
    "    earlystopper = EarlyStopping(monitor='val_loss', patience=5, verbose=0)\n",
    "    #validation_data=(np.transpose(validmat['validxdata'],axes=(0,2,1)), validmat['validdata']), callbacks=[checkpointer,earlystopper]\n",
    "    print('model training')\n",
    "    model.fit(training, y, batch_size=batch, epochs=epoch, verbose=0, validation_data=(validation, val_y), callbacks=[earlystopper])\n",
    "    print('training finished')\n",
    "    training = []\n",
    "    validation = []\n",
    "    \n",
    "    # test\n",
    "    true_y = test[:,4]\n",
    "    \n",
    "    print('predicting')\n",
    "    testing = []\n",
    "    testing.append(resh0_test)\n",
    "    testing.append(resh1_test)\n",
    "    testing.append(resh2_test)\n",
    "    testing.append(resh3_test)\n",
    "        \n",
    "    predictions = model.predict_proba(testing)[:,1]\n",
    "    #print(predictions)\n",
    "    for i,nulll in enumerate(predictions):\n",
    "        predictions[i] = round(predictions[i])\n",
    "    #print(predictions,true_y)\n",
    "    perfs = calculate_performance(len(predictions), predictions, true_y)\n",
    "    print(\"acc : \", perfs[0])\n",
    "    print(\"precision : \", perfs[1])\n",
    "    print(\"sensitivity : \", perfs[2])\n",
    "    print(\"specificity : \", perfs[3])\n",
    "    print(\"MCC : \", perfs[4])\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    print(\"Elapsed Time : \",elapsed_time//60,\" min \",elapsed_time%60,\" sec\")\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  750\n",
      "Number of epochs :  75\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conspiracy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:66: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/conspiracy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:95: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "/home/conspiracy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:106: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5968\n",
      "precision :  0.6003223207091055\n",
      "sensitivity :  0.5926809864757359\n",
      "specificity :  0.6009654062751408\n",
      "MCC :  0.19364837578258573\n",
      "Elapsed Time :  6.0  min  4.4944376945495605  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  750\n",
      "Number of epochs :  75\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/conspiracy/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:108: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.586\n",
      "precision :  0.5806686046511628\n",
      "sensitivity :  0.6356404136833731\n",
      "specificity :  0.5358004827031375\n",
      "MCC :  0.1723158629727202\n",
      "Elapsed Time :  2.0  min  47.03413772583008  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  760\n",
      "Number of epochs :  76\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5964\n",
      "precision :  0.596875\n",
      "sensitivity :  0.6077963404932378\n",
      "specificity :  0.584875301689461\n",
      "MCC :  0.19272413361310226\n",
      "Elapsed Time :  5.0  min  20.44149661064148  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  760\n",
      "Number of epochs :  76\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.578\n",
      "precision :  0.5539529914529915\n",
      "sensitivity :  0.8249801113762928\n",
      "specificity :  0.32823813354786807\n",
      "MCC :  0.17663669997499706\n",
      "Elapsed Time :  1.0  min  51.21043348312378  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  770\n",
      "Number of epochs :  77\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5956\n",
      "precision :  0.5876068376068376\n",
      "sensitivity :  0.6563245823389021\n",
      "specificity :  0.5341914722445696\n",
      "MCC :  0.1919755636070732\n",
      "Elapsed Time :  7.0  min  29.70896601676941  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  770\n",
      "Number of epochs :  77\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5932\n",
      "precision :  0.5820793433652531\n",
      "sensitivity :  0.6770087509944311\n",
      "specificity :  0.5084473049074819\n",
      "MCC :  0.18817930468181956\n",
      "Elapsed Time :  4.0  min  34.30656599998474  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  780\n",
      "Number of epochs :  78\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5964\n",
      "precision :  0.5919881305637982\n",
      "sensitivity :  0.6348448687350835\n",
      "specificity :  0.5575221238938053\n",
      "MCC :  0.1929579040179048\n",
      "Elapsed Time :  5.0  min  9.797364473342896  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  780\n",
      "Number of epochs :  78\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5852\n",
      "precision :  0.5729442970822282\n",
      "sensitivity :  0.6873508353221957\n",
      "specificity :  0.48189863234111024\n",
      "MCC :  0.17297128337075823\n",
      "Elapsed Time :  2.0  min  24.929673671722412  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  790\n",
      "Number of epochs :  79\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.598\n",
      "precision :  0.6044776119402985\n",
      "sensitivity :  0.5799522673031027\n",
      "specificity :  0.6162510056315366\n",
      "MCC :  0.19632185945958905\n",
      "Elapsed Time :  6.0  min  59.77876091003418  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  790\n",
      "Number of epochs :  79\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5768\n",
      "precision :  0.5574812247255921\n",
      "sensitivity :  0.7677008750994431\n",
      "specificity :  0.3837489943684634\n",
      "MCC :  0.16408179660968253\n",
      "Elapsed Time :  2.0  min  29.404582977294922  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  800\n",
      "Number of epochs :  80\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5888\n",
      "precision :  0.5989628349178912\n",
      "sensitivity :  0.5513126491646778\n",
      "specificity :  0.6267095736122285\n",
      "MCC :  0.1785141871248939\n",
      "Elapsed Time :  8.0  min  2.3429784774780273  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  800\n",
      "Number of epochs :  80\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5772\n",
      "precision :  0.5584112149532711\n",
      "sensitivity :  0.7605409705648369\n",
      "specificity :  0.3917940466613033\n",
      "MCC :  0.16394114360217002\n",
      "Elapsed Time :  4.0  min  48.565786361694336  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  810\n",
      "Number of epochs :  81\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5912\n",
      "precision :  0.5854545454545454\n",
      "sensitivity :  0.6404136833731106\n",
      "specificity :  0.5414320193081255\n",
      "MCC :  0.18275894200941295\n",
      "Elapsed Time :  7.0  min  34.76565861701965  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  810\n",
      "Number of epochs :  81\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5804\n",
      "precision :  0.5898100172711571\n",
      "sensitivity :  0.543357199681782\n",
      "specificity :  0.6178600160901045\n",
      "MCC :  0.1616531166435272\n",
      "Elapsed Time :  4.0  min  48.33055567741394  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  820\n",
      "Number of epochs :  82\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5948\n",
      "precision :  0.6023489932885906\n",
      "sensitivity :  0.5712012728719172\n",
      "specificity :  0.6186645213193885\n",
      "MCC :  0.1900675312130215\n",
      "Elapsed Time :  9.0  min  16.60387349128723  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  820\n",
      "Number of epochs :  82\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.574\n",
      "precision :  0.573394495412844\n",
      "sensitivity :  0.5966587112171837\n",
      "specificity :  0.5510860820595334\n",
      "MCC :  0.147901775711055\n",
      "Elapsed Time :  6.0  min  11.928408145904541  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  830\n",
      "Number of epochs :  83\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5916\n",
      "precision :  0.5841654778887304\n",
      "sensitivity :  0.6515513126491647\n",
      "specificity :  0.5309734513274337\n",
      "MCC :  0.1838864894456518\n",
      "Elapsed Time :  10.0  min  18.28239917755127  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  830\n",
      "Number of epochs :  83\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5644\n",
      "precision :  0.6063291139240506\n",
      "sensitivity :  0.381066030230708\n",
      "specificity :  0.7497988736926791\n",
      "MCC :  0.1407391076199548\n",
      "Elapsed Time :  3.0  min  21.014784336090088  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  840\n",
      "Number of epochs :  84\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.59\n",
      "precision :  0.5823863636363636\n",
      "sensitivity :  0.6523468575974543\n",
      "specificity :  0.5269509251810137\n",
      "MCC :  0.18074466019020616\n",
      "Elapsed Time :  9.0  min  53.256837368011475  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  840\n",
      "Number of epochs :  84\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5864\n",
      "precision :  0.5732107682206172\n",
      "sensitivity :  0.6945107398568019\n",
      "specificity :  0.4770716009654063\n",
      "MCC :  0.17582416275574894\n",
      "Elapsed Time :  5.0  min  12.407956600189209  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  850\n",
      "Number of epochs :  85\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5884\n",
      "precision :  0.581081081081081\n",
      "sensitivity :  0.6499602227525855\n",
      "specificity :  0.5261464199517297\n",
      "MCC :  0.17749152448064173\n",
      "Elapsed Time :  9.0  min  23.882433891296387  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  850\n",
      "Number of epochs :  85\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.578\n",
      "precision :  0.562192118226601\n",
      "sensitivity :  0.726332537788385\n",
      "specificity :  0.42799678197908286\n",
      "MCC :  0.16173595587245257\n",
      "Elapsed Time :  3.0  min  18.464837789535522  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  860\n",
      "Number of epochs :  86\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5884\n",
      "precision :  0.5872894333843798\n",
      "sensitivity :  0.6101829753381066\n",
      "specificity :  0.5663716814159292\n",
      "MCC :  0.1767293288486595\n",
      "Elapsed Time :  7.0  min  47.449936389923096  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  860\n",
      "Number of epochs :  86\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5716\n",
      "precision :  0.5695067264573991\n",
      "sensitivity :  0.6062052505966588\n",
      "specificity :  0.5366049879324215\n",
      "MCC :  0.14316320980069333\n",
      "Elapsed Time :  2.0  min  8.191717147827148  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  870\n",
      "Number of epochs :  87\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5976\n",
      "precision :  0.6046705587989991\n",
      "sensitivity :  0.5767700875099443\n",
      "specificity :  0.6186645213193885\n",
      "MCC :  0.1955944093355246\n",
      "Elapsed Time :  7.0  min  6.622240781784058  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  870\n",
      "Number of epochs :  87\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5896\n",
      "precision :  0.5819730305180979\n",
      "sensitivity :  0.6523468575974543\n",
      "specificity :  0.5261464199517297\n",
      "MCC :  0.1799522145469211\n",
      "Elapsed Time :  5.0  min  9.97807002067566  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  880\n",
      "Number of epochs :  88\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5892\n",
      "precision :  0.5851851851851851\n",
      "sensitivity :  0.6284805091487669\n",
      "specificity :  0.5494770716009654\n",
      "MCC :  0.1785269937278652\n",
      "Elapsed Time :  9.0  min  44.61150074005127  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  880\n",
      "Number of epochs :  88\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5848\n",
      "precision :  0.5714285714285714\n",
      "sensitivity :  0.6968973747016707\n",
      "specificity :  0.47144006436041835\n",
      "MCC :  0.1728222299544553\n",
      "Elapsed Time :  3.0  min  10.342767238616943  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  890\n",
      "Number of epochs :  89\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.59\n",
      "precision :  0.5766182298546896\n",
      "sensitivity :  0.6945107398568019\n",
      "specificity :  0.48431214802896216\n",
      "MCC :  0.18294683995790958\n",
      "Elapsed Time :  7.0  min  18.416430711746216  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  890\n",
      "Number of epochs :  89\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5848\n",
      "precision :  0.5673017824216349\n",
      "sensitivity :  0.7342879872712809\n",
      "specificity :  0.4336283185840708\n",
      "MCC :  0.17611452512575695\n",
      "Elapsed Time :  3.0  min  56.84073281288147  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  900\n",
      "Number of epochs :  90\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5956\n",
      "precision :  0.5984\n",
      "sensitivity :  0.5950676213206046\n",
      "specificity :  0.5961383748994369\n",
      "MCC :  0.19120299808651517\n",
      "Elapsed Time :  6.0  min  59.647019386291504  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  900\n",
      "Number of epochs :  90\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5768\n",
      "precision :  0.5796637309847879\n",
      "sensitivity :  0.5759745425616547\n",
      "specificity :  0.5776347546259051\n",
      "MCC :  0.15360693772912418\n",
      "Elapsed Time :  3.0  min  0.21540236473083496  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  910\n",
      "Number of epochs :  91\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.588\n",
      "precision :  0.5857898715041572\n",
      "sensitivity :  0.6165473349244233\n",
      "specificity :  0.5591311343523733\n",
      "MCC :  0.17597605937601205\n",
      "Elapsed Time :  9.0  min  7.675851821899414  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  910\n",
      "Number of epochs :  91\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5912\n",
      "precision :  0.5796610169491525\n",
      "sensitivity :  0.6801909307875895\n",
      "specificity :  0.501206757843926\n",
      "MCC :  0.18440683298040622\n",
      "Elapsed Time :  4.0  min  44.244300365448  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  920\n",
      "Number of epochs :  92\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5908\n",
      "precision :  0.5986509274873525\n",
      "sensitivity :  0.5648369132856006\n",
      "specificity :  0.6170555108608206\n",
      "MCC :  0.18212844810288806\n",
      "Elapsed Time :  7.0  min  7.848782539367676  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  920\n",
      "Number of epochs :  92\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5768\n",
      "precision :  0.5968841285296982\n",
      "sensitivity :  0.48766905330151156\n",
      "specificity :  0.666934835076428\n",
      "MCC :  0.157122007896668\n",
      "Elapsed Time :  3.0  min  18.75367259979248  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  930\n",
      "Number of epochs :  93\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5924\n",
      "precision :  0.6008474576271187\n",
      "sensitivity :  0.5640413683373111\n",
      "specificity :  0.6210780370072405\n",
      "MCC :  0.18540744981251367\n",
      "Elapsed Time :  10.0  min  0.5060296058654785  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  930\n",
      "Number of epochs :  93\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5832\n",
      "precision :  0.5735797399041752\n",
      "sensitivity :  0.6666666666666666\n",
      "specificity :  0.498793242156074\n",
      "MCC :  0.1678661392022502\n",
      "Elapsed Time :  3.0  min  35.031095027923584  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  940\n",
      "Number of epochs :  94\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5964\n",
      "precision :  0.6031613976705491\n",
      "sensitivity :  0.5767700875099443\n",
      "specificity :  0.6162510056315366\n",
      "MCC :  0.1931605324824176\n",
      "Elapsed Time :  7.0  min  19.820374488830566  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  940\n",
      "Number of epochs :  94\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5824\n",
      "precision :  0.5626839317245439\n",
      "sensitivity :  0.7605409705648369\n",
      "specificity :  0.4022526146419952\n",
      "MCC :  0.17443255551171047\n",
      "Elapsed Time :  3.0  min  7.564631700515747  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  950\n",
      "Number of epochs :  95\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5968\n",
      "precision :  0.6\n",
      "sensitivity :  0.594272076372315\n",
      "specificity :  0.5993563958165729\n",
      "MCC :  0.19362698509271742\n",
      "Elapsed Time :  6.0  min  59.238712549209595  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  950\n",
      "Number of epochs :  95\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5848\n",
      "precision :  0.5943152454780362\n",
      "sensitivity :  0.548926014319809\n",
      "specificity :  0.6210780370072405\n",
      "MCC :  0.17043393684565072\n",
      "Elapsed Time :  2.0  min  15.613564014434814  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  960\n",
      "Number of epochs :  96\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5944\n",
      "precision :  0.5912847483095417\n",
      "sensitivity :  0.6260938743038982\n",
      "specificity :  0.5623491552695092\n",
      "MCC :  0.18883695880656973\n",
      "Elapsed Time :  8.0  min  25.54372000694275  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  960\n",
      "Number of epochs :  96\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5848\n",
      "precision :  0.5836516424751719\n",
      "sensitivity :  0.6077963404932378\n",
      "specificity :  0.5615446500402252\n",
      "MCC :  0.169527280367613\n",
      "Elapsed Time :  4.0  min  48.881362438201904  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  970\n",
      "Number of epochs :  97\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5912\n",
      "precision :  0.5981620718462823\n",
      "sensitivity :  0.569610182975338\n",
      "specificity :  0.6130329847144006\n",
      "MCC :  0.1828046972268682\n",
      "Elapsed Time :  7.0  min  32.631961822509766  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  970\n",
      "Number of epochs :  97\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5652\n",
      "precision :  0.5540712468193384\n",
      "sensitivity :  0.6929196499602227\n",
      "specificity :  0.4360418342719228\n",
      "MCC :  0.13346364052131576\n",
      "Elapsed Time :  1.0  min  52.1924843788147  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  980\n",
      "Number of epochs :  98\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5944\n",
      "precision :  0.5791530944625407\n",
      "sensitivity :  0.7072394590294352\n",
      "specificity :  0.48028962188254226\n",
      "MCC :  0.19259897952845761\n",
      "Elapsed Time :  5.0  min  14.991668701171875  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  980\n",
      "Number of epochs :  98\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5852\n",
      "precision :  0.6145833333333334\n",
      "sensitivity :  0.4693715194908512\n",
      "specificity :  0.7023330651649236\n",
      "MCC :  0.176518048548508\n",
      "Elapsed Time :  4.0  min  12.77432370185852  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  990\n",
      "Number of epochs :  99\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5916\n",
      "precision :  0.59688013136289\n",
      "sensitivity :  0.5783611774065235\n",
      "specificity :  0.6049879324215608\n",
      "MCC :  0.18340634333186634\n",
      "Elapsed Time :  7.0  min  38.55037879943848  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  990\n",
      "Number of epochs :  99\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5948\n",
      "precision :  0.5860366713681241\n",
      "sensitivity :  0.6610978520286396\n",
      "specificity :  0.5277554304102977\n",
      "MCC :  0.19057941741402723\n",
      "Elapsed Time :  3.0  min  22.78941559791565  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1000\n",
      "Number of epochs :  100\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5968\n",
      "precision :  0.5905454545454546\n",
      "sensitivity :  0.6459824980111376\n",
      "specificity :  0.5470635559131134\n",
      "MCC :  0.1940155420451885\n",
      "Elapsed Time :  5.0  min  16.07658576965332  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1000\n",
      "Number of epochs :  100\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5896\n",
      "precision :  0.5874337623012869\n",
      "sensitivity :  0.6173428798727129\n",
      "specificity :  0.5615446500402252\n",
      "MCC :  0.17917398757346725\n",
      "Elapsed Time :  3.0  min  8.51650619506836  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1010\n",
      "Number of epochs :  101\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5988\n",
      "precision :  0.5957767722473605\n",
      "sensitivity :  0.6284805091487669\n",
      "specificity :  0.5687851971037812\n",
      "MCC :  0.1976282315176601\n",
      "Elapsed Time :  6.0  min  32.32444643974304  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1010\n",
      "Number of epochs :  101\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.58\n",
      "precision :  0.5628415300546448\n",
      "sensitivity :  0.7374701670644391\n",
      "specificity :  0.42075623491552694\n",
      "MCC :  0.16686330470117897\n",
      "Elapsed Time :  3.0  min  41.3087317943573  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1020\n",
      "Number of epochs :  102\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.592\n",
      "precision :  0.5868131868131868\n",
      "sensitivity :  0.6372315035799523\n",
      "specificity :  0.5462590506838294\n",
      "MCC :  0.184269161334671\n",
      "Elapsed Time :  7.0  min  35.51843738555908  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1020\n",
      "Number of epochs :  102\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5832\n",
      "precision :  0.5744975744975745\n",
      "sensitivity :  0.6595067621320605\n",
      "specificity :  0.5060337892196299\n",
      "MCC :  0.16754711005918574\n",
      "Elapsed Time :  3.0  min  8.92111349105835  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1030\n",
      "Number of epochs :  103\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5928\n",
      "precision :  0.5854181558255898\n",
      "sensitivity :  0.6515513126491647\n",
      "specificity :  0.5333869670152857\n",
      "MCC :  0.18626338870391826\n",
      "Elapsed Time :  6.0  min  1.3287596702575684  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1030\n",
      "Number of epochs :  103\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.586\n",
      "precision :  0.5912828947368421\n",
      "sensitivity :  0.5719968178202068\n",
      "specificity :  0.6001609010458568\n",
      "MCC :  0.1722187383551967\n",
      "Elapsed Time :  3.0  min  10.007002830505371  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1040\n",
      "Number of epochs :  104\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5912\n",
      "precision :  0.5927387529597474\n",
      "sensitivity :  0.5974542561654733\n",
      "specificity :  0.584875301689461\n",
      "MCC :  0.18234356281756556\n",
      "Elapsed Time :  7.0  min  26.10066795349121  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1040\n",
      "Number of epochs :  104\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5892\n",
      "precision :  0.6161616161616161\n",
      "sensitivity :  0.48528241845664283\n",
      "specificity :  0.6942880128720836\n",
      "MCC :  0.18358278673810366\n",
      "Elapsed Time :  3.0  min  18.654863834381104  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1050\n",
      "Number of epochs :  105\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5916\n",
      "precision :  0.5861313868613138\n",
      "sensitivity :  0.6388225934765315\n",
      "specificity :  0.5438455349959774\n",
      "MCC :  0.18351284877597399\n",
      "Elapsed Time :  8.0  min  6.802463054656982  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1050\n",
      "Number of epochs :  105\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5816\n",
      "precision :  0.5670692943420216\n",
      "sensitivity :  0.7096260938743039\n",
      "specificity :  0.45213193885760256\n",
      "MCC :  0.167442165205992\n",
      "Elapsed Time :  3.0  min  11.031574487686157  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1060\n",
      "Number of epochs :  106\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5844\n",
      "precision :  0.5973214285714286\n",
      "sensitivity :  0.5322195704057279\n",
      "specificity :  0.6371681415929203\n",
      "MCC :  0.1703085888491634\n",
      "Elapsed Time :  7.0  min  33.874361991882324  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1060\n",
      "Number of epochs :  106\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5832\n",
      "precision :  0.5679949399114484\n",
      "sensitivity :  0.7143993635640413\n",
      "specificity :  0.4505229283990346\n",
      "MCC :  0.1710247145229862\n",
      "Elapsed Time :  4.0  min  31.639618396759033  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1070\n",
      "Number of epochs :  107\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5976\n",
      "precision :  0.6071733561058924\n",
      "sensitivity :  0.5656324582338902\n",
      "specificity :  0.6299275945293644\n",
      "MCC :  0.19594871099923478\n",
      "Elapsed Time :  6.0  min  35.41947650909424  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1070\n",
      "Number of epochs :  107\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.59\n",
      "precision :  0.612621359223301\n",
      "sensitivity :  0.5019888623707239\n",
      "specificity :  0.6790024135156878\n",
      "MCC :  0.18385843750887834\n",
      "Elapsed Time :  4.0  min  8.24721384048462  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1080\n",
      "Number of epochs :  108\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5888\n",
      "precision :  0.5893832943013271\n",
      "sensitivity :  0.6006364359586317\n",
      "specificity :  0.5768302493966211\n",
      "MCC :  0.17751850154181992\n",
      "Elapsed Time :  8.0  min  9.275260925292969  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1080\n",
      "Number of epochs :  108\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5828\n",
      "precision :  0.5793768545994066\n",
      "sensitivity :  0.6213206046141607\n",
      "specificity :  0.5438455349959774\n",
      "MCC :  0.16567349563645875\n",
      "Elapsed Time :  3.0  min  29.44244647026062  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1090\n",
      "Number of epochs :  109\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5928\n",
      "precision :  0.5922779922779923\n",
      "sensitivity :  0.6101829753381066\n",
      "specificity :  0.5752212389380531\n",
      "MCC :  0.18552156406468534\n",
      "Elapsed Time :  6.0  min  3.5109775066375732  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1090\n",
      "Number of epochs :  109\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.578\n",
      "precision :  0.5834710743801653\n",
      "sensitivity :  0.5616547334924423\n",
      "specificity :  0.5945293644408689\n",
      "MCC :  0.15626167541729263\n",
      "Elapsed Time :  4.0  min  26.679027318954468  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1100\n",
      "Number of epochs :  110\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.59\n",
      "precision :  0.6010452961672473\n",
      "sensitivity :  0.548926014319809\n",
      "specificity :  0.6315366049879324\n",
      "MCC :  0.18106360789902265\n",
      "Elapsed Time :  7.0  min  29.167505502700806  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1100\n",
      "Number of epochs :  110\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5804\n",
      "precision :  0.5720221606648199\n",
      "sensitivity :  0.6571201272871917\n",
      "specificity :  0.502815768302494\n",
      "MCC :  0.16189505887025385\n",
      "Elapsed Time :  4.0  min  26.554065227508545  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1110\n",
      "Number of epochs :  111\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5952\n",
      "precision :  0.5940138142747505\n",
      "sensitivity :  0.6157517899761337\n",
      "specificity :  0.5744167337087691\n",
      "MCC :  0.19033670864356267\n",
      "Elapsed Time :  7.0  min  40.33420991897583  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1110\n",
      "Number of epochs :  111\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5824\n",
      "precision :  0.5618826263800116\n",
      "sensitivity :  0.7692919649960223\n",
      "specificity :  0.3934030571198713\n",
      "MCC :  0.17563792774050552\n",
      "Elapsed Time :  2.0  min  50.48416447639465  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1120\n",
      "Number of epochs :  112\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5896\n",
      "precision :  0.5765407554671969\n",
      "sensitivity :  0.6921241050119332\n",
      "specificity :  0.48592115848753015\n",
      "MCC :  0.18199195099387053\n",
      "Elapsed Time :  12.0  min  13.929133892059326  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1120\n",
      "Number of epochs :  112\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5896\n",
      "precision :  0.6054794520547945\n",
      "sensitivity :  0.5274463007159904\n",
      "specificity :  0.6524537409493162\n",
      "MCC :  0.1812964271270079\n",
      "Elapsed Time :  2.0  min  47.41024684906006  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1130\n",
      "Number of epochs :  113\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5968\n",
      "precision :  0.598731165741475\n",
      "sensitivity :  0.6006364359586317\n",
      "specificity :  0.5929203539823009\n",
      "MCC :  0.1935612497833662\n",
      "Elapsed Time :  7.0  min  33.06935358047485  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1130\n",
      "Number of epochs :  113\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5704\n",
      "precision :  0.549009105516872\n",
      "sensitivity :  0.8154335719968179\n",
      "specificity :  0.32260659694288013\n",
      "MCC :  0.1587211024326326\n",
      "Elapsed Time :  4.0  min  6.333738803863525  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1140\n",
      "Number of epochs :  114\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5888\n",
      "precision :  0.5876052027543994\n",
      "sensitivity :  0.6109785202863962\n",
      "specificity :  0.5663716814159292\n",
      "MCC :  0.17753209344644486\n",
      "Elapsed Time :  7.0  min  10.173409223556519  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1140\n",
      "Number of epochs :  114\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5856\n",
      "precision :  0.5656565656565656\n",
      "sensitivity :  0.7573587907716786\n",
      "specificity :  0.41190667739340303\n",
      "MCC :  0.1804340443169055\n",
      "Elapsed Time :  3.0  min  18.09311270713806  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1150\n",
      "Number of epochs :  115\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5896\n",
      "precision :  0.5952184666117065\n",
      "sensitivity :  0.5743834526650756\n",
      "specificity :  0.6049879324215608\n",
      "MCC :  0.17944720197828054\n",
      "Elapsed Time :  7.0  min  24.69422936439514  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1150\n",
      "Number of epochs :  115\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.566\n",
      "precision :  0.5451680672268907\n",
      "sensitivity :  0.8257756563245824\n",
      "specificity :  0.3032984714400644\n",
      "MCC :  0.15145576195310453\n",
      "Elapsed Time :  3.0  min  5.59475040435791  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1160\n",
      "Number of epochs :  116\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.586\n",
      "precision :  0.5823442136498517\n",
      "sensitivity :  0.624502784407319\n",
      "specificity :  0.5470635559131134\n",
      "MCC :  0.17209335643209311\n",
      "Elapsed Time :  7.0  min  48.86770009994507  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1160\n",
      "Number of epochs :  116\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.588\n",
      "precision :  0.5738451528952505\n",
      "sensitivity :  0.7016706443914081\n",
      "specificity :  0.47304907481898634\n",
      "MCC :  0.1795126462071145\n",
      "Elapsed Time :  4.0  min  39.61837649345398  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1170\n",
      "Number of epochs :  117\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5888\n",
      "precision :  0.5884169884169884\n",
      "sensitivity :  0.6062052505966588\n",
      "specificity :  0.5711987127916331\n",
      "MCC :  0.17751624949607264\n",
      "Elapsed Time :  10.0  min  50.88996744155884  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1170\n",
      "Number of epochs :  117\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.59\n",
      "precision :  0.5783783783783784\n",
      "sensitivity :  0.6809864757358791\n",
      "specificity :  0.49798873692679\n",
      "MCC :  0.18208121668108324\n",
      "Elapsed Time :  4.0  min  17.34900188446045  sec\n",
      "\n",
      "\n",
      "Fusion des réseaux deux à deux\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1180\n",
      "Number of epochs :  118\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n",
      "training finished\n",
      "predicting\n",
      "acc :  0.5884\n",
      "precision :  0.58675799086758\n",
      "sensitivity :  0.6133651551312649\n",
      "specificity :  0.5631536604987932\n",
      "MCC :  0.17674786678186594\n",
      "Elapsed Time :  7.0  min  27.56390643119812  sec\n",
      "\n",
      "\n",
      "Fusion simultané\n",
      "Neural Network run with the following parameter : \n",
      "Number of filter for the micro sequence CNN :  25\n",
      "Number of filter for the messenger sequence CNN :  116\n",
      "Batch size :  1180\n",
      "Number of epochs :  118\n",
      "Size of training database :  17000 elements\n",
      "Settings the Neural Network\n",
      "model training\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()   \n",
    "i = 25\n",
    "j = 116\n",
    "for k in range (750, 1200, 10):\n",
    "    m = merge_networks_train_predict(i,j,k,k//10,True)\n",
    "    m = merge_networks_train_predict(i,j,k,k//10,False)\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Total Elapsed Time : \",elapsed_time//60,\" min \",elapsed_time%60,\" sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network run with the following parameter : \n",
    "Number of filter for the micro sequence CNN :  27\n",
    "Number of filter for the messenger sequence CNN :  115\n",
    "Batch size :  800\n",
    "Number of epochs :  80\n",
    "Size of training database :  17000 elements\n",
    "training finished\n",
    "predicting\n",
    "[0.66268104 0.5558354  0.33351898 ... 0.6252597  0.34933755 0.5189561 ]\n",
    "[1. 1. 0. ... 1. 0. 1.] [1 1 0.0 ... 1 1 1]\n",
    "acc :  0.6008\n",
    "precision :  0.61875\n",
    "sensitivity :  0.48450244698205547\n",
    "specificity :  0.7127158555729984\n",
    "MCC :  0.2027128075842045\n",
    "Elapsed Time :  9.0  min  54.87723112106323  sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "acc :  0.6096\n",
    "precision :  0.6086956521739131\n",
    "sensitivity :  0.5979049153908138\n",
    "specificity :  0.6211278792692613\n",
    "MCC :  0.21909450356110444"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 100 trains : \n",
    "acc :  0.5\n",
    "precision :  0.5333333333333333\n",
    "sensitivity :  0.7272727272727273\n",
    "specificity :  0.2222222222222222\n",
    "MCC :  -0.058025885318565944\n",
    "\n",
    "##### 17000 trains\n",
    "acc :  0.5964\n",
    "precision :  0.6069017254313578\n",
    "sensitivity :  0.625193199381762\n",
    "specificity :  0.5655058043117744\n",
    "MCC :  0.19100235122777048\n",
    "##### \n",
    "acc :  0.5564\n",
    "precision :  0.5346628679962013\n",
    "sensitivity :  0.8972111553784861\n",
    "specificity :  0.21285140562248997\n",
    "MCC :  0.15103195995226454\n",
    "(10000 batch et 1000 epochs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/DATA/anaconda3/envs/keras/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/media/DATA/anaconda3/envs/keras/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/media/DATA/anaconda3/envs/keras/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Concatenate, concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.utils import np_utils, generic_utils\n",
    "from keras.optimizers import SGD, RMSprop, Adadelta, Adagrad, Adam\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D,Conv1D, MaxPooling1D\n",
    "from keras.models import model_from_config\n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.constraints import maxnorm\n",
    "from keras.models import load_model\n",
    "from keras.layers.convolutional import AveragePooling2D\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import gzip\n",
    "from sklearn import svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.externals import joblib \n",
    "from scipy import sparse\n",
    "import pdb\n",
    "from math import  sqrt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import theano\n",
    "import subprocess as sp\n",
    "import scipy.stats as stats\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import csv\n",
    "from random import shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.core import Lambda\n",
    "from keras.models import Sequential\n",
    "from tensorflow.python.framework import ops\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import keras\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean(seq):\n",
    "    seq = seq.split('\\n')\n",
    "    seq2 = ''\n",
    "    for j in seq:\n",
    "        seq2 = seq2 + j\n",
    "    seq2 = seq2[2:len(seq2)-1]\n",
    "    seq2 = seq2.split(' ')\n",
    "    #print(seq2)\n",
    "    seq3=[]\n",
    "    for j in seq2:\n",
    "        #print(j)\n",
    "        if j=='':\n",
    "            a=0\n",
    "        else:\n",
    "            seq3.append(float(j))\n",
    "    return seq3\n",
    "\n",
    "def load_data(nb_train = 165000,nb_val = 6000,nb_test = 5000):\n",
    "    # load your data using this function\n",
    "    verif = []\n",
    "\n",
    "    verif = pd.read_csv(\"genomes/negatifs_m-m-str.csv\", sep = \"\\t\",header=None)\n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "            \n",
    "\n",
    "    neg1 = verif\n",
    "\n",
    "    verif=[]\n",
    "\n",
    "    verif = pd.read_csv(\"genomes/negatifs_divers-str.csv\", sep = \"\\t\",header=None)\n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "    neg2 = verif\n",
    "    verif=[]\n",
    "    verif = pd.read_csv(\"genomes/negatifs_mouse_divers-str.csv\", sep = \"\\t\",header=None)\n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "    neg3 = verif\n",
    "    verif=[]\n",
    "\n",
    "    verif = pd.read_csv(\"genomes/positifs_m-m-str.csv\", sep = \"\\t\",header=None)  \n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "            \n",
    "    pos1 = verif\n",
    "    l = len(pos1)\n",
    "    verif=[]\n",
    "\n",
    "    verif = pd.read_csv(\"genomes/positifs_divers-str.csv\", sep = \"\\t\",header=None)  \n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "            \n",
    "    pos2 = verif\n",
    "    l=l+len(pos2)\n",
    "    verif=[]\n",
    "\n",
    "    verif = pd.read_csv(\"genomes/positifs_mouse_divers-str.csv\", sep = \"\\t\",header=None)  \n",
    "    verif = np.array(verif)\n",
    "    print(len(verif))\n",
    "    for i in range(len(verif)):\n",
    "        for j in range(2):\n",
    "            if len(verif[i,j]) <= 15:\n",
    "                print(i,\"erreur\")\n",
    "            \n",
    "    pos3 = verif\n",
    "    l=l+len(pos3)\n",
    "    verif=[]\n",
    "\n",
    "    bdd = np.concatenate((pos1,pos2,pos3,neg1,neg2,neg3))\n",
    "\n",
    "    pos1 = []\n",
    "    neg1 = []\n",
    "    pos2 = []\n",
    "    neg2 = []\n",
    "\n",
    "    labels = np.zeros((len(bdd),1))\n",
    "\n",
    "    bdd = np.concatenate((bdd,labels),axis=1)\n",
    "    for i in range(l):\n",
    "        bdd[i,4]=1\n",
    "    labels=[]\n",
    "    \n",
    "    # shuffle total\n",
    "\n",
    "    indices = np.arange(len(bdd))\n",
    "    shuffle(indices)\n",
    "    bdd = bdd[indices]\n",
    "    indices=[]\n",
    "\n",
    "    # \n",
    "    l = len(bdd)\n",
    "    matrice = np.zeros((l,36,36,1)) #4\n",
    "    matrice1 = np.zeros((l,36,36,1))\n",
    "    matrice2 = np.zeros((l,36,4))\n",
    "    matrice3 = np.zeros((l,36,4))\n",
    "    matrice4 = np.zeros((l,36,4))\n",
    "    matrice5 = np.zeros((l,36,4))\n",
    "\n",
    "    for i in range(l):\n",
    "        seq1 = bdd[i,0]\n",
    "        seq2 = bdd[i,1]\n",
    "        prob1 = np.array(clean(bdd[i,2]))\n",
    "        prob2 = np.array(clean(bdd[i,3]))\n",
    "        for j in range(len(seq1)):\n",
    "            for k in range(len(seq2)):\n",
    "                if (seq1[j]=='a' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='a'):\n",
    "                    matrice[i,j,k,0] = 1\n",
    "                    #matrice[i,j,k,1] = prob1[j]+prob2[k]\n",
    "                elif (seq1[j]=='g' and seq2[k]=='c') or (seq1[j]=='c' and seq2[k]=='g'):\n",
    "                    matrice[i,j,k,0] = 1\n",
    "                    #matrice[i,j,k,1] = prob1[j]+prob2[k]\n",
    "                elif (seq1[j]=='g' and seq2[k]=='u') or (seq1[j]=='u' and seq2[k]=='g'):\n",
    "                    matrice[i,j,k,0] = 1\n",
    "                    #matrice[i,j,k,1] = prob1[j]+prob2[k]\n",
    "                matrice1[i,j,k,0] = prob1[j]+prob2[k]\n",
    "        for j in range(len(seq1)):\n",
    "            if seq1[j]=='a':\n",
    "                matrice2[i,j,0] = 1\n",
    "            elif seq1[j]=='u':\n",
    "                matrice2[i,j,1] = 1\n",
    "            elif seq1[j]=='g':\n",
    "                matrice2[i,j,2] = 1\n",
    "            elif seq1[j]=='c':\n",
    "                matrice2[i,j,3] = 1\n",
    "        for j in range(len(seq2)):\n",
    "            if seq2[j]=='a':\n",
    "                matrice3[i,j,0] = 1\n",
    "            elif seq2[j]=='u':\n",
    "                matrice3[i,j,1] = 1\n",
    "            elif seq2[j]=='g':\n",
    "                matrice3[i,j,2] = 1\n",
    "            elif seq2[j]=='c':\n",
    "                matrice3[i,j,3] = 1\n",
    "\n",
    "    for i in range(36):\n",
    "        matrice4[:,36-i-1,:] = matrice2[:,i,:]\n",
    "    for i in range(36):\n",
    "        matrice5[:,36-i-1,:] = matrice3[:,i,:]\n",
    "    \n",
    "    training = []\n",
    "    training.append(matrice[:nb_train])\n",
    "    training.append(matrice1[:nb_train])\n",
    "    training.append(matrice2[:nb_train])\n",
    "    training.append(matrice4[:nb_train])\n",
    "    training.append(matrice3[:nb_train])\n",
    "    training.append(matrice5[:nb_train])    \n",
    "    \n",
    "    validation = []\n",
    "    validation.append(matrice[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice1[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice2[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice4[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice3[nb_train:nb_train+nb_val])\n",
    "    validation.append(matrice5[nb_train:nb_train+nb_val])\n",
    "\n",
    "    testing = []\n",
    "    testing.append(matrice[-nb_test:])\n",
    "    testing.append(matrice1[-nb_test:])\n",
    "    testing.append(matrice2[-nb_test:])\n",
    "    testing.append(matrice4[-nb_test:])\n",
    "    testing.append(matrice3[-nb_test:])\n",
    "    testing.append(matrice5[-nb_test:])\n",
    "\n",
    "    labels = bdd[:,4]\n",
    "    bdd = []\n",
    "    y = labels[:nb_train]\n",
    "    y = keras.utils.np_utils.to_categorical(y,2)\n",
    "    val_y = labels[nb_train:nb_train+nb_val]\n",
    "    val_y = keras.utils.np_utils.to_categorical(val_y,2)\n",
    "    true_y = labels[-nb_test:]\n",
    "    argtest=[]\n",
    "    np.sum(y[:,1])\n",
    "    return training, y, validation, val_y, testing, true_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26017\n",
      "24222\n",
      "37991\n",
      "26023\n",
      "24229\n",
      "37993\n"
     ]
    }
   ],
   "source": [
    "Data = load_data(150000,5000,20000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récupération du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paramètres \n",
    "\n",
    "matrixsize11 = 6\n",
    "nbfilter11 = 24\n",
    "matrixsize12 = 7\n",
    "nbfilter12 = 4\n",
    "matrixsize21 = 6\n",
    "nbfilter21 = 24\n",
    "matrixsize22 = 7\n",
    "nbfilter22 = 4\n",
    "nbfilter1 = 64\n",
    "kernelsize = 7\n",
    "nbfilters2 = 64\n",
    "kernel_size2 = 7\n",
    "Dense1 = 128\n",
    "Dense2 = 512\n",
    "Dense3 = 512\n",
    "Dense4 = 128\n",
    "Dense5 = 0\n",
    "\n",
    "from keras.layers import merge\n",
    "from keras import Model\n",
    "k = matrixsize11\n",
    "# init_weights\n",
    "I = np.eye(k)\n",
    "M = np.diag(np.ones(k-1),1) + np.diag(np.ones(k-1),-1) + np.eye(k)\n",
    "I2 = np.zeros((k,k))\n",
    "M2 = np.zeros((k,k))\n",
    "for j in range(k):\n",
    "    I2[:,j] = I[:,k-j-1]\n",
    "    M2[:,j] = M[:,k-j-1]        \n",
    "W = np.zeros((k,k,1,nbfilter11))\n",
    "W[:,:,0,0] = I\n",
    "W[:,:,0,1] = I2\n",
    "W[:,:,0,2] = M\n",
    "W[:,:,0,3] = M2\n",
    "for j in range(4,nbfilter11):\n",
    "    W[:,:,0,j] = np.random.randn(k,k)*0.2\n",
    "\n",
    "\n",
    "k2 = matrixsize12\n",
    "I = np.eye(k2)\n",
    "M = np.diag(np.ones(k2-1),1) + np.diag(np.ones(k2-1),-1) + np.eye(k2)\n",
    "I2=np.zeros((k2,k2))\n",
    "M2=np.zeros((k2,k2))\n",
    "for j in range(k2):\n",
    "    I2[:,j] = I[:,k2-j-1]\n",
    "    M2[:,j] = M[:,k2-j-1]   \n",
    "\n",
    "Z = np.zeros((k2,k2,nbfilter11,nbfilter12))\n",
    "\n",
    "for u in range(nbfilter12):\n",
    "    Z[:,:,u,0] = I\n",
    "    Z[:,:,u,1] = I2\n",
    "    Z[:,:,u,2] = M\n",
    "    Z[:,:,u,3] = M2\n",
    "    for p in range(4,nbfilter12):\n",
    "        Z[:,:,u,p]=np.random.randn(k2,k2)*0.3            \n",
    "\n",
    "c2d1_input = keras.Input(shape=(36,36,1))\n",
    "cnn2d1 = Conv2D(filters = nbfilter11, kernel_size=(k,k), padding='valid', input_shape=(36,36,1),strides=(1,1),weights=[W,np.zeros(nbfilter11)])(c2d1_input)\n",
    "cnn2d1 = AveragePooling2D(pool_size=(3,3))(cnn2d1)\n",
    "cnn2d1 = Conv2D(filters = nbfilter12, kernel_size = (k2, k2),strides=(1,1),padding='valid',weights=[Z,np.zeros(nbfilter12)])(cnn2d1)\n",
    "cnn2d1 = Dropout(0.2)(cnn2d1)\n",
    "cnn2d1 = Flatten()(cnn2d1)\n",
    "\n",
    "c2d2_input = keras.Input(shape=(36,36,1))\n",
    "cnn2d2 = Conv2D(filters = nbfilter11, kernel_size=(k,k), padding='valid', input_shape=(36,36,1),strides=(1,1),weights=[W,np.zeros(nbfilter11)])(c2d2_input)\n",
    "cnn2d2 = AveragePooling2D(pool_size=(3,3))(cnn2d2)\n",
    "cnn2d2 = Conv2D(filters = nbfilter12, kernel_size = (k2, k2),strides=(1,1),padding='valid',weights=[Z,np.zeros(nbfilter12)])(cnn2d2)\n",
    "cnn2d2 = Dropout(0.2)(cnn2d2)\n",
    "cnn2d2 = Flatten()(cnn2d2)\n",
    "\n",
    "c1d1_input = keras.Input(shape=(36,4))\n",
    "cnn1d1 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d1_input)\n",
    "cnn1d1 = MaxPooling1D(pool_size=8)(cnn1d1)\n",
    "cnn1d1 = Dropout(0.2)(cnn1d1)\n",
    "cnn1d1 = Flatten()(cnn1d1)\n",
    "#cnn1d1 = get_cnn_network_seq(nbfilter1,kernel_size1)(c1d1_input)\n",
    "c1d2_input = keras.Input(shape=(36,4))\n",
    "cnn1d2 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d2_input)\n",
    "cnn1d2 = MaxPooling1D(pool_size=8)(cnn1d2)\n",
    "cnn1d2 = Dropout(0.2)(cnn1d2)\n",
    "cnn1d2 = Flatten()(cnn1d2)\n",
    "#cnn1d2 = get_cnn_network_seq(nbfilter1,kernel_size1)(c1d2_input)\n",
    "c1d3_input = keras.Input(shape=(36,4))\n",
    "cnn1d3 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d3_input)\n",
    "cnn1d3 = MaxPooling1D(pool_size=8)(cnn1d3)\n",
    "cnn1d3 = Dropout(0.2)(cnn1d3)\n",
    "cnn1d3 = Flatten()(cnn1d3)\n",
    "\n",
    "c1d4_input = keras.Input(shape=(36,4))\n",
    "cnn1d4 = Conv1D(filters = nbfilter1, kernel_size = kernelsize, strides = 1, padding = 'valid', input_shape=(36,4), kernel_initializer = keras.initializers.lecun_uniform(seed=None))(c1d4_input)\n",
    "cnn1d4 = MaxPooling1D(pool_size=8)(cnn1d4)\n",
    "cnn1d4 = Dropout(0.2)(cnn1d4)\n",
    "cnn1d4 = Flatten()(cnn1d4)\n",
    "\n",
    "model21 = keras.layers.concatenate([cnn1d1,cnn1d2])\n",
    "model21 = Dense(int(Dense2/2),kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model21)\n",
    "model21 = BatchNormalization()(model21)\n",
    "model21 = Activation('relu')(model21)\n",
    "model21 = Dropout(0.3)(model21)\n",
    "\n",
    "model22 = keras.layers.concatenate([cnn1d3,cnn1d4])\n",
    "model22 = Dense(int(Dense2/2),kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model22)\n",
    "model22 = BatchNormalization()(model22)\n",
    "model22 = Activation('relu')(model22)\n",
    "model22 = Dropout(0.3)(model22)\n",
    "\n",
    "model2 = keras.layers.concatenate([model21,model22])\n",
    "model2 = Dense(Dense2,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model2)\n",
    "model2 = BatchNormalization()(model2)\n",
    "model2 = Activation('relu')(model2)\n",
    "model2 = Dropout(0.3)(model2)\n",
    "\n",
    "model1 = keras.layers.concatenate([cnn2d1,cnn2d2])\n",
    "model1 = Dense(Dense1,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model1)\n",
    "model1 = Dropout(0.1)(model1)\n",
    "model1 = BatchNormalization()(model1)\n",
    "model1 = Activation('relu')(model1)\n",
    "\n",
    "model = keras.layers.concatenate([model1,model2])\n",
    "model = Dense(Dense3,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Activation('relu')(model)\n",
    "model = Dropout(0.2)(model)\n",
    "model = Dense(Dense4,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "model = Activation('relu')(model)\n",
    "model = Dropout(0.2)(model)\n",
    "\n",
    "if Dense5>0:\n",
    "    model = Dense(Dense5,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "    model = BatchNormalization()(model)\n",
    "    model = Activation('relu')(model)\n",
    "    model = Dropout(0.2)(model)\n",
    "\n",
    "model = Dense(2,kernel_initializer=keras.initializers.lecun_uniform(seed=None))(model)\n",
    "model = BatchNormalization()(model)\n",
    "interaction_output = Activation('softmax')(model)\n",
    "interaction = Model(inputs=[c2d1_input,c2d2_input,c1d1_input,c1d2_input,c1d3_input,c1d4_input],outputs=[interaction_output])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explication d'interaction par des motifs de séquences d'ARN primaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def target_category_loss(x, category_index, nb_classes):\n",
    "    return tf.multiply(x, K.one_hot([category_index], nb_classes))\n",
    "\n",
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "\n",
    "def seq2augc(seq):\n",
    "    string = ''\n",
    "    for i in range(36):\n",
    "        if seq[i][0]==1:\n",
    "            string += 'a'\n",
    "        elif seq[i][1]==1:\n",
    "            string += 'u'\n",
    "        elif seq[i][2]==1:\n",
    "            string += 'g'\n",
    "        elif seq[i][3]==1:\n",
    "            string += 'c'\n",
    "        else:\n",
    "            a=0\n",
    "    return string\n",
    "\n",
    "def argumentsmax(argw):\n",
    "    l=[]\n",
    "    for r in argw:\n",
    "        l.append(r)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_classes = 2\n",
    "category_index = 1\n",
    "target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "interaction_output = Lambda(target_layer, output_shape = target_category_loss_output_shape)(interaction_output)\n",
    "interaction = Model(inputs=[c2d1_input,c2d2_input,c1d1_input,c1d2_input,c1d3_input,c1d4_input],outputs=[interaction_output])\n",
    "interaction.load_weights(\"model_finaldeep.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['conv1d_1', 'conv1d_2', 'conv1d_3', 'conv1d_4']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[l.name for l in interaction.layers[4:8]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des interactions véritables uniquement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "indices_positifs = np.argwhere(Data[1][:,1]==1)[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identification de motifs (très gourmand en temps de calcul, dû aux gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.4\n",
      "0.8\n",
      "1.2\n",
      "1.6\n",
      "2.0\n",
      "2.4\n",
      "2.8000000000000003\n",
      "3.2\n",
      "3.5999999999999996\n",
      "4.0\n",
      "4.3999999999999995\n",
      "4.8\n",
      "5.2\n",
      "5.6000000000000005\n",
      "6.0\n",
      "6.4\n",
      "6.800000000000001\n",
      "7.199999999999999\n",
      "7.6\n",
      "8.0\n",
      "8.4\n",
      "8.799999999999999\n",
      "9.2\n",
      "9.6\n",
      "10.0\n",
      "10.4\n",
      "10.8\n",
      "11.200000000000001\n",
      "11.600000000000001\n",
      "12.0\n",
      "12.4\n",
      "12.8\n",
      "13.200000000000001\n",
      "13.600000000000001\n",
      "14.000000000000002\n",
      "14.399999999999999\n",
      "14.799999999999999\n",
      "15.2\n",
      "15.6\n",
      "16.0\n",
      "16.400000000000002\n",
      "16.8\n",
      "17.2\n",
      "17.599999999999998\n",
      "18.0\n",
      "18.4\n",
      "18.8\n",
      "19.2\n",
      "19.6\n",
      "20.0\n",
      "20.4\n",
      "20.8\n",
      "21.2\n",
      "21.6\n",
      "22.0\n",
      "22.400000000000002\n",
      "22.8\n",
      "23.200000000000003\n",
      "rien\n",
      "23.599999999999998\n",
      "rien\n",
      "24.0\n",
      "24.4\n",
      "24.8\n",
      "25.2\n",
      "25.6\n",
      "26.0\n",
      "26.400000000000002\n",
      "26.8\n",
      "27.200000000000003\n",
      "27.6\n",
      "28.000000000000004\n",
      "28.4\n",
      "28.799999999999997\n",
      "29.2\n",
      "29.599999999999998\n",
      "30.0\n",
      "30.4\n",
      "30.8\n",
      "31.2\n",
      "31.6\n",
      "32.0\n",
      "32.4\n",
      "32.800000000000004\n",
      "33.2\n",
      "33.6\n",
      "34.0\n",
      "34.4\n",
      "34.8\n",
      "35.199999999999996\n",
      "35.6\n",
      "36.0\n",
      "36.4\n",
      "36.8\n",
      "37.2\n",
      "37.6\n",
      "38.0\n",
      "38.4\n",
      "38.800000000000004\n",
      "39.2\n",
      "39.6\n",
      "40.0\n",
      "40.400000000000006\n",
      "40.8\n",
      "41.199999999999996\n",
      "41.6\n",
      "42.0\n",
      "42.4\n",
      "42.8\n",
      "43.2\n",
      "rien\n",
      "43.6\n",
      "44.0\n",
      "44.4\n",
      "44.800000000000004\n",
      "45.2\n",
      "45.6\n",
      "46.0\n",
      "rien\n",
      "46.400000000000006\n",
      "46.800000000000004\n",
      "47.199999999999996\n",
      "47.599999999999994\n",
      "48.0\n",
      "48.4\n",
      "48.8\n",
      "49.2\n",
      "49.6\n",
      "50.0\n",
      "50.4\n",
      "50.8\n",
      "51.2\n",
      "51.6\n",
      "52.0\n",
      "52.400000000000006\n",
      "52.800000000000004\n",
      "53.2\n",
      "53.6\n",
      "54.0\n",
      "54.400000000000006\n",
      "54.800000000000004\n",
      "55.2\n",
      "55.60000000000001\n",
      "56.00000000000001\n",
      "56.39999999999999\n",
      "56.8\n",
      "57.199999999999996\n",
      "57.599999999999994\n",
      "rien\n",
      "57.99999999999999\n",
      "58.4\n",
      "58.8\n",
      "59.199999999999996\n",
      "59.599999999999994\n",
      "60.0\n",
      "60.4\n",
      "60.8\n",
      "61.199999999999996\n",
      "61.6\n",
      "62.0\n",
      "62.4\n",
      "62.8\n",
      "63.2\n",
      "63.6\n",
      "64.0\n",
      "64.4\n",
      "64.8\n",
      "65.2\n",
      "65.60000000000001\n",
      "66.0\n",
      "66.4\n",
      "rien\n",
      "66.8\n",
      "67.2\n",
      "67.60000000000001\n",
      "68.0\n",
      "68.4\n",
      "68.8\n",
      "69.19999999999999\n",
      "69.6\n",
      "70.0\n",
      "70.39999999999999\n",
      "70.8\n",
      "71.2\n",
      "71.6\n",
      "72.0\n",
      "72.39999999999999\n",
      "72.8\n",
      "73.2\n",
      "73.6\n",
      "74.0\n",
      "74.4\n",
      "74.8\n",
      "75.2\n",
      "75.6\n",
      "76.0\n",
      "76.4\n",
      "76.8\n",
      "77.2\n",
      "77.60000000000001\n",
      "78.0\n",
      "78.4\n",
      "78.8\n",
      "79.2\n",
      "79.60000000000001\n",
      "80.0\n",
      "80.4\n",
      "80.80000000000001\n",
      "81.2\n",
      "81.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method TF_Output.<lambda> of <tensorflow.python.pywrap_tensorflow_internal.TF_Output; proxy of <Swig Object of type 'TF_Output *' at 0x7f7dc7a6ef30> >>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/louis_jeay/downloads/3-5-2-test/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\", line 963, in <lambda>\n",
      "    __del__ = lambda self: None\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-a5f14ff79551>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mgradient_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minteraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmatrice_sequence0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatrice_sequence1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatrice_sequence\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatrice_sequence2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatrice_sequence3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmatrice_sequence4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_val\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/downloads/3-5-2-test/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/downloads/3-5-2-test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/downloads/3-5-2-test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/downloads/3-5-2-test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/downloads/3-5-2-test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/downloads/3-5-2-test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1305\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m   1307\u001b[0m           options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "\u001b[0;32m~/downloads/3-5-2-test/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1338\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1340\u001b[0;31m         \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1341\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "motifs = []\n",
    "for t in range(250):\n",
    "        \n",
    "    indice_1 = indices_positifs[t]\n",
    "    sequence = Data[0][0][indice_1]\n",
    "    matrice_sequence0 = np.zeros((1,36,36,1))\n",
    "    matrice_sequence0[0,:,:,:] = sequence\n",
    "    sequence = Data[0][1][indice_1]\n",
    "    matrice_sequence1 = np.zeros((1,36,36,1))\n",
    "    matrice_sequence1[0,:,:,:] = sequence\n",
    "    sequence = Data[0][2][indice_1]\n",
    "    matrice_sequence = np.zeros((1,36,4))\n",
    "    matrice_sequence[0,:,:] = sequence\n",
    "    sequence = Data[0][3][indice_1]\n",
    "    matrice_sequence2 = np.zeros((1,36,4))\n",
    "    matrice_sequence2[0,:,:] = sequence\n",
    "    sequence = Data[0][4][indice_1]\n",
    "    matrice_sequence3 = np.zeros((1,36,4))\n",
    "    matrice_sequence3[0,:,:] = sequence\n",
    "    sequence = Data[0][5][indice_1]\n",
    "    matrice_sequence4 = np.zeros((1,36,4))\n",
    "    matrice_sequence4[0,:,:] = sequence\n",
    "    \n",
    "    motif1 = []\n",
    "    \n",
    "    z1=0\n",
    "    layer_name = 'conv1d_1'\n",
    "    loss = K.sum(interaction.layers[-1].output)\n",
    "    conv_output = [l for l in interaction.layers if l.name == layer_name][0].output\n",
    "    grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "    gradient_function = K.function(interaction.input, [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([matrice_sequence0,matrice_sequence1,matrice_sequence,matrice_sequence2,matrice_sequence3,matrice_sequence4])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis = 0)\n",
    "    cam = np.ones(output.shape[0 : 1], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w*output[:, i]\n",
    "\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "    args = argumentsmax(np.argwhere(heatmap==1)[:,0])\n",
    "    if (len(args)==0):\n",
    "        z1+=1\n",
    "    else:    \n",
    "        seq = seq2augc(matrice_sequence[0])\n",
    "        args = (np.argwhere(heatmap>0.9)[:,0])\n",
    "        for pos in argumentsmax(args):\n",
    "            motif1.append(seq[pos:pos+7])\n",
    "    layer_name = 'conv1d_2'\n",
    "    loss = K.sum(interaction.layers[-1].output)\n",
    "    conv_output = [l for l in interaction.layers if l.name == layer_name][0].output\n",
    "    grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "    gradient_function = K.function(interaction.input, [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([matrice_sequence0,matrice_sequence1,matrice_sequence,matrice_sequence2,matrice_sequence3,matrice_sequence4])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis = 0)\n",
    "    cam = np.ones(output.shape[0 : 1], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, i]\n",
    "\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "    args = argumentsmax(np.argwhere(heatmap==1)[:,0])\n",
    "    if (len(args)==0):\n",
    "        z1+=1\n",
    "    else:    \n",
    "        seq = seq2augc(matrice_sequence2[0])\n",
    "        args = (np.argwhere(heatmap>0.9)[:,0])\n",
    "        for pos in argumentsmax(args):\n",
    "            motif1.append(seq[pos:pos+7])\n",
    "    \n",
    "    #\n",
    "    motif2 = []\n",
    "    \n",
    "    z2=0\n",
    "    layer_name = 'conv1d_3'\n",
    "    loss = K.sum(interaction.layers[-1].output)\n",
    "    conv_output = [l for l in interaction.layers if l.name == layer_name][0].output\n",
    "    grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "    gradient_function = K.function(interaction.input, [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([matrice_sequence0,matrice_sequence1,matrice_sequence,matrice_sequence2,matrice_sequence3,matrice_sequence4])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis = 0)\n",
    "    cam = np.ones(output.shape[0 : 1], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, i]\n",
    "\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "    \n",
    "    args = (np.argwhere(heatmap==1)[:,0])\n",
    "    if (len(args)==0):\n",
    "        z2+=1\n",
    "    else:    \n",
    "        seq = seq2augc(matrice_sequence3[0])\n",
    "        for pos in argumentsmax(args):\n",
    "            motif2.append(seq[pos:pos+7])\n",
    "    \n",
    "    layer_name = 'conv1d_4'\n",
    "    loss = K.sum(interaction.layers[-1].output)\n",
    "    conv_output = [l for l in interaction.layers if l.name == layer_name][0].output\n",
    "    grads = normalize(K.gradients(loss, conv_output)[0])\n",
    "    gradient_function = K.function(interaction.input, [conv_output, grads])\n",
    "\n",
    "    output, grads_val = gradient_function([matrice_sequence0,matrice_sequence1,matrice_sequence,matrice_sequence2,matrice_sequence3,matrice_sequence4])\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :]\n",
    "\n",
    "    weights = np.mean(grads_val, axis = 0)\n",
    "    cam = np.ones(output.shape[0 : 1], dtype = np.float32)\n",
    "\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, i]\n",
    "\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "    \n",
    "    args = (np.argwhere(heatmap==1)[:,0])\n",
    "    if (len(args)==0):\n",
    "        z2+=1\n",
    "    else:    \n",
    "        seq = seq2augc(matrice_sequence4[0])\n",
    "        \n",
    "        for pos in argumentsmax(args):\n",
    "            motif2.append(seq[pos:pos+7])\n",
    "    #\n",
    "    if (z1>=2 or z2>=2):\n",
    "        print('rien')\n",
    "    else:\n",
    "        motifs.append([motif1,motif2])\n",
    "    #        \n",
    "    print(t/250*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['auugcgg', 'uugcgga'], ['cccccgc', 'g']],\n",
       " [['aacuaga', 'uagaagu', 'aaguuau', 'auguca', 'ug', ''], ['cuccaag', 'auc']],\n",
       " [['uuggucu', 'uuagucu', 'agucuuu'], ['agc', 'cgaacag']],\n",
       " [['uugagcu', 'ugagcug', ''], ['agcua', 'guccga']],\n",
       " [['guccugu'], ['gaacggg', '']],\n",
       " [['uggaucg', 'ucggcuc', 'a'], ['uuauagg', 'auu']],\n",
       " [['uugacuc'],\n",
       "  ['agaucgg',\n",
       "   'aacuauu',\n",
       "   'acuauuc',\n",
       "   'cuauucg',\n",
       "   'uauucga',\n",
       "   'auucgag',\n",
       "   'uucgaga',\n",
       "   'ucgagaa',\n",
       "   'cgagaag',\n",
       "   'gagaagg']],\n",
       " [['uccacua', '', ''], ['a']],\n",
       " [['ucgcggg', 'ccgccgg', ''], ['agguccg', 'aggu']],\n",
       " [['auuucag', 'gacuccc', '', ''], ['guuguaa', '']],\n",
       " [['ucgccua'], ['gugcagu', '']],\n",
       " [['uaaagga'], ['ugcau', '']],\n",
       " [['ccgcccg', 'agguuag', 'gguuagc', 'guuagcc'], ['ggcucgg', 'cucggcu']],\n",
       " [['ugg',\n",
       "   'gguguac',\n",
       "   'guguacu',\n",
       "   'uguacuu',\n",
       "   'guacuuu',\n",
       "   'uacuuug',\n",
       "   'acuuugg',\n",
       "   'cuuuggg',\n",
       "   'uuuggga',\n",
       "   'uugggac'],\n",
       "  ['acuaguu']],\n",
       " [['ucggcgc'], ['ggguugu', '']],\n",
       " [['uucauca', 'uucauac', 'uaca', 'gacuacu'], ['aauccuu', 'guguaag']],\n",
       " [['aaggcgc', 'cgcgcgc', 'cgcggaa'], ['gcgccgc', 'ggaggag']],\n",
       " [['ugggauu', 'aacuggg', 'acugggu', 'cuggguc', 'ugggucg', 'gggucgu'],\n",
       "  ['ugcacgg', 'cggcacg']],\n",
       " [['uucccuu', 'ccggcug', 'ucccgug'], ['ggccca', 'gaacg']],\n",
       " [['uucuagg', 'uaggguu', 'uucaacc', 'ucaacca', 'accaacu', 'uucc'],\n",
       "  ['aga', 'uuccuca']],\n",
       " [['uggggaa', ''], ['gcucagu', 'gagguca']],\n",
       " [['uggggug', 'gugggcc', 'gggu'], ['uggccag']],\n",
       " [['agagcca',\n",
       "   'cuuucac',\n",
       "   'uuucacu',\n",
       "   'ucacuua',\n",
       "   'cacuuag',\n",
       "   'cuuagaa',\n",
       "   'uuagaa',\n",
       "   '',\n",
       "   ''],\n",
       "  ['ugauugg', '']],\n",
       " [['auuauuu', 'guuac', 'uac', 'cuuua', ''], ['gagauuu', 'gucc']],\n",
       " [['uacaguu', 'cauguga', ''], ['uuuaugu', '']],\n",
       " [['ac', '', '', '', '', '', '', '', '', '', '', ''], ['gauuauu', '']],\n",
       " [['uacaggg',\n",
       "   'uuaguaa',\n",
       "   'uaguaac',\n",
       "   'aguaaca',\n",
       "   'guaacaa',\n",
       "   'uaacaaa',\n",
       "   'aacaaau',\n",
       "   'acaaaua'],\n",
       "  ['ugccc', '']],\n",
       " [['agaguca', 'uguguu', ''], ['cucaugu', 'cga']],\n",
       " [['uacaagu', 'aug', 'g'], ['auccacg', '']],\n",
       " [['augagga'], ['cccaguc', '']],\n",
       " [['ucccaug', 'cccuuau'], ['gcccag', 'uga']],\n",
       " [['aaucug', 'ug', 'g', '', '', '', '', '', ''], ['aucuagu', '']],\n",
       " [['uugagau',\n",
       "   'ugagauu',\n",
       "   'gagauuu',\n",
       "   'uuucuuu',\n",
       "   'uuuucua',\n",
       "   'uucuaug',\n",
       "   'cuaugca',\n",
       "   'uaugca',\n",
       "   'augca',\n",
       "   ''],\n",
       "  ['uugcagg', 'aau']],\n",
       " [['ugcucug', 'ucugucu', 'cugucuc'], ['ugcagcc', 'cacuc']],\n",
       " [['uccugug',\n",
       "   'uggccgu',\n",
       "   'guguacg',\n",
       "   'uguacgu',\n",
       "   'guacgug',\n",
       "   'uacgugc',\n",
       "   'acgugcc',\n",
       "   'cgugccg',\n",
       "   'gugccgg',\n",
       "   'ugccggu',\n",
       "   'gccggug',\n",
       "   'ccggugu',\n",
       "   'cgguguc',\n",
       "   ''],\n",
       "  ['gggcggu', 'cuggggc']],\n",
       " [[''], ['ggggcug']],\n",
       " [['ucgaacg',\n",
       "   'gauggag',\n",
       "   'auggagg',\n",
       "   'uggagga',\n",
       "   'ggaggag',\n",
       "   'gaggaga',\n",
       "   'aggagaa',\n",
       "   'ggagaaa'],\n",
       "  ['cggccgc', 'cgccggc']],\n",
       " [['ucacggg'], ['aagcaga', 'aaguguu']],\n",
       " [['ucccugg', 'auggucc', 'ugguccc', 'ggucccu', 'gucccug'],\n",
       "  ['cagaggc', 'acggaga']],\n",
       " [['uuccaca', 'uuucaua', 'uagaccu', '', ''], ['uucagau', 'gacuuau']],\n",
       " [['uggaaug',\n",
       "   'ccuugac',\n",
       "   'cuugacg',\n",
       "   'uugacgu',\n",
       "   'ugacgua',\n",
       "   'gacguaa',\n",
       "   'acguaag',\n",
       "   'cguaagg',\n",
       "   'guaaggu',\n",
       "   'uaaggua',\n",
       "   'aagguac'],\n",
       "  ['cugccau', '']],\n",
       " [['uccauug', 'accucau', 'uccuacu'], ['gagugga', '']],\n",
       " [['ugggcgg'], ['aggacuu', 'gaa']],\n",
       " [['accgcgg', 'cggcgcc'], ['ucggcgg', 'cc']],\n",
       " [['ucggcgg', 'cgggugg', 'ggguggc'],\n",
       "  ['cguccgu', 'cguccgu', 'cguccgu', 'cguccgu', 'ccugccu']],\n",
       " [['uucacug', 'uua', 'ua', 'a', ''], ['gauaaga', 'aggaaag']],\n",
       " [['uaagaua', 'uacacag', 'gaau', 'u'], ['agacuug', 'uucagag']],\n",
       " [['ugggccc', 'cggu', ''], ['aacucuc', 'cucagua']],\n",
       " [['uggagag', ''], ['guguacc', '']],\n",
       " [['ucccagc', 'gacccu', ''],\n",
       "  ['ggau',\n",
       "   'uaggguc',\n",
       "   'agggucg',\n",
       "   'gggucga',\n",
       "   'ggucgag',\n",
       "   'gucgagu',\n",
       "   'ucgagug',\n",
       "   'cgagugc']],\n",
       " [['uugcacg',\n",
       "   'ggaucau',\n",
       "   'gaucauc',\n",
       "   'aucaucg',\n",
       "   'ucaucgg',\n",
       "   'caucggg',\n",
       "   'aucgggc',\n",
       "   'ucgggca',\n",
       "   'cgggcac',\n",
       "   'gggcacg'],\n",
       "  ['uucugag', '']],\n",
       " [['uggcagg', 'auucaua'], ['gggc', 'aauga']],\n",
       " [['accacca',\n",
       "   'accacca',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   '',\n",
       "   'ac',\n",
       "   'c',\n",
       "   ''],\n",
       "  ['aucua', 'uguacgu']],\n",
       " [['ucgggac', 'uccggu'], ['gccccac', 'cuc']],\n",
       " [['uccg', 'gccuccu', 'ccuccug', 'cuccugg', 'uccuggu', 'ccugguc'],\n",
       "  ['ggaucgc', 'accggag']],\n",
       " [['agaugaa',\n",
       "   'gaugaac',\n",
       "   'augaacc',\n",
       "   'ugaaccu',\n",
       "   'gaaccuu',\n",
       "   'aaccuuc',\n",
       "   'accuuca',\n",
       "   'ccuucag',\n",
       "   'cuucagu'],\n",
       "  ['agggagc', 'cuacgag']],\n",
       " [['ugcaacu', 'ugccguc', 'g'], ['gu', '']],\n",
       " [['ucgg',\n",
       "   'ggcuccu',\n",
       "   'gcuccuc',\n",
       "   'cuccucg',\n",
       "   'uccucgg',\n",
       "   'ccucggc',\n",
       "   'cucggcc',\n",
       "   'ucggccc',\n",
       "   'cggcccg',\n",
       "   'ggcccgc'],\n",
       "  ['gcaugag']],\n",
       " [['uacaua', 'ga', ''], ['caccugu', 'cuauguu']],\n",
       " [['gacguuc',\n",
       "   'acguucg',\n",
       "   'cguucgu',\n",
       "   'guucguc',\n",
       "   'uucgucg',\n",
       "   'ucgucga',\n",
       "   'cgucgaa'],\n",
       "  ['ucgugug']],\n",
       " [['ugggggc', 'ugggcca', ''], ['caggggc', 'ggac']],\n",
       " [['guauuca', 'uauucac', 'auucacc', 'uucaccc'], ['ggcuaaa', '']],\n",
       " [['aagccuu', 'aagucug', '', '', '', '', '', ''], ['ggcca', 'guuuuag']],\n",
       " [['aauauuu', 'uaaa', 'aa', 'uuga', '', ''], ['aaauagu', '']],\n",
       " [['uugacca', 'ucgagcc'],\n",
       "  ['gguaauc',\n",
       "   'ccuaaug',\n",
       "   'cuaaugg',\n",
       "   'uaauggu',\n",
       "   'aauggua',\n",
       "   'augguac',\n",
       "   'ugguacc',\n",
       "   'gguaccg',\n",
       "   'guaccgu']],\n",
       " [['uuuaugc', 'ugcau', 'aauucaa', 'uucaauu', '', '', ''],\n",
       "  ['auggugc',\n",
       "   'agacgaa',\n",
       "   'gacgaag',\n",
       "   'acgaaga',\n",
       "   'cgaagac',\n",
       "   'gaagacg',\n",
       "   'aagacgu',\n",
       "   'agacgug',\n",
       "   'gacgugg']],\n",
       " [['uuucaug',\n",
       "   'augucca',\n",
       "   'guccagc',\n",
       "   'uaagc',\n",
       "   'aagc',\n",
       "   'accugua',\n",
       "   'uacuuua',\n",
       "   'cccgac'],\n",
       "  ['aagaaga', '']],\n",
       " [['aaaaccc', '', '', '', '', '', '', ''], ['uagaagu', 'uaugggu']],\n",
       " [['uacgugg', '', ''], ['aaacuga', '']],\n",
       " [['uuccaug'], ['ccacccu', 'cccgagc']],\n",
       " [['auggcua',\n",
       "   'aaucaau',\n",
       "   'aucaaug',\n",
       "   'ucaaugg',\n",
       "   'caauggu',\n",
       "   'aauggug',\n",
       "   'auggugu',\n",
       "   'uggugua',\n",
       "   'gguguau',\n",
       "   'guguauc',\n",
       "   'uguaucg',\n",
       "   'guaucgg'],\n",
       "  ['agac', 'gacaac']],\n",
       " [['ucggagg', 'cucuccu'], ['gggucgg', 'gcggg']],\n",
       " [['uccgcgg', 'cugccuu'], ['gacccg', 'ggcggcg']],\n",
       " [['agggagg', 'aca', 'ca', 'a', ''], ['cuccucc', '']],\n",
       " [['ucacccc', 'u', ''], ['ggcgagu', 'cc']],\n",
       " [['uccaggg', 'ccuagau'], ['cggugug', '']],\n",
       " [['ucggcgc', 'c', ''], ['cccaugc', 'caaaccu']],\n",
       " [['ucggcgg', 'ucggcgg', 'cggcugg'], ['cgguugc', 'cguuggc']],\n",
       " [['cggggcg', 'ccgggcc', 'cgggccg', ''], ['ggguccc', 'ggggcgg']],\n",
       " [['auggcga', 'aauucuu', ''], ['guacaac']],\n",
       " [['u', 'uaucaua', 'cauaa'], ['agauugc', 'agguggg']],\n",
       " [['uaaaagg', 'ggcacag', 'aagggcg', 'ggacacg', 'aauucc'], ['uaauggc', '']],\n",
       " [['ugucggg', 'ucggggg', 'cgggggg', 'ugucu'], ['ugcgcgg', 'uug']],\n",
       " [['ucccgag', 'cccgagg', 'ccgaggu', ''], ['ggcgggc', 'gugca']],\n",
       " [['aggaaca', 'ggaacau', '', ''], ['uagacac', 'aug']],\n",
       " [['uucgaug', ''], ['guacg']],\n",
       " [['uccaccg'], ['gacugug', '']],\n",
       " [['accgcac',\n",
       "   'cugcacg',\n",
       "   'ugcacgc',\n",
       "   'gcacgcc',\n",
       "   'cacgcca',\n",
       "   'acgccac',\n",
       "   'cgccacg',\n",
       "   'gccacgc',\n",
       "   'ccacgcc',\n",
       "   'cacgccg',\n",
       "   'acgccga'],\n",
       "  ['cgcuac', 'uaagugu']],\n",
       " [['uuugggc', 'uugggca', 'ugggcau', ''], ['uuuuuu', 'ucagu']],\n",
       " [['uggccua'], ['aaacccu', 'gucccaa']],\n",
       " [['aaggcua'], ['ugaccag']],\n",
       " [['ucgccuc', 'gcuacac'], ['gcguggg', 'uggagg']],\n",
       " [['ucggcuc'], ['agccgag', 'agucgu']],\n",
       " [['ucgcucg', 'ca', ''], ['gggc', 'gggugcu']],\n",
       " [['ugaacug', ''], ['guguccc', 'cugugca']],\n",
       " [['aagagga', 'aggagga', 'gu'], ['guagaag', 'uga']],\n",
       " [['cuggcug',\n",
       "   'ccaccgc',\n",
       "   'caccgcu',\n",
       "   'accgcuc',\n",
       "   'ccgcucg',\n",
       "   'cgcucgg',\n",
       "   'gcucggu',\n",
       "   'cucgguc',\n",
       "   'ucggucg',\n",
       "   'cggucgg',\n",
       "   'ggucggu'],\n",
       "  ['aggccac', 'accggag']],\n",
       " [['uaggcgu', 'aggggac'], ['ggcccga', 'uccgccg']],\n",
       " [['gucccug', 'uuggucc', 'ugguccc', 'gcgacgu', ''], ['ggccugg', '']],\n",
       " [['gagccgg', 'ucagcuc', '', '', ''], ['cuggcuc', '']],\n",
       " [['agucgau',\n",
       "   'gucgaua',\n",
       "   'ucgauag',\n",
       "   'cgauaga',\n",
       "   'gauagac',\n",
       "   'auagacc',\n",
       "   'uagaccu',\n",
       "   'agaccuu',\n",
       "   'gaccuuc'],\n",
       "  ['auggccc']],\n",
       " [['uggcagg', 'uaccaug'], ['aacucga', 'gcucaaa']],\n",
       " [['ucaacca', 'ua', '', ''], ['agacaaa', 'ucgguua']],\n",
       " [['uucaugu', 'uugaag', '', ''], ['gauuagu', '']],\n",
       " [['cucaac', 'caacuca', 'aacucag'], ['acaaagu', 'cgaauga']],\n",
       " [['uuccauu', '', ''], ['agau', '']],\n",
       " [['ugggggu', 'ugggggu', 'uggggcu', 'cccgucg'], ['gggccga', '']],\n",
       " [['uccggcc', 'uggggcg', ''], ['ggcgcgc', 'cggcgga']],\n",
       " [['ugacccg', '', ''], ['ggaacgu', '']],\n",
       " [['uu', 'guca'], ['acuucau', 'a']],\n",
       " [['acgagua',\n",
       "   'cccccuu',\n",
       "   'ccccuug',\n",
       "   'cccuugc',\n",
       "   'ccuugcg',\n",
       "   'cuugcgu',\n",
       "   'uugcguc',\n",
       "   'ugcgucg',\n",
       "   'gcgucga',\n",
       "   'cgucgau',\n",
       "   'gucgaug'],\n",
       "  ['ggccccg', 'cgcaagc']],\n",
       " [['uccgcgg', 'ucgcccg'], ['ccacauc', '']],\n",
       " [['uuugaag', 'uugaagu', 'ugaagug', 'aagugca', 'uac', 'ucu', '', ''],\n",
       "  ['gggaagg', 'gagggga']],\n",
       " [['uugccaa', 'acgau'], ['auucccc', '']],\n",
       " [['ugcgug', 'gggcgac', ''], ['ggccccu', 'cacagua']],\n",
       " [['accgcgg', 'cggcgcc'], ['ucggcgc', '']],\n",
       " [['aucgcgc'], ['cgcccuc', 'ucccgcu']],\n",
       " [['uggcagg'], ['gggcaa', 'uggugga']],\n",
       " [['uucccgc', 'gag'], ['aggcag', 'gggucca']],\n",
       " [['acgcagg', 'u', ''], ['agccggg']],\n",
       " [['uggcaug', 'uuguacg', 'uguacgg', 'guacggu', 'uacgguc', 'acggucu'],\n",
       "  ['gaggagc', 'uccgagg']],\n",
       " [['uucccag', 'uacc', 'acc'], ['ggcuccu', '']],\n",
       " [['uuggaug'], ['uac']],\n",
       " [['cacuguc',\n",
       "   'acugucc',\n",
       "   'cugucca',\n",
       "   'uguccac',\n",
       "   'guccaca',\n",
       "   'uccacau',\n",
       "   'ccacaug',\n",
       "   'cacauga',\n",
       "   'acaugac',\n",
       "   'caugacc',\n",
       "   'augaccg'],\n",
       "  ['ggaugug', 'ccuuuag']],\n",
       " [['ccccggg', 'ucccggg', 'cccgggg', 'gggcccc'], ['uccugag', 'cccuag']],\n",
       " [['uugcugg', 'auuuacg', 'gaucu', 'cu', '', '', '', ''],\n",
       "  ['auua',\n",
       "   'auuaauu',\n",
       "   'uuaauua',\n",
       "   'uaauuag',\n",
       "   'aauuaga',\n",
       "   'auuagac',\n",
       "   'uuagacg',\n",
       "   'uagacgg',\n",
       "   'agacggu',\n",
       "   'gacggug',\n",
       "   'acggugu',\n",
       "   'cgguguc']],\n",
       " [['aacaagg', 'a', ''], ['aaaaaga', 'aaaaaaa']],\n",
       " [['a', 'ucgu'], ['guucccc', 'uccg']],\n",
       " [['ugcgccg'], ['ggacggc', '']],\n",
       " [['uccccgu',\n",
       "   'cugccug',\n",
       "   'ugccugc',\n",
       "   'gccugcc',\n",
       "   'ccugccu',\n",
       "   'cugccug',\n",
       "   'ugccugc'],\n",
       "  ['gcggcg', 'ggcggcg']],\n",
       " [['agcgacg', 'acuugcg', 'cuugcga', 'gcgaacc', ''], ['ggcuugg', '']],\n",
       " [['uccgggg',\n",
       "   'cggggcg',\n",
       "   'ggggcgg',\n",
       "   'gggcggc',\n",
       "   'ggcggcg',\n",
       "   'gcggcgc',\n",
       "   'cggcgcg'],\n",
       "  ['ggcgcgc', '', '']],\n",
       " [['ccccgug',\n",
       "   'ccgugg',\n",
       "   'ugg',\n",
       "   'ggugccc',\n",
       "   'gugcccc',\n",
       "   'ugccccc',\n",
       "   'gcccccc',\n",
       "   'ccccccg',\n",
       "   'cccccgg',\n",
       "   'ccccgga',\n",
       "   'cccggaa',\n",
       "   'ccggaaa'],\n",
       "  ['ccgc', 'ucucucu']],\n",
       " [['uagggau'], ['agacccu', 'uauccca']],\n",
       " [[''], ['ggucagg', 'ccagauc']],\n",
       " [['acggcug', 'ucaggga'], ['ggcagac', 'acac']],\n",
       " [['ugcaggc', 'uac'], ['uacaauu', 'acga']],\n",
       " [['uuugugg', 'ugguuug', 'uugacac', 'uuguuu', 'uu'],\n",
       "  ['', '', '', '', '', '', '', '', '', '']],\n",
       " [['acccgug',\n",
       "   'agaaguu',\n",
       "   'gaaguuu',\n",
       "   'aaguuua',\n",
       "   'aguuuag',\n",
       "   'guuuagc',\n",
       "   'uuuagcc',\n",
       "   'uuagccc'],\n",
       "  ['agcca', 'aag']],\n",
       " [['ucggccg', 'ccggcgc', 'gcuccgc', 'uccgcga', 'gcgaccc', ''],\n",
       "  ['agcccag', '']],\n",
       " [['uaggcag'], ['gcccuga', '']],\n",
       " [['gacccug', 'gucccag', 'gaau'], ['ggauaac']],\n",
       " [['uccccga'], ['uggccgc', 'cgccggu']],\n",
       " [['ccugggg', 'uggggca', 'uggggag', 'ggguccc', 'guccccc'],\n",
       "  ['ggau', 'gcgaggg']],\n",
       " [['ucaguac', 'a', '', '', '', '', '', '', 'agcauga'], ['aaaagag', '']],\n",
       " [['uggguuc',\n",
       "   'uccucuu',\n",
       "   'ccucuua',\n",
       "   'cucuuag',\n",
       "   'ucuuagu',\n",
       "   'cuuagug',\n",
       "   'uuagugg'],\n",
       "  ['cgccc', '']],\n",
       " [['uucucca', '', '', '', ''],\n",
       "  ['auuua',\n",
       "   'auuuaua',\n",
       "   'uuuauaa',\n",
       "   'uuauaaa',\n",
       "   'uauaaac',\n",
       "   'auaaacc',\n",
       "   'uaaacca',\n",
       "   'aaaccac',\n",
       "   'aaccacg',\n",
       "   'accacga',\n",
       "   'ccacgag',\n",
       "   'cacgagu']],\n",
       " [['ucccaug', 'agu'], ['ggcgagu', 'cc']],\n",
       " [['uuccccg',\n",
       "   'uccccga',\n",
       "   'ucccgug',\n",
       "   'gugaagu',\n",
       "   'ugaagug',\n",
       "   'gaagugc',\n",
       "   'aagugcc',\n",
       "   'agugccc'],\n",
       "  ['gaagcgc', 'gucaguu']],\n",
       " [['uc',\n",
       "   'cuccgag',\n",
       "   'uccgaga',\n",
       "   'ccgagac',\n",
       "   'cgagacc',\n",
       "   'gagaccc',\n",
       "   'agaccca',\n",
       "   'gacccau',\n",
       "   'acccaug'],\n",
       "  ['ugacccc', 'cccaguc']],\n",
       " [['acggccg', 'ggugucc', 'guguccc', 'ugucccg'], ['agccacg', 'cgaaggg']],\n",
       " [['ugaggua', 'uucccac', 'ucccacc', 'uucccaa'],\n",
       "  ['ugucagg', 'ccuucca', 'cuuccau', 'uuccauu', 'uccauua', 'ccauuag']],\n",
       " [['uggagug', 'cgcguga', 'gcgugag', 'cgugagg', 'gugaggu'], ['gacacua']],\n",
       " [['agggccc', 'acucuac'], ['ugcucug', 'agugua']],\n",
       " [['ugcacug',\n",
       "   'uugucac',\n",
       "   'ugucacg',\n",
       "   'gucacgu',\n",
       "   'ucacguu',\n",
       "   'cacguuc',\n",
       "   'acguucu'],\n",
       "  ['', '', '', '', '', '', '', '', 'gguguu']],\n",
       " [['gagacuu', 'uaaguc', 'aaguc', 'g', ''], ['gggaaga', 'uuaugau']],\n",
       " [['auuacac', 'uuacacu', 'uacacuu', 'acacuuu', 'cacuuua'], ['aggcagg', 'u']],\n",
       " [['aggcagc',\n",
       "   'uccagg',\n",
       "   'ggaccuc',\n",
       "   'gaccucu',\n",
       "   'accucuc',\n",
       "   'ccucucu',\n",
       "   'cucucuc',\n",
       "   'ucucucg'],\n",
       "  ['aac', 'caagacc', 'aagacca', 'agaccac', 'gaccacu', 'accacuc']],\n",
       " [['cacguca',\n",
       "   'acgucac',\n",
       "   'cgucacc',\n",
       "   'gucaccg',\n",
       "   'ucaccga',\n",
       "   'caccgau',\n",
       "   'accgaua',\n",
       "   'ccgauaa',\n",
       "   'cgauaag',\n",
       "   'gauaagu',\n",
       "   'gacc'],\n",
       "  ['ggaucgc', 'ggugaug']],\n",
       " [['aaaauag', 'uagaaug', ''], ['agauugu', 'a']],\n",
       " [['uucuacc', '', '', '', ''], ['gau', '']],\n",
       " [['agcgcuu', 'cagucgu', 'agucguu', 'gucguuc', 'ucguucg'], ['ucucguc']],\n",
       " [['gggagaa', 'agaaugu', 'aauguga', 'u', '', '', ''], ['gugaaga', 'agug']],\n",
       " [['aaaaagu', 'aaauuag', ''], ['gccaaga', '']],\n",
       " [['ugcagug',\n",
       "   'agugacg',\n",
       "   'gugacgu',\n",
       "   'ugacguu',\n",
       "   'gacguug',\n",
       "   'acguugg',\n",
       "   'cguugga',\n",
       "   'guuggag',\n",
       "   'uuggagg',\n",
       "   'uggaggc',\n",
       "   'ggaggca'],\n",
       "  ['agc', '']],\n",
       " [['uggaacc'], ['cccccgc', '']],\n",
       " [['aucuauu', 'uugguca', 'uacuc', 'c', '', '', ''], ['accauuu', 'uuuuuua']],\n",
       " [['gugacgg', 'ugacggg', 'gacgggu', 'acggguu'], ['a', 'caccugc']],\n",
       " [['ucuggug',\n",
       "   'uggugcg',\n",
       "   'cgaccag',\n",
       "   'gaccagg',\n",
       "   'accaggc',\n",
       "   'ccaggcg',\n",
       "   'caggcgu',\n",
       "   'aggcgug',\n",
       "   'ggcgugg',\n",
       "   'gcguggu',\n",
       "   'cgugguc',\n",
       "   'guggucu'],\n",
       "  ['ggcaauc', '']],\n",
       " [['uugaggg'], ['ggca', 'cccua']],\n",
       " [['ccggcgg',\n",
       "   'ccaggcg',\n",
       "   'caggcgg',\n",
       "   'aggcggc',\n",
       "   'ggcggcc',\n",
       "   'gcggccc',\n",
       "   'cggcccg',\n",
       "   'ggcccgc',\n",
       "   'gcccgcu',\n",
       "   'cccgcua',\n",
       "   'ccgcuag'],\n",
       "  ['ugccccc', '']],\n",
       " [['ucggcuc'], ['gag', 'g']],\n",
       " [['ugggauu',\n",
       "   'guggugg',\n",
       "   'ugguggu',\n",
       "   'ggugguu',\n",
       "   'gugguua',\n",
       "   'ugguuag',\n",
       "   'gguuagg',\n",
       "   'guuaggg',\n",
       "   'uuagggu',\n",
       "   'uagggug',\n",
       "   'agggugu'],\n",
       "  ['ccacccc', '']],\n",
       " [['ccggcgg'], ['aggcaag', 'ggacgug']],\n",
       " [['ucggcuu'], ['ggauguc', 'ccagccg']],\n",
       " [['uggacgg'], ['ugacguc', 'ggag']],\n",
       " [['ugaaguu', 'uuaaacc', 'uaaaccc', 'gu', 'u', '', '', '', ''],\n",
       "  ['augggg', '']],\n",
       " [['cccgcuc',\n",
       "   'ucgccu',\n",
       "   'uccgcuc',\n",
       "   'ccgcucc',\n",
       "   'cgcuccu',\n",
       "   'gcuccuc',\n",
       "   'cuccucg',\n",
       "   'uccucgc',\n",
       "   'ccucgcc',\n",
       "   'cucgccc',\n",
       "   'ucgcccc',\n",
       "   'cgccccg'],\n",
       "  ['ggguugg', 'cagag']],\n",
       " [['accacga'], ['ggccgc', 'ccuu']],\n",
       " [['aagauuc', 'cag', ''], ['agaucac', 'acuaga']],\n",
       " [['uggaaua', 'uugugu'], ['gugcagc', 'gag']],\n",
       " [['uugccga'], ['ggcucuu', '']],\n",
       " [['ugcccac'], ['ggcgugu', '']],\n",
       " [['aucaguu', 'gaggauc'], ['aaucuug', '']],\n",
       " [['uggggcg', 'ucgagga'], ['cugcagu', 'gaa']],\n",
       " [['ucggggg',\n",
       "   'cgaagua',\n",
       "   'gaaguag',\n",
       "   'aaguagg',\n",
       "   'aguaggg',\n",
       "   'guagggg',\n",
       "   'uaggggg'],\n",
       "  ['cgaacgc', 'gcc']],\n",
       " [['uccccgc',\n",
       "   'cugcugc',\n",
       "   'ugcugcg',\n",
       "   'gcugcgc',\n",
       "   'cugcgcc',\n",
       "   'ugcgccc',\n",
       "   'gcgcccc',\n",
       "   'cgccccu',\n",
       "   'gccccuc',\n",
       "   'ccccucc',\n",
       "   'cccuccg'],\n",
       "  ['cgccacc', '']],\n",
       " [['auggccc', 'acgcccg', 'gcccgca', 'cccgcaa'], ['gugc', '']],\n",
       " [['ucgcgug', 'ucgccc'], ['ggcgggc', 'ucgac']],\n",
       " [['uggcagg', 'uaccaug'], ['gca', '']],\n",
       " [['uu',\n",
       "   'uuccucc',\n",
       "   'uccuccc',\n",
       "   'ccuccca',\n",
       "   'cucccau',\n",
       "   'ucccauc',\n",
       "   'cccaucc',\n",
       "   'ccauccu',\n",
       "   'cauccuc',\n",
       "   'auccuca',\n",
       "   'uccucac',\n",
       "   'ccucacc'],\n",
       "  ['agccag', '']],\n",
       " [['ugcccag'], ['gggucag']],\n",
       " [['au', '', ''], ['aucauug', '']],\n",
       " [['aagaaug', ''], ['gcaaagg', '']],\n",
       " [['uccacua', ''], ['gccuggc', 'aucag']],\n",
       " [['ucagcgg'], ['ugcuc', 'uguug']],\n",
       " [['uggaggc'], ['ugcaugg', '']],\n",
       " [['aaccccg'], ['cugcag', '']],\n",
       " [['uggggcg', ''], ['gggugac', 'gacagug']]]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "motifs_save = np.array(motifs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('motifs.npy',motifs_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Récupération des motifs extraits pour 250 interactions*\n",
    "*sur plus de 100 000 possibles (mais temps de calcul trop long pour faire les 100 000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "motifs = np.load('motifs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[list(['auugcgg', 'uugcgga']) list(['cccccgc', 'g'])]\n",
      " [list(['aacuaga', 'uagaagu', 'aaguuau', 'auguca', 'ug', ''])\n",
      "  list(['cuccaag', 'auc'])]\n",
      " [list(['uuggucu', 'uuagucu', 'agucuuu']) list(['agc', 'cgaacag'])]\n",
      " [list(['uugagcu', 'ugagcug', '']) list(['agcua', 'guccga'])]\n",
      " [list(['guccugu']) list(['gaacggg', ''])]\n",
      " [list(['uggaucg', 'ucggcuc', 'a']) list(['uuauagg', 'auu'])]\n",
      " [list(['uugacuc'])\n",
      "  list(['agaucgg', 'aacuauu', 'acuauuc', 'cuauucg', 'uauucga', 'auucgag', 'uucgaga', 'ucgagaa', 'cgagaag', 'gagaagg'])]\n",
      " [list(['uccacua', '', '']) list(['a'])]\n",
      " [list(['ucgcggg', 'ccgccgg', '']) list(['agguccg', 'aggu'])]\n",
      " [list(['auuucag', 'gacuccc', '', '']) list(['guuguaa', ''])]\n",
      " [list(['ucgccua']) list(['gugcagu', ''])]\n",
      " [list(['uaaagga']) list(['ugcau', ''])]\n",
      " [list(['ccgcccg', 'agguuag', 'gguuagc', 'guuagcc'])\n",
      "  list(['ggcucgg', 'cucggcu'])]\n",
      " [list(['ugg', 'gguguac', 'guguacu', 'uguacuu', 'guacuuu', 'uacuuug', 'acuuugg', 'cuuuggg', 'uuuggga', 'uugggac'])\n",
      "  list(['acuaguu'])]\n",
      " [list(['ucggcgc']) list(['ggguugu', ''])]\n",
      " [list(['uucauca', 'uucauac', 'uaca', 'gacuacu'])\n",
      "  list(['aauccuu', 'guguaag'])]\n",
      " [list(['aaggcgc', 'cgcgcgc', 'cgcggaa']) list(['gcgccgc', 'ggaggag'])]\n",
      " [list(['ugggauu', 'aacuggg', 'acugggu', 'cuggguc', 'ugggucg', 'gggucgu'])\n",
      "  list(['ugcacgg', 'cggcacg'])]\n",
      " [list(['uucccuu', 'ccggcug', 'ucccgug']) list(['ggccca', 'gaacg'])]\n",
      " [list(['uucuagg', 'uaggguu', 'uucaacc', 'ucaacca', 'accaacu', 'uucc'])\n",
      "  list(['aga', 'uuccuca'])]\n",
      " [list(['uggggaa', '']) list(['gcucagu', 'gagguca'])]\n",
      " [list(['uggggug', 'gugggcc', 'gggu']) list(['uggccag'])]\n",
      " [list(['agagcca', 'cuuucac', 'uuucacu', 'ucacuua', 'cacuuag', 'cuuagaa', 'uuagaa', '', ''])\n",
      "  list(['ugauugg', ''])]\n",
      " [list(['auuauuu', 'guuac', 'uac', 'cuuua', ''])\n",
      "  list(['gagauuu', 'gucc'])]\n",
      " [list(['uacaguu', 'cauguga', '']) list(['uuuaugu', ''])]\n",
      " [list(['ac', '', '', '', '', '', '', '', '', '', '', ''])\n",
      "  list(['gauuauu', ''])]\n",
      " [list(['uacaggg', 'uuaguaa', 'uaguaac', 'aguaaca', 'guaacaa', 'uaacaaa', 'aacaaau', 'acaaaua'])\n",
      "  list(['ugccc', ''])]\n",
      " [list(['agaguca', 'uguguu', '']) list(['cucaugu', 'cga'])]\n",
      " [list(['uacaagu', 'aug', 'g']) list(['auccacg', ''])]\n",
      " [list(['augagga']) list(['cccaguc', ''])]\n",
      " [list(['ucccaug', 'cccuuau']) list(['gcccag', 'uga'])]\n",
      " [list(['aaucug', 'ug', 'g', '', '', '', '', '', ''])\n",
      "  list(['aucuagu', ''])]\n",
      " [list(['uugagau', 'ugagauu', 'gagauuu', 'uuucuuu', 'uuuucua', 'uucuaug', 'cuaugca', 'uaugca', 'augca', ''])\n",
      "  list(['uugcagg', 'aau'])]\n",
      " [list(['ugcucug', 'ucugucu', 'cugucuc']) list(['ugcagcc', 'cacuc'])]\n",
      " [list(['uccugug', 'uggccgu', 'guguacg', 'uguacgu', 'guacgug', 'uacgugc', 'acgugcc', 'cgugccg', 'gugccgg', 'ugccggu', 'gccggug', 'ccggugu', 'cgguguc', ''])\n",
      "  list(['gggcggu', 'cuggggc'])]\n",
      " [list(['']) list(['ggggcug'])]\n",
      " [list(['ucgaacg', 'gauggag', 'auggagg', 'uggagga', 'ggaggag', 'gaggaga', 'aggagaa', 'ggagaaa'])\n",
      "  list(['cggccgc', 'cgccggc'])]\n",
      " [list(['ucacggg']) list(['aagcaga', 'aaguguu'])]\n",
      " [list(['ucccugg', 'auggucc', 'ugguccc', 'ggucccu', 'gucccug'])\n",
      "  list(['cagaggc', 'acggaga'])]\n",
      " [list(['uuccaca', 'uuucaua', 'uagaccu', '', ''])\n",
      "  list(['uucagau', 'gacuuau'])]\n",
      " [list(['uggaaug', 'ccuugac', 'cuugacg', 'uugacgu', 'ugacgua', 'gacguaa', 'acguaag', 'cguaagg', 'guaaggu', 'uaaggua', 'aagguac'])\n",
      "  list(['cugccau', ''])]\n",
      " [list(['uccauug', 'accucau', 'uccuacu']) list(['gagugga', ''])]\n",
      " [list(['ugggcgg']) list(['aggacuu', 'gaa'])]\n",
      " [list(['accgcgg', 'cggcgcc']) list(['ucggcgg', 'cc'])]\n",
      " [list(['ucggcgg', 'cgggugg', 'ggguggc'])\n",
      "  list(['cguccgu', 'cguccgu', 'cguccgu', 'cguccgu', 'ccugccu'])]\n",
      " [list(['uucacug', 'uua', 'ua', 'a', '']) list(['gauaaga', 'aggaaag'])]\n",
      " [list(['uaagaua', 'uacacag', 'gaau', 'u']) list(['agacuug', 'uucagag'])]\n",
      " [list(['ugggccc', 'cggu', '']) list(['aacucuc', 'cucagua'])]\n",
      " [list(['uggagag', '']) list(['guguacc', ''])]\n",
      " [list(['ucccagc', 'gacccu', ''])\n",
      "  list(['ggau', 'uaggguc', 'agggucg', 'gggucga', 'ggucgag', 'gucgagu', 'ucgagug', 'cgagugc'])]\n",
      " [list(['uugcacg', 'ggaucau', 'gaucauc', 'aucaucg', 'ucaucgg', 'caucggg', 'aucgggc', 'ucgggca', 'cgggcac', 'gggcacg'])\n",
      "  list(['uucugag', ''])]\n",
      " [list(['uggcagg', 'auucaua']) list(['gggc', 'aauga'])]\n",
      " [list(['accacca', 'accacca', '', '', '', '', '', '', '', '', '', '', 'ac', 'c', ''])\n",
      "  list(['aucua', 'uguacgu'])]\n",
      " [list(['ucgggac', 'uccggu']) list(['gccccac', 'cuc'])]\n",
      " [list(['uccg', 'gccuccu', 'ccuccug', 'cuccugg', 'uccuggu', 'ccugguc'])\n",
      "  list(['ggaucgc', 'accggag'])]\n",
      " [list(['agaugaa', 'gaugaac', 'augaacc', 'ugaaccu', 'gaaccuu', 'aaccuuc', 'accuuca', 'ccuucag', 'cuucagu'])\n",
      "  list(['agggagc', 'cuacgag'])]\n",
      " [list(['ugcaacu', 'ugccguc', 'g']) list(['gu', ''])]\n",
      " [list(['ucgg', 'ggcuccu', 'gcuccuc', 'cuccucg', 'uccucgg', 'ccucggc', 'cucggcc', 'ucggccc', 'cggcccg', 'ggcccgc'])\n",
      "  list(['gcaugag'])]\n",
      " [list(['uacaua', 'ga', '']) list(['caccugu', 'cuauguu'])]\n",
      " [list(['gacguuc', 'acguucg', 'cguucgu', 'guucguc', 'uucgucg', 'ucgucga', 'cgucgaa'])\n",
      "  list(['ucgugug'])]\n",
      " [list(['ugggggc', 'ugggcca', '']) list(['caggggc', 'ggac'])]\n",
      " [list(['guauuca', 'uauucac', 'auucacc', 'uucaccc'])\n",
      "  list(['ggcuaaa', ''])]\n",
      " [list(['aagccuu', 'aagucug', '', '', '', '', '', ''])\n",
      "  list(['ggcca', 'guuuuag'])]\n",
      " [list(['aauauuu', 'uaaa', 'aa', 'uuga', '', '']) list(['aaauagu', ''])]\n",
      " [list(['uugacca', 'ucgagcc'])\n",
      "  list(['gguaauc', 'ccuaaug', 'cuaaugg', 'uaauggu', 'aauggua', 'augguac', 'ugguacc', 'gguaccg', 'guaccgu'])]\n",
      " [list(['uuuaugc', 'ugcau', 'aauucaa', 'uucaauu', '', '', ''])\n",
      "  list(['auggugc', 'agacgaa', 'gacgaag', 'acgaaga', 'cgaagac', 'gaagacg', 'aagacgu', 'agacgug', 'gacgugg'])]\n",
      " [list(['uuucaug', 'augucca', 'guccagc', 'uaagc', 'aagc', 'accugua', 'uacuuua', 'cccgac'])\n",
      "  list(['aagaaga', ''])]\n",
      " [list(['aaaaccc', '', '', '', '', '', '', ''])\n",
      "  list(['uagaagu', 'uaugggu'])]\n",
      " [list(['uacgugg', '', '']) list(['aaacuga', ''])]\n",
      " [list(['uuccaug']) list(['ccacccu', 'cccgagc'])]\n",
      " [list(['auggcua', 'aaucaau', 'aucaaug', 'ucaaugg', 'caauggu', 'aauggug', 'auggugu', 'uggugua', 'gguguau', 'guguauc', 'uguaucg', 'guaucgg'])\n",
      "  list(['agac', 'gacaac'])]\n",
      " [list(['ucggagg', 'cucuccu']) list(['gggucgg', 'gcggg'])]\n",
      " [list(['uccgcgg', 'cugccuu']) list(['gacccg', 'ggcggcg'])]\n",
      " [list(['agggagg', 'aca', 'ca', 'a', '']) list(['cuccucc', ''])]\n",
      " [list(['ucacccc', 'u', '']) list(['ggcgagu', 'cc'])]\n",
      " [list(['uccaggg', 'ccuagau']) list(['cggugug', ''])]\n",
      " [list(['ucggcgc', 'c', '']) list(['cccaugc', 'caaaccu'])]\n",
      " [list(['ucggcgg', 'ucggcgg', 'cggcugg']) list(['cgguugc', 'cguuggc'])]\n",
      " [list(['cggggcg', 'ccgggcc', 'cgggccg', ''])\n",
      "  list(['ggguccc', 'ggggcgg'])]\n",
      " [list(['auggcga', 'aauucuu', '']) list(['guacaac'])]\n",
      " [list(['u', 'uaucaua', 'cauaa']) list(['agauugc', 'agguggg'])]\n",
      " [list(['uaaaagg', 'ggcacag', 'aagggcg', 'ggacacg', 'aauucc'])\n",
      "  list(['uaauggc', ''])]\n",
      " [list(['ugucggg', 'ucggggg', 'cgggggg', 'ugucu'])\n",
      "  list(['ugcgcgg', 'uug'])]\n",
      " [list(['ucccgag', 'cccgagg', 'ccgaggu', '']) list(['ggcgggc', 'gugca'])]\n",
      " [list(['aggaaca', 'ggaacau', '', '']) list(['uagacac', 'aug'])]\n",
      " [list(['uucgaug', '']) list(['guacg'])]\n",
      " [list(['uccaccg']) list(['gacugug', ''])]\n",
      " [list(['accgcac', 'cugcacg', 'ugcacgc', 'gcacgcc', 'cacgcca', 'acgccac', 'cgccacg', 'gccacgc', 'ccacgcc', 'cacgccg', 'acgccga'])\n",
      "  list(['cgcuac', 'uaagugu'])]\n",
      " [list(['uuugggc', 'uugggca', 'ugggcau', '']) list(['uuuuuu', 'ucagu'])]\n",
      " [list(['uggccua']) list(['aaacccu', 'gucccaa'])]\n",
      " [list(['aaggcua']) list(['ugaccag'])]\n",
      " [list(['ucgccuc', 'gcuacac']) list(['gcguggg', 'uggagg'])]\n",
      " [list(['ucggcuc']) list(['agccgag', 'agucgu'])]\n",
      " [list(['ucgcucg', 'ca', '']) list(['gggc', 'gggugcu'])]\n",
      " [list(['ugaacug', '']) list(['guguccc', 'cugugca'])]\n",
      " [list(['aagagga', 'aggagga', 'gu']) list(['guagaag', 'uga'])]\n",
      " [list(['cuggcug', 'ccaccgc', 'caccgcu', 'accgcuc', 'ccgcucg', 'cgcucgg', 'gcucggu', 'cucgguc', 'ucggucg', 'cggucgg', 'ggucggu'])\n",
      "  list(['aggccac', 'accggag'])]\n",
      " [list(['uaggcgu', 'aggggac']) list(['ggcccga', 'uccgccg'])]\n",
      " [list(['gucccug', 'uuggucc', 'ugguccc', 'gcgacgu', ''])\n",
      "  list(['ggccugg', ''])]\n",
      " [list(['gagccgg', 'ucagcuc', '', '', '']) list(['cuggcuc', ''])]\n",
      " [list(['agucgau', 'gucgaua', 'ucgauag', 'cgauaga', 'gauagac', 'auagacc', 'uagaccu', 'agaccuu', 'gaccuuc'])\n",
      "  list(['auggccc'])]\n",
      " [list(['uggcagg', 'uaccaug']) list(['aacucga', 'gcucaaa'])]\n",
      " [list(['ucaacca', 'ua', '', '']) list(['agacaaa', 'ucgguua'])]\n",
      " [list(['uucaugu', 'uugaag', '', '']) list(['gauuagu', ''])]\n",
      " [list(['cucaac', 'caacuca', 'aacucag']) list(['acaaagu', 'cgaauga'])]\n",
      " [list(['uuccauu', '', '']) list(['agau', ''])]\n",
      " [list(['ugggggu', 'ugggggu', 'uggggcu', 'cccgucg'])\n",
      "  list(['gggccga', ''])]\n",
      " [list(['uccggcc', 'uggggcg', '']) list(['ggcgcgc', 'cggcgga'])]\n",
      " [list(['ugacccg', '', '']) list(['ggaacgu', ''])]\n",
      " [list(['uu', 'guca']) list(['acuucau', 'a'])]\n",
      " [list(['acgagua', 'cccccuu', 'ccccuug', 'cccuugc', 'ccuugcg', 'cuugcgu', 'uugcguc', 'ugcgucg', 'gcgucga', 'cgucgau', 'gucgaug'])\n",
      "  list(['ggccccg', 'cgcaagc'])]\n",
      " [list(['uccgcgg', 'ucgcccg']) list(['ccacauc', ''])]\n",
      " [list(['uuugaag', 'uugaagu', 'ugaagug', 'aagugca', 'uac', 'ucu', '', ''])\n",
      "  list(['gggaagg', 'gagggga'])]\n",
      " [list(['uugccaa', 'acgau']) list(['auucccc', ''])]\n",
      " [list(['ugcgug', 'gggcgac', '']) list(['ggccccu', 'cacagua'])]\n",
      " [list(['accgcgg', 'cggcgcc']) list(['ucggcgc', ''])]\n",
      " [list(['aucgcgc']) list(['cgcccuc', 'ucccgcu'])]\n",
      " [list(['uggcagg']) list(['gggcaa', 'uggugga'])]\n",
      " [list(['uucccgc', 'gag']) list(['aggcag', 'gggucca'])]\n",
      " [list(['acgcagg', 'u', '']) list(['agccggg'])]\n",
      " [list(['uggcaug', 'uuguacg', 'uguacgg', 'guacggu', 'uacgguc', 'acggucu'])\n",
      "  list(['gaggagc', 'uccgagg'])]\n",
      " [list(['uucccag', 'uacc', 'acc']) list(['ggcuccu', ''])]\n",
      " [list(['uuggaug']) list(['uac'])]\n",
      " [list(['cacuguc', 'acugucc', 'cugucca', 'uguccac', 'guccaca', 'uccacau', 'ccacaug', 'cacauga', 'acaugac', 'caugacc', 'augaccg'])\n",
      "  list(['ggaugug', 'ccuuuag'])]\n",
      " [list(['ccccggg', 'ucccggg', 'cccgggg', 'gggcccc'])\n",
      "  list(['uccugag', 'cccuag'])]\n",
      " [list(['uugcugg', 'auuuacg', 'gaucu', 'cu', '', '', '', ''])\n",
      "  list(['auua', 'auuaauu', 'uuaauua', 'uaauuag', 'aauuaga', 'auuagac', 'uuagacg', 'uagacgg', 'agacggu', 'gacggug', 'acggugu', 'cgguguc'])]\n",
      " [list(['aacaagg', 'a', '']) list(['aaaaaga', 'aaaaaaa'])]\n",
      " [list(['a', 'ucgu']) list(['guucccc', 'uccg'])]\n",
      " [list(['ugcgccg']) list(['ggacggc', ''])]\n",
      " [list(['uccccgu', 'cugccug', 'ugccugc', 'gccugcc', 'ccugccu', 'cugccug', 'ugccugc'])\n",
      "  list(['gcggcg', 'ggcggcg'])]\n",
      " [list(['agcgacg', 'acuugcg', 'cuugcga', 'gcgaacc', ''])\n",
      "  list(['ggcuugg', ''])]\n",
      " [list(['uccgggg', 'cggggcg', 'ggggcgg', 'gggcggc', 'ggcggcg', 'gcggcgc', 'cggcgcg'])\n",
      "  list(['ggcgcgc', '', ''])]\n",
      " [list(['ccccgug', 'ccgugg', 'ugg', 'ggugccc', 'gugcccc', 'ugccccc', 'gcccccc', 'ccccccg', 'cccccgg', 'ccccgga', 'cccggaa', 'ccggaaa'])\n",
      "  list(['ccgc', 'ucucucu'])]\n",
      " [list(['uagggau']) list(['agacccu', 'uauccca'])]\n",
      " [list(['']) list(['ggucagg', 'ccagauc'])]\n",
      " [list(['acggcug', 'ucaggga']) list(['ggcagac', 'acac'])]\n",
      " [list(['ugcaggc', 'uac']) list(['uacaauu', 'acga'])]\n",
      " [list(['uuugugg', 'ugguuug', 'uugacac', 'uuguuu', 'uu'])\n",
      "  list(['', '', '', '', '', '', '', '', '', ''])]\n",
      " [list(['acccgug', 'agaaguu', 'gaaguuu', 'aaguuua', 'aguuuag', 'guuuagc', 'uuuagcc', 'uuagccc'])\n",
      "  list(['agcca', 'aag'])]\n",
      " [list(['ucggccg', 'ccggcgc', 'gcuccgc', 'uccgcga', 'gcgaccc', ''])\n",
      "  list(['agcccag', ''])]\n",
      " [list(['uaggcag']) list(['gcccuga', ''])]\n",
      " [list(['gacccug', 'gucccag', 'gaau']) list(['ggauaac'])]\n",
      " [list(['uccccga']) list(['uggccgc', 'cgccggu'])]\n",
      " [list(['ccugggg', 'uggggca', 'uggggag', 'ggguccc', 'guccccc'])\n",
      "  list(['ggau', 'gcgaggg'])]\n",
      " [list(['ucaguac', 'a', '', '', '', '', '', '', 'agcauga'])\n",
      "  list(['aaaagag', ''])]\n",
      " [list(['uggguuc', 'uccucuu', 'ccucuua', 'cucuuag', 'ucuuagu', 'cuuagug', 'uuagugg'])\n",
      "  list(['cgccc', ''])]\n",
      " [list(['uucucca', '', '', '', ''])\n",
      "  list(['auuua', 'auuuaua', 'uuuauaa', 'uuauaaa', 'uauaaac', 'auaaacc', 'uaaacca', 'aaaccac', 'aaccacg', 'accacga', 'ccacgag', 'cacgagu'])]\n",
      " [list(['ucccaug', 'agu']) list(['ggcgagu', 'cc'])]\n",
      " [list(['uuccccg', 'uccccga', 'ucccgug', 'gugaagu', 'ugaagug', 'gaagugc', 'aagugcc', 'agugccc'])\n",
      "  list(['gaagcgc', 'gucaguu'])]\n",
      " [list(['uc', 'cuccgag', 'uccgaga', 'ccgagac', 'cgagacc', 'gagaccc', 'agaccca', 'gacccau', 'acccaug'])\n",
      "  list(['ugacccc', 'cccaguc'])]\n",
      " [list(['acggccg', 'ggugucc', 'guguccc', 'ugucccg'])\n",
      "  list(['agccacg', 'cgaaggg'])]\n",
      " [list(['ugaggua', 'uucccac', 'ucccacc', 'uucccaa'])\n",
      "  list(['ugucagg', 'ccuucca', 'cuuccau', 'uuccauu', 'uccauua', 'ccauuag'])]\n",
      " [list(['uggagug', 'cgcguga', 'gcgugag', 'cgugagg', 'gugaggu'])\n",
      "  list(['gacacua'])]\n",
      " [list(['agggccc', 'acucuac']) list(['ugcucug', 'agugua'])]\n",
      " [list(['ugcacug', 'uugucac', 'ugucacg', 'gucacgu', 'ucacguu', 'cacguuc', 'acguucu'])\n",
      "  list(['', '', '', '', '', '', '', '', 'gguguu'])]\n",
      " [list(['gagacuu', 'uaaguc', 'aaguc', 'g', ''])\n",
      "  list(['gggaaga', 'uuaugau'])]\n",
      " [list(['auuacac', 'uuacacu', 'uacacuu', 'acacuuu', 'cacuuua'])\n",
      "  list(['aggcagg', 'u'])]\n",
      " [list(['aggcagc', 'uccagg', 'ggaccuc', 'gaccucu', 'accucuc', 'ccucucu', 'cucucuc', 'ucucucg'])\n",
      "  list(['aac', 'caagacc', 'aagacca', 'agaccac', 'gaccacu', 'accacuc'])]\n",
      " [list(['cacguca', 'acgucac', 'cgucacc', 'gucaccg', 'ucaccga', 'caccgau', 'accgaua', 'ccgauaa', 'cgauaag', 'gauaagu', 'gacc'])\n",
      "  list(['ggaucgc', 'ggugaug'])]\n",
      " [list(['aaaauag', 'uagaaug', '']) list(['agauugu', 'a'])]\n",
      " [list(['uucuacc', '', '', '', '']) list(['gau', ''])]\n",
      " [list(['agcgcuu', 'cagucgu', 'agucguu', 'gucguuc', 'ucguucg'])\n",
      "  list(['ucucguc'])]\n",
      " [list(['gggagaa', 'agaaugu', 'aauguga', 'u', '', '', ''])\n",
      "  list(['gugaaga', 'agug'])]\n",
      " [list(['aaaaagu', 'aaauuag', '']) list(['gccaaga', ''])]\n",
      " [list(['ugcagug', 'agugacg', 'gugacgu', 'ugacguu', 'gacguug', 'acguugg', 'cguugga', 'guuggag', 'uuggagg', 'uggaggc', 'ggaggca'])\n",
      "  list(['agc', ''])]\n",
      " [list(['uggaacc']) list(['cccccgc', ''])]\n",
      " [list(['aucuauu', 'uugguca', 'uacuc', 'c', '', '', ''])\n",
      "  list(['accauuu', 'uuuuuua'])]\n",
      " [list(['gugacgg', 'ugacggg', 'gacgggu', 'acggguu'])\n",
      "  list(['a', 'caccugc'])]\n",
      " [list(['ucuggug', 'uggugcg', 'cgaccag', 'gaccagg', 'accaggc', 'ccaggcg', 'caggcgu', 'aggcgug', 'ggcgugg', 'gcguggu', 'cgugguc', 'guggucu'])\n",
      "  list(['ggcaauc', ''])]\n",
      " [list(['uugaggg']) list(['ggca', 'cccua'])]\n",
      " [list(['ccggcgg', 'ccaggcg', 'caggcgg', 'aggcggc', 'ggcggcc', 'gcggccc', 'cggcccg', 'ggcccgc', 'gcccgcu', 'cccgcua', 'ccgcuag'])\n",
      "  list(['ugccccc', ''])]\n",
      " [list(['ucggcuc']) list(['gag', 'g'])]\n",
      " [list(['ugggauu', 'guggugg', 'ugguggu', 'ggugguu', 'gugguua', 'ugguuag', 'gguuagg', 'guuaggg', 'uuagggu', 'uagggug', 'agggugu'])\n",
      "  list(['ccacccc', ''])]\n",
      " [list(['ccggcgg']) list(['aggcaag', 'ggacgug'])]\n",
      " [list(['ucggcuu']) list(['ggauguc', 'ccagccg'])]\n",
      " [list(['uggacgg']) list(['ugacguc', 'ggag'])]\n",
      " [list(['ugaaguu', 'uuaaacc', 'uaaaccc', 'gu', 'u', '', '', '', ''])\n",
      "  list(['augggg', ''])]\n",
      " [list(['cccgcuc', 'ucgccu', 'uccgcuc', 'ccgcucc', 'cgcuccu', 'gcuccuc', 'cuccucg', 'uccucgc', 'ccucgcc', 'cucgccc', 'ucgcccc', 'cgccccg'])\n",
      "  list(['ggguugg', 'cagag'])]\n",
      " [list(['accacga']) list(['ggccgc', 'ccuu'])]\n",
      " [list(['aagauuc', 'cag', '']) list(['agaucac', 'acuaga'])]\n",
      " [list(['uggaaua', 'uugugu']) list(['gugcagc', 'gag'])]\n",
      " [list(['uugccga']) list(['ggcucuu', ''])]\n",
      " [list(['ugcccac']) list(['ggcgugu', ''])]\n",
      " [list(['aucaguu', 'gaggauc']) list(['aaucuug', ''])]\n",
      " [list(['uggggcg', 'ucgagga']) list(['cugcagu', 'gaa'])]\n",
      " [list(['ucggggg', 'cgaagua', 'gaaguag', 'aaguagg', 'aguaggg', 'guagggg', 'uaggggg'])\n",
      "  list(['cgaacgc', 'gcc'])]\n",
      " [list(['uccccgc', 'cugcugc', 'ugcugcg', 'gcugcgc', 'cugcgcc', 'ugcgccc', 'gcgcccc', 'cgccccu', 'gccccuc', 'ccccucc', 'cccuccg'])\n",
      "  list(['cgccacc', ''])]\n",
      " [list(['auggccc', 'acgcccg', 'gcccgca', 'cccgcaa']) list(['gugc', ''])]\n",
      " [list(['ucgcgug', 'ucgccc']) list(['ggcgggc', 'ucgac'])]\n",
      " [list(['uggcagg', 'uaccaug']) list(['gca', ''])]\n",
      " [list(['uu', 'uuccucc', 'uccuccc', 'ccuccca', 'cucccau', 'ucccauc', 'cccaucc', 'ccauccu', 'cauccuc', 'auccuca', 'uccucac', 'ccucacc'])\n",
      "  list(['agccag', ''])]\n",
      " [list(['ugcccag']) list(['gggucag'])]\n",
      " [list(['au', '', '']) list(['aucauug', ''])]\n",
      " [list(['aagaaug', '']) list(['gcaaagg', ''])]\n",
      " [list(['uccacua', '']) list(['gccuggc', 'aucag'])]\n",
      " [list(['ucagcgg']) list(['ugcuc', 'uguug'])]\n",
      " [list(['uggaggc']) list(['ugcaugg', ''])]\n",
      " [list(['aaccccg']) list(['cugcag', ''])]\n",
      " [list(['uggggcg', '']) list(['gggugac', 'gacagug'])]]\n"
     ]
    }
   ],
   "source": [
    "print(motifs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fréquence de certains couples de motifs peut révéler des fonctions biologiques s'alliant, expliquant les interactions. Eventuellement à corréler aux familles des ARN à étudier. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
